[{"title":"OpenLDAP 快速落地实践-进阶","path":"/2020/openldap-high-ranking.html","content":"备份与恢复> 主要介绍如何备份 OpenLDAP 的配置目录和数据目录，并将其恢复到另一个 OpenLDAP 服务中OpenLDAP 的备份OpenLDAP 的备份可以通过服务端的 `slapcat` 命令或客户端的 `ldapsearch` 命令两种方式进行。下面展示了如何在 OpenLDAP 服务端使用 `slapcat` 对配置目录和数据目录进行导出。```$ slapcat -n 0 -l ./config.`date '+%Y-%m-%d'`.ldif$ slapcat -n 2 -l ./data.`date '+%Y-%m-%d'`.ldif```其中，`-n` 表示要导出的 OpenLDAP 数据库编号OpenLDAP 的恢复 在开始恢复之前，需要先暂停 OpenLDAP 服务$ systemctl stop slapd OpenLDAP 配置目录一般位于 `/etc/openldap/slapd.d`，我们需要先将原有配置删除，然后使用 `slapadd` 导入新的配置$ rm -rf /etc/openldap/slapd.d/*$ slapadd -n 0 -F /etc/openldap/slapd.d -l ./config.2019-01-04.ldif$ chown -R ldap:ldap /etc/openldap/slapd.d 2020-04-20 OpenLDAP 数据目录一般位于 `/var/lib/ldap`，同样的我们需要先将原有数据删除，然后使用 `slapadd` 导入新的数据$ rm -rf /var/lib/ldap/*$ slapadd -n 2 -F /etc/openldap/slapd.d -l ./data.2019-01-04.ldif$ chown -R ldap:ldap /var/lib/ldap 最后，重启 OpenLDAP 服务即可$ systemctl start slapd添加 memberof 支持> 如果使用 LDAP 仅仅作为用户统一登录中心，则参考安装文档即可；如果 ldap 要与第三方软件结合，例如 confluence、gitlab 等结合，则需要开启 memberof 支持1. 开启 memberof 支持。```yamlvim 1-load-memberof.ldif内容如下：dn: cn=module,cn=configobjectClass: olcModuleListcn: module olcModuleLoad: memberof.laolcModulepath: /usr/lib64/openldap#ldap库路径与操作系统版本是相关的，此处是64位操作系统。```2. 新增用户支持 memberof 配置。```yamlvim 2-use-memberof.ldifdn: olcOverlay=memberof,olcDatabase={2}hdb,cn=configobjectClass: olcConfigobjectClass: olcMemberOfobjectClass: olcOverlayConfigobjectClass: topolcOverlay: memberof```3. 导入相关配置。```shldapadd -Y EXTERNAL -H ldapi:/// -f 1-chrootpw.ldifldapadd -Y EXTERNAL -H ldapi:/// -f 2-chdomain.ldifldapadd -Y EXTERNAL -H ldapi:/// -f 3-load-memberof.ldifldapadd -Y EXTERNAL -H ldapi:/// -f 4-use-memberof.ldif```4. 查看当前 dn 下包含 cn=config 配置列表。```shldapsearch -Q -LLL -Y EXTERNAL -H ldapi:/// -b cn=config dn```5. 查看用户的 memberof 信息。```shldapsearch -LL -Y EXTERNAL -H ldapi:/// \"(uid=xxxxxx)\" -b dc=xxx,dc=com dn memberof```开启日志 查看现在的日志配置[root@slave3] ~$ cat /etc/openldap/slapd.d/cn\\=config.ldif grep olcLogLevelstate 必须先创建日志文件，并调整权限，再修改 rsyslog.confmkdir -p /var/log/slapdtouch /var/log/slapd/slapd.logchown ldap:ldap /var/log/slapd/echo \"local4.* /var/log/slapd/slapd.log\" >> /etc/rsyslog.conf 重启使其生效`systemctl restart rsyslog` 修改数数据库配置文件[root@test1] ~$ cat log.ldif dn: cn=configchangetype: modifyadd: olcLogLevelolcLogLevel: 32[root@test1] ~$ ldapmodify -Y EXTERNAL -H ldapi:/// -f log.ldif 最好进行日志切割配置，防止文件过大，不便排查故障`vi /etc/logrotate.d/ldap`/var/log/slapd/slapd.log{ daily # 每天轮询一次 rotate  5 # 保存5个历史日志文件，超过的删除 size 100M copytruncate # 复制源日志内容后，清空文件，而不是创建新文件 dateext # 切割文件时，文件名带有日期 missingok # 如果指定的目录不存在，会报错，此选项用来抑制报错}color:orange 如果你是使用旧版修改配置文件的方式，如下启用日志功能 修改 `slapd.conf`[root@backup2] /etc/openldap$ vim slapd.conf#末尾添加一行loglevel -1 修改 rsyslog.conf，并重启[root@backup2] /etc/openldap$ vim /etc/rsyslog.conf#末尾添加如下一行：local4.* /var/log/slapd.log[root@backup2] /etc/openldap$ systemctl restart rsyslog 生成配置[root@backup2] /etc/openldap$ rm -rf /etc/openldap/slapd.d/*[root@backup2] /etc/openldap$ slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d/[root@backup2] /etc/openldap$ systemctl start slapd.service123color:green 来查看日志 通过 `tailf /var/log/slapd.log` 来查看日志","tags":["OpenLDAP"],"categories":["折腾不止"]},{"title":"Kubernetes 控制器的进化之旅","path":"/2020/kubernetes-operator.html","content":"> 我是一堆 Kubernetes 控制器。>> 你可能会疑惑为什么是一堆，因为我不是一个人，我只是众多控制器中的一员，你也可以把我看成是众多控制器的集合。我的职责就是监控集群内资源的实际状态，一旦发现其与期望的状态不相符，就采取行动使其符合期望状态。>> 想当初，Kubernetes 老大哥创造我时，只是打算让我用**控制循环**简单维护下资源的状态。但我后来的发展，远远超出了他的想象。1. 控制循环所谓控制循环就是一个用来调节系统状态的周期性操作，在 Kubernetes 中也叫**调谐循环**（Reconcile Loop）。我的手下控制着很多种不同类型的资源，比如 Pod，Deployment，Service 等等。就拿 `Deployment` 来说吧，我的控制循环主要分为三步：1. 从 `API Server` 中获取到所有属于该 Deployment 的 Pod，然后统计一下它们的数量，即它们的实际状态。2. 检查 Deployment 的 `Replicas` 字段，看看期望状态是多少个 Pod。3. 将这两个状态做比较，如果期望状态的 Pod 数量比实际状态多，就创建新 Pod，多几个就创建几个新的；如果期望状态的 Pod 数量比实际状态少，就删除旧 Pod，少几个就删除几个旧的。然而好景不长，我收到了 Kubernetes 掌门人（看大门的） `API Server` 的抱怨：“你访问我的次数太频繁了，非常消耗我的资源，我连上厕所的时间都没有了！”我仔细一想，当前的控制循环模式确实有这个缺陷 —— 访问 `API Server` 的次数太频繁了，容易被老大反感。所以我决定，找一个小弟。2. Informer这次我招的小弟叫 `Informer`，它分担一部分我的任务，具体的做法是这样的：由 `Informer` 代替我去访问 API Server，而我不管是查状态还是对资源进行伸缩都和 Informer 进行交接。而且 Informer 不需要每次都去访问 API Server，它只要在初始化的时候通过 `LIST API` 获取所有资源的最新状态，然后再通过 `WATCH API` 去监听这些资源状态的变化，整个过程被称作 `ListAndWatch`。而 Informer 也不傻，它也有一个助手叫 `Reflector`，上面所说的 `ListAndWatch` 事实上是由 Reflector 一手操办的。这一次，`API Server` 的压力大大减轻了，因为 Reflector 大部分时间都在 `WATCH`，并没有通过 LIST 获取所有状态，这使 `API Server` 的压力大大减少。我想这次掌门人应该不会再批评我了吧。然而没过几天，掌门人又找我谈话了：“你的手下每次来 WATCH 我，都要 WATCH 所有兄弟的状态，依然很消耗我的资源啊！我就纳闷了，你一次搞这么多兄弟，你虎啊？”我一想有道理啊，没必要每次都 WATCH 所有兄弟的状态，于是告诉 Informer：“以后再去 API Server 那里 WATCH 状态的时候，只查 WATCH 特定资源的状态，不要一股脑儿全 WATCH。“Informer 再把这个决策告诉 Reflector，事情就这么愉快地决定了。本以为这次我会得到掌门人的夸奖，可没过几天安稳日子，它又来找我诉苦了：“兄弟，虽然你减轻了我的精神压力，但我的财力有限啊，如果每个控制器都招一个小弟，那我得多发多少人的工资啊，你想想办法。”3. SharedInformer经过和其他控制器的讨论，我们决定这么做：所有控制器联合起来作为一个整体来分配 `Informer`，针对每个（受多个控制器管理的）资源招一个 Informer 小弟，我们称之为 `SharedInformer`。你们可以理解为共享 Informer，因为有很多资源是受多个控制器管理的，比如 Pod 同时受 `Deployment` 和 `StatefulSet` 管理。这样当多个控制器同时想查 Pod 的状态时，只需要访问一个 Informer 就行了。但这又引来了新的问题，`SharedInformer` 无法同时给多个控制器提供信息，这就需要每个控制器自己排队和重试。为了配合控制器更好地实现排队和重试，`SharedInformer` 搞了一个 `Delta FIFO Queue`（增量先进先出队列），每当资源被修改时，它的助手 `Reflector` 就会收到事件通知，并将对应的事件放入 `Delta FIFO Queue` 中。与此同时，`SharedInformer` 会不断从 `Delta FIFO Queue` 中读取事件，然后更新本地缓存的状态。这还不行，`SharedInformer` 除了更新本地缓存之外，还要想办法将数据同步给各个控制器，为了解决这个问题，它又搞了个工作队列（Workqueue），一旦有资源被添加、修改或删除，就会将相应的事件加入到工作队列中。所有的控制器排队进行读取，一旦某个控制器发现这个事件与自己相关，就执行相应的操作。如果操作失败，就将该事件放回队列，等下次排到自己再试一次。如果操作成功，就将该事件从队列中删除。现在这个工作模式得到了大家的一致好评。虽然单个 `SharedInformer` 的工作量增加了，但 Informer 的数量大大减少了，老大可以把省下来的资金拿出一小部分给 `SharedInformer` 涨工资啊，这样大家都很开心。4. CRD全民 Kubernetes 时代到了。随着容器及其编排技术的普及，使用 Kubernetes 的用户大量增长，用户已经不满足 Kubernetes 自带的那些资源（Pod，Node，Service）了，大家都希望能根据具体的业务创建特定的资源，并且对这些资源的状态维护还要遵循上面所说的那一套控制循环机制。幸好最近掌门人做了一次升级，新增了一个插件叫 `CRD（Custom Resource Definition）`，创建一个全新的资源实例，只需要经过以下两步：1. 创建一个 CRD 资源（没错，CRD 也是一种资源类型），其中定义” 自定义资源 “的 **API 组**、**API 版本**和**资源类型**。这样就会向 API Server 注册该资源类型的 API。2. 指定上面定义的 API 组 和 API 版本，创建自定义资源。当然，中间还要加入一些代码让 Kubernetes 认识自定义资源的各种参数。到这一步就基本上完成了自定义资源的创建，但 Kubernetes 并不知道该资源所对应的业务逻辑，比如你的自定义资源是宿主机，那么对应的业务逻辑就是创建一台真正的宿主机出来。那么怎样实现它的业务逻辑呢？5. 自定义控制器`Controller Manager` 见多识广，说：” 这里的每个控制器都是我的一部分，当初创造你们是因为你们都属于通用的控制器，大家都能用得上。而自定义资源需要根据具体的业务来实现，我们不可能知道每个用户的具体业务是啥，自己一拍脑袋想出来的自定义资源，用户也不一定用得上。我们可以让用户自己编写自定义控制器，你们把之前使用的控制循环和 Informer 这些编码模式总结一下，然后提供给用户，让他们按照同样的方法编写自己的控制器。“Deployment 控制器一惊，要把自己的秘密告诉别人？那别人把自己取代了咋办？赶忙问道：” 那将来我岂不是很危险，没有存在的余地了？“`Controller Manager` 赶忙解释道：” 不用担心，虽然用户可以编写自定义控制器，但无论他们玩出什么花样，只要他们的业务跑在 Kubernetes 平台上，就免不了要跑容器，最后还是会来求你们帮忙的，你要知道，控制器是可以层层递进的，他们只不过是在你外面套了一层，最后还是要回到你这里，请求你帮忙控制 Pod。“这下大家都不慌了，决定就把自定义控制器这件事情交给用户自己去处理，将选择权留给用户。6. Operator用户自从获得了编写自定义控制器的权力之后，非常开心，有的用户（CoreOS）为了方便大家控制有状态应用，开发出了一种特定的控制器模型叫 `Operator`，并开始在社区内推广，得到了大家的一致好评。不可否认，`Operator` 这种模式是很聪明的，它把需要特定领域知识的应用单独写一个 Operator 控制器，将这种应用特定的操作知识编写到软件中，使其可以利用 Kubernetes 强大的抽象能力，达到正确运行和管理应用的目的。以 `ETCD Operator` 为例，假如你想手动扩展一个 ETCD 集群，一般的做法是：1. 使用 ETCD 管理工具添加一个新成员。2. 为这个成员所在的节点生成对应的启动参数，并启动它。而 ETCD Operator 将这些特定于 etcd 的操作手法编写到了它的控制循环中，你只需要通过修改自定义资源声明集群期望的成员数量，剩下的事情交给 Operator 就好了。本以为这是一个皆大欢喜的方案，但没过多久，就有开发 Operator 的小哥来抱怨了：” 我们有很多开发的小伙伴都是不懂运维那一套的，什么高可用、容灾根本不懂啊，现在让我们将运维的操作知识编写到软件中，臣妾做不到啊。。“这确实是个问题，这样一来就把开发和运维的工作都塞到了开发手里，既懂开发又懂运维的可不多啊，为了照顾大家，还得继续想办法把开发和运维的工作拆分开来。7. OAM这时候阿里和微软发力了，他们联合发布了一个开放应用模型，叫 Open Application Model （OAM）。这个模型就是为了解决上面提到的问题，将开发和运维的职责解耦，不同的角色履行不同的职责，并形成一个统一的规范，如下图所示：这个规范告诉我们：- 开发人员负责描述组件的功能，如何配置组件，以及运行需要多少资源- 运维人员负责将相关组件组合成一个应用，并配置运行时参数和运维支撑能力，比如是否需要监控，是否需要弹性伸缩。- 基础设施工程师负责建立和维护应用的运行时环境（如底层系统）。其中每一个团队负责的事情都用对应的 CRD 来配置。这样一来，开发和运维人员的职责就被区分开来了，简化了应用的组合和运维。它将应用的配置和运维特征（如自动伸缩、流量监控）进行解耦，然后通过建模构成一个整体，避免了 Operator 这种模型带来的大量冗余。自从用上了这个模型之后，运维和开发小哥表示现在他们的关系很融洽，没事还能一起出去喝两杯。文章转自","tags":["Cloud Navite","Kubernetes"],"categories":["技术加油站"]},{"title":"OpenLDAP 快速落地实践-部署配置","path":"/2020/openldap-install-config.html","content":"## 下载依赖\n\n本文中相关操作系统及依赖包的版本如下：\n\n- centos-release-7-4.1708.el7.centos.x86_64\n- openldap-clients-2.4.44-5.el7.x86_64：包含客户端程序，用来访问和修改 OpenLDAP 目录\n- openldap-servers-2.4.44-5.el7.x86_64：包含主 LDAP 服务器 slapd 和同步服务器 slurpd 服务器、迁移脚本和相关文件\n\n## 安装部署\n\n**第一步，需要切换到 root 账号来安装 OpenLDAP 相关程序包，并启动服务：**\n\n```bash\n$ yum install -y openldap-servers openldap-clients\n$ cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG\n$ chown ldap. /var/lib/ldap/DB_CONFIG\n$ systemctl enable slapd\n$ systemctl start slapd\n```\n\n**第二步，我们使用 `slappasswd` 命令来生成一个密码，并使用 LDIF（LDAP 数据交换格式）文件将其导入到 LDAP 中来配置管理员密码：**\n\n```bash\n$ slappasswd\nNew password:\nRe-enter new password:\n{SSHA}KS/bFZ8KTmO56khHjJvM97l7zivH1MwG\n\n$ vim chrootpw.ldif\n# specify the password generated above for \"olcRootPW\" section\ndn: olcDatabase={0}config,cn=config\nchangetype: modify\nadd: olcRootPW\nolcRootPW: {SSHA}KS/bFZ8KTmO56khHjJvM97l7zivH1MwG\n\n$ ldapadd -Y EXTERNAL -H ldapi:/// -f chrootpw.ldif\n```\n\n**第三步，我们需要向 LDAP 中导入一些基本的 Schema。这些 Schema 文件位于 `/etc/openldap/schema/` 目录中，定义了我们以后创建的条目可以使用哪些属性**：\n\n```bash\n$ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/core.ldif\n$ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif\n$ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif\n$ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif\n```\n\n**第四步，我们需要配置 LDAP 的顶级域（以 `dc=leeif,dc=me` 为例）及其管理域：**\n\n```bash\n$ slappasswd\nNew password:\nRe-enter new password:\n{SSHA}z/rsbmAjVtLlWeUB0xS5itLPI0VA1akD\n\n$ vim chdomain.ldif\n# replace to your own domain name for \"dc=***,dc=***\" section\n# specify the password generated above for \"olcRootPW\" section\ndn: olcDatabase={1}monitor,cn=config\nchangetype: modify\nreplace: olcAccess\nolcAccess: {0}to * by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\"\n  read by dn.base=\"cn=admin,dc=leeif,dc=me\" read by * none\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nreplace: olcSuffix\nolcSuffix: dc=leeif,dc=me\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nreplace: olcRootDN\nolcRootDN: cn=admin,dc=leeif,dc=me\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nadd: olcRootPW\nolcRootPW: {SSHA}z/rsbmAjVtLlWeUB0xS5itLPI0VA1akD\n\ndn: olcDatabase={2}mdb,cn=config\nchangetype: modify\nadd: olcAccess\nolcAccess: {0}to attrs=userPassword,shadowLastChange by\n  dn=\"cn=admin,dc=leeif,dc=me\" write by anonymous auth by self write by * none\nolcAccess: {1}to dn.base=\"\" by * read\nolcAccess: {2}to * by dn=\"cn=admin,dc=leeif,dc=me\" write by * read\n\n$ ldapmodify -Y EXTERNAL -H ldapi:/// -f chdomain.ldif\n```\n\n**第五步，在上述基础上，我们来创建一个叫做 leeif News Agency 的组织，并在其下创建一个 Manager 的组织角色（该角色内的用户具有管理整个 LDAP 的权限）和 People 和 Group 两个组织单元：**\n\n```bash\n$ vim basedomain.ldif\n# replace to your own domain name for \"dc=***,dc=***\" section\ndn: dc=leeif,dc=me\nobjectClass: top\nobjectClass: dcObject\nobjectclass: organization\no: leeif.IO\ndc: leeif\n\ndn: cn=admin,dc=leeif,dc=me\nobjectClass: organizationalRole\ncn: Manager\n\ndn: ou=people,dc=leeif,dc=me\nobjectClass: organizationalUnit\nou: people\n\ndn: ou=group,dc=leeif,dc=me\nobjectClass: organizationalUnit\nou: group\n\n$ ldapadd -x -D cn=admin,dc=leeif,dc=me -W -f basedomain.ldif\n```\n\n通过以上的所有步骤，我们就设置好了一个 LDAP 目录树：其中基准 dn `dc=leeif,dc=me` 是该树的根节点，其下有一个管理域 `cn=admin,dc=leeif,dc=me` 和两个组织单元 `ou=people,dc=leeif,dc=me` 及 `ou=group,dc=leeif,dc=me`。\n\n接下来，我们来创建一个叫作 Ada Catherine 的员工并将其分配到 Secretary 组来验证上述配置是否生效。\n\n```bash\n$ slappasswd\nNew password:\nRe-enter new password:\n{SSHA}HTGqAd4p6fOOIVHm7VZYUSorWGfnrqAA\n\n$ vim ldapuser.ldif\n# create new\n# replace to your own domain name for \"dc=***,dc=***\" section\ndn: uid=ada,ou=people,dc=leeif,dc=me\nobjectClass: inetOrgPerson\nobjectClass: posixAccount\nobjectClass: shadowAccount\nuid: ada\ncn: Ada Catherine\nsn: Catherine\nuserPassword: {SSHA}HTGqAd4p6fOOIVHm7VZYUSorWGfnrqAA\nloginShell: /bin/bash\nuidNumber: 1000\ngidNumber: 1000\nhomeDirectory: /home/users/ada\n\ndn: cn=Secretary,ou=group,dc=leeif,dc=me\nobjectClass: posixGroup\ncn: Secretary\ngidNumber: 1000\nmemberUid: ada\n\n# ldapadd -x -D cn=admin,dc=leeif,dc=me -W -f ldapuser.ldif\nEnter LDAP Password:\nadding new entry \"uid=ada,ou=People,dc=leeif,dc=org\"\nadding new entry \"cn=Secretary,ou=Group,dc=leeif,dc=org\"\n```\n\n我们也可以使用 `ldapsearch` 命令来查看 LDAP 目录服务中的所有条目信息：\n\n```bash\n$ ldapsearch -x -b \"dc=leeif,dc=me\" -H ldap://127.0.0.1\n# extended LDIF\n#\n# LDAPv3\n# base <dc=leeif,dc=me> with scope subtree\n# filter: (objectclass=*)\n# requesting: ALL\n#\n\n# leeif.org\ndn: dc=leeif,dc=me\nobjectClass: top\nobjectClass: dcObject\nobjectClass: organization\no: leeif News Agency\ndc: leeif\n...\n```\n\n如果要删除一个条目，可以按下面的命令操作：\n\n```bash\n$ ldapdelete -x -W -D 'cn=admin,dc=leeif,dc=me' \"uid=ada,ou=People,dc=leeif,dc=me\"\n```\n\n## 常用命令记录\n\n```bash\n(&(&(objectClass=inetOrgPerson)))\nmkdir /etc/yum.repos.d/backup\nmv /etc/yum.repos.d/* /etc/yum.repos.d/backup/\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo\n\nyum -y install openldap-servers openldap-clients\n# yum reinstall --downloadonly --downloaddir=./openldap/ openldap-servers openldap-clients\n\nmv slapd.d slapd.d.bak\n\nsudo systemctl stop slapd && sudo rm -rf slapd.d && sudo mkdir slapd.d\nsudo slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d\nsudo chown -R ldap:ldap slapd.d  && sudo systemctl start slapd\n\nsystemctl stop slapd && rm -rf slapd.d && mkdir slapd.d\nslaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d\nchown -R ldap:ldap slapd.d  && systemctl start slapd\n\nservice slapd stop && rm -rf slapd.d && mkdir slapd.d\nslaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d\nchown -R ldap:ldap slapd.d  && service slapd start\n\nrm -rf /var/lib/ldap && mkdir /var/lib/ldap\n\ncp /usr/share/openldap-servers/slapd.ldif /etc/openldap/\ncp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG\nchown ldap. /var/lib/ldap/DB_CONFIG\nchown -R ldap:ldap slapd.d \nchown -R ldap:ldap /var/lib/ldap/*\n\n# 方案一\nvim /etc/openldap/slapd.ldif  ##修改后的初始化ldif文件\nslapadd -n 0 -F slapd.d -l slapd.ldif   ##生成配置数据库信息\n\n# 方案二\nvi /etc/openldap/slapd.conf\nslaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d\n\n# systemctl start slapd\n# systemctl enable slapd\n# systemctl status slapd\n```\n\n## slapd.conf 文件配置\n\n```bash\npidfile /var/run/openldap/slapd.pid\nargsfile /var/run/openldap/slapd.args\n\ninclude /etc/openldap/schema/core.schema\ninclude /etc/openldap/schema/collective.schema\ninclude /etc/openldap/schema/corba.schema\ninclude /etc/openldap/schema/cosine.schema\ninclude /etc/openldap/schema/duaconf.schema\ninclude /etc/openldap/schema/dyngroup.schema\ninclude /etc/openldap/schema/inetorgperson.schema\ninclude /etc/openldap/schema/java.schema\ninclude /etc/openldap/schema/misc.schema\ninclude /etc/openldap/schema/nis.schema\ninclude /etc/openldap/schema/openldap.schema\ninclude /etc/openldap/schema/pmi.schema\ninclude /etc/openldap/schema/ppolicy.schema\n\nmodulepath /usr/lib64/openldap\nmoduleload memberof.la\nmoduleload back_ldap.la\nmoduleload back_relay.la\nmoduleload pcache.la\nmoduleload ppolicy.la\nmoduleload syncprov.la\nmoduleload rwm.la\n\nloglevel 256\n\n# before any database\noverlay rwm\nrwm-rewriteEngine on\nrwm-rewriteContext bindDN\n# rwm-rewriteRule \"(.+,)?dc=leeif,dc=me$\" \"$1dc=auth\" \":@\"\nrwm-rewriteRule \"(^uid=.+,)(.+,)?dc=leeif,dc=me$\" \"$1dc=auth\" \":@\"\n\ndatabase    config\naccess  to *\n        by dn.base=\"gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth\" manage\n        by * none\n\ndatabase    monitor\naccess  to dn.base=\"dc=ldapproxy,dc=com\"\n        by ssf=256 group.exact=\"cn=admin,dc=ldapproxy,dc=com\" read\n        by * none\n\ndatabase    hdb\nsuffix      \"dc=ldapproxy,dc=com\"\nrootdn      \"cn=admin,dc=ldapproxy,dc=com\"\nrootpw      {SSHA}password\ndirectory   /var/lib/ldap\n\n# Database LDAP for OpenLDAP \ndatabase    ldap\nreadonly    yes\nsuffix      \"dc=leeif,dc=me\"\nuri         ldap://127.0.0.1:389\nidassert-bind bindmethod=simple\n   binddn=\"cn=admin,dc=leeif,dc=me\"\n   credentials=\"zto.com\"\n   mode=none\n   flags=non-prescriptive\nidassert-authzFrom \"dn.exact:cn=admin,dc=ldapproxy,dc=com\"\n\n# Database LDAP for LDAP-Auth\ndatabase    ldap\nreadonly    yes\nsuffix      \"dc=auth\"\nuri         ldap://127.0.0.1:10389\n```","tags":["OpenLDAP"],"categories":["折腾不止"]},{"title":"OpenLDAP 快速落地实践-基本介绍","path":"/2020/openldap-getting-started.html","content":"场景需求color:orange 需求 当公司体量较大，内部有多个系统，如果每个平台都需要维护一个用户管理体系，那么如果一个员工拥有 N 个平台权限离职及常规权限变更，对于的管理无疑也是一个挑战，也无法做到精细化权限管理。比如每次新进或离职一位同事，我们这边 OPS 运维组的小伙伴们，都要在每个系统上去添加用户，搞得小伙伴们很不爽。简单说一下 OPENLDAP 对运维管理的价值，支撑企业技术发展比如 `GIT、 ZABBIX、 YAPI、 JUMPSERVER、 OA` 等大大小小系统，乃至 Windows，Linux 系统的认证登录。通过 LDAP 技术我们可以实现多平台账号集中管理，权限灵活控制，密码强度及其有效期的约束，将用户管理与各个平台解耦，最终实现一次修改 N 处生效。LDAP 简介`LDAP`（轻量级目录访问协议，`Lightweight Directory Access Protocol`) 是实现提供被称为目录服务的信息服务。目录服务是一种特殊的数据库系统，其专门针对读取，浏览和搜索操作进行了特定的优化。目录一般用来包含描述性的，基于属性的信息并支持精细复杂的过滤能力。目录一般不支持通用数据库针对大量更新操作操作需要的复杂的事务管理或回卷策略。而目录服务的更新则一般都非常简单。这种目录可以存储包括个人信息、web 链结、jpeg 图像等各种信息。为了访问存储在目录中的信息，就需要使用运行在 TCP/IP 之上的访问协议 —LDAP。LDAP 目录中的信息是是按照树型结构组织，具体信息存储在条目 (entry) 的数据结构中。条目相当于关系数据库中表的记录；条目是具有区别名 `DN` （Distinguished Name）的属性（Attribute），DN 是用来引用条目的，DN 相当于关系数据库表中的关键字（Primary Key）。属性由类型（Type）和一个或多个值（Values）组成，相当于关系数据库中的字段（Field）由字段名和数据类型组成，只是为了方便检索的需要，LDAP 中的 Type 可以有多个 Value，而不是关系数据库中为降低数据的冗余性要求实现的各个域必须是不相关的。LDAP 中条目的组织一般按照地理位置和组织关系进行组织，非常的直观。LDAP 把数据存放在文件中，为提高效率可以使用基于索引的文件数据库，而不是关系数据库。类型的一个例子就是 mail，其值将是一个电子邮件地址。OpenLADP 简介LDAP 具有两个标准，分别是 X.500 和 LDAP。OpenLDAP 是基于 X.500 标准的，而且去除了 X.500 复杂的功能并且可以根据自我需求定制额外扩展功能，但与 X.500 也有不同之处，例如 OpenLDAP 支持 TCP/IP 协议等。OpenLDAP 可以直接运行在更简单和更通用的 TCP/IP 或其他可靠的传输协议层上，避免了在 OSI 会话层和表示层的开销，使连接的建立和包的处理更简单、更快，对于互联网和企业网应用更理想。OpenLDAP 目录中的信息是以树状的层次结构来存储数据（这很类同于 DNS），最顶层即根部称作 “基准 DN”，形如 “dc=mydomain,dc=org” 或者 “o=mydomain.org”，前一种方式更为灵活也是 Windows AD 中使用的方式。在根目录的下面有很多的文件和目录，为了把这些大量的数据从逻辑上分开，OpenLDAP 像其它的目录服务协议一样使用 `OU`（`Organization Unit`，组织单元），可以用来表示公司内部机构，如部门等，也可以用来表示设备、人员等。同时 OU 还可以有子 OU，用来表示更为细致的分类。OpenLDAP 中每一条记录都有一个唯一的区别于其它记录的名字 `DN`（`Distinguished Name`）, 其处在 “叶子” 位置的部分称作 RDN (用户条目的相对标识名)。如 dn:cn=tom,ou=animals,dc=ilanni,dc=com 中 cn 即为 RDN，而 RDN 在一个 OU 中必须是唯一的。OpenLDAP 默认以 `Berkeley DB` 作为后端数据库，BerkeleyDB 数据库主要以散列的数据类型进行数据存储，如以键值对的方式进行存储。**BerkeleyDB 是一类特殊的面向查询进行优化、面向读取进行优化的数据库，主要用于搜索、浏览、更新查询操作，一般对于一次写入数据、多次查询和搜索有很好的效果**。BerkeleyDB 不支持事务型数据库 (MySQL、MariDB、Oracle 等) 所支持的高并发的吞吐量以及复杂的事务操作。LDAP 简称目录 简称  全称（含义）  ----  ------------------------------------  c  countryName（国家）  dc  domainComponent（域名）  o  organization（组织 - 公司）  ou  organization unit（组织单元 - 部门）  sn  suer name（真实名称）  cn  common name（常用名称）","tags":["OpenLDAP"],"categories":["折腾不止"]},{"title":"模块设计文档编写规范","path":"/2019/module-design-doc.html","content":"## 模块负责人\n\n-   **👩‍💻** leeifme / XXXX项目\n-   **🚀** XXXX部门  /  XXXX事业部  \n-   **📧** Email i@leeif.me\n\n## 版本历史记录(History) （可选）\n\n>   设计稿版本每发生一次比较大的迭代更新，都要记录在版本历史记录里，相比一个个去翻以前的设计稿，版本历史记录可以清晰地展现设计稿的迭代历程，有哪些需求的变动，有哪些设计时没思考清楚需要修改的地方，Review 时大家给出了哪些意见和建议等。有时版本需要回滚，可以更方便地追溯，而项目结束后浏览这一部分，可以看到自己的设计在哪些方面一开始思考不足出现了各种问题，是如何被发现、改进和提升的，下一次设计的时候是否可以更早地思考到和回避掉\n\n## 排期(Schedule) （可选）\n\n>   和需求方确认各阶段交付的时间节点，制定完成模块设计的具体计划，每个阶段大概做哪些工作，什么时候内部 Review，什么时候和项目组 Review 等。确保设计以一个合理的节奏展开，可以以较高的质量按时交付\n\n## 模块概述(Background) \n\n>   这一部分的内容在开发者和 PM、业务方充分沟通需求之后完成 \n\n-   **模块描述，要设计的产品是什么，解决什么业务需求**\n-   业务 / 产品现状，总结需求方现在面临的主要问题 \n-   **功能设计，模块开发关键点以及业务逻辑描述**\n-   需要设计什么新的功能，需要优化哪些已有的设计 \n-   提高模块哪些使用环节的体验，引导用户做出什么操作\n\n## 模块详细设计\n\n>   详细描述模块实现的架构分析，采用的框架、技术栈选型，以及实现算法等\n\n-   **使用第三方服务**：采用的框架、什么存储服务、数据库、队列等等的一些服务，以及可能需要用到的算法\n-   **程序逻辑描述**：有什么样的交互逻辑，处理流程是什么样的，是不是有异步处理任务又是怎样做的\n-   **数据结构定义**：程序内部主要用到的数据结构、数据库表设计、索引设计\n-   **结构 / 架构图**：根据使用了什么服务、有什么样的调用流程、或者是程序里面有什么样的结构和流程需要画的图\n    - [百度脑图](http://naotu.baidu.com/)\n    - [Process On](https://www.processon.com/)\n\n`这些框架、设计都需经过可行性分析，必须是可行的`\n\n## 接口设计文档(Interface)\n\n>   主要参考 `Swagger`文档（如果有），这里只做一些补充说明，用来说明调用此接口需要注意的事项(没有可不写)\n\n## 原型设计（可选）\n\n>原型设计之于应用开发，是为第一要素。它所起到的不仅是沟通的作用，更有体现之效。通过内容和结构展示，以及粗略布局，能够说明用户将如何与产品进行交互 。也能更直观的体现出所设计模块的基本功能和交互方式，体现开发者及UI设计师的idea，体现用户所期望看到的内容，体现内容相对优先级等 \n\n-   [墨刀](https://modao.cc/)\n-   [摹客](https://www.mockplus.cn/)\n-   [Axure RP](https://www.axure.com.cn/)\n\n## 测试要点（可选）\n\n>   给出测试模块的主要测试要求，和逻辑操作\n\n\n\n`注明：` 以上设计规范只是通用设计要求，具体视模块功能要求做具体改动","tags":["规范建议"],"categories":["设计开发"]},{"title":"搭建 Airflow 任务调度环境","path":"/2019/deploy-airflow.html","content":"## 前期准备\n\n### 关闭防火墙和 selinux\n\n```sh\nsystemctl stop firewalld\nsystemctl disable firewalld\nsetenforce 0 \nsed -i 's/^SELINUX=.*/SELINUX=disabled/g' /etc/selinux/config\n```\n\n### 部署 Python 3.X\n\n-   依赖包安装\n\n    Python 安装会依赖一些环境，为了避免在安装过程中因为缺少依赖而产生不必要的麻烦，需要先执行以下命令，确保安装好以下依赖包：\n\n    ```bash\n    yum -y install zlib zlib-devel\n    yum -y install bzip2 bzip2-devel\n    yum -y install ncurses ncurses-devel\n    yum -y install readline readline-devel\n    yum -y install openssl openssl-devel\n    yum -y install openssl-static\n    yum -y install xz lzma xz-devel\n    yum -y install sqlite sqlite-devel\n    yum -y install gdbm gdbm-devel\n    yum -y install tk tk-devel\n    yum -y install libffi-devel # 只有 3.7 才会用到这个包，如果不安装这个包的话，在 make 阶段会出现如下的报错：ModuleNotFoundError: No module named '_ctypes'\n    yum install gcc\n    yum install wget\n    \n    # 安装 pip，因为 CentOs 是没有 pip 的\n    #运行这个命令添加epel扩展源 \n    yum -y install epel-release \n    #安装pip \n    yum install python-pip\n    ```\n\n-   Python 源码下载\n\n    可以前往 https://www.python.org/ftp/python/ 查看 Python 各个版本\n\n    ```sh\n    wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz\n    ```\n\n知识点补充：如果不知道 `configure, make, make install` 三个命令作用，[点这里查看](https://www.cnblogs.com/tinywan/p/7230039.html)\n\n**安装 Python**\n\n-   解压缩\n\n    ```sh\n    tar -zxvf Python-3.7.0.tgz\n    ```\n\n-   进入解压后的目录，依次执行下面命令进行手动编译\n\n    ```sh\n    ./configure prefix=/usr/local/python3 # 指定目录\n    make && make install\n    ```\n\n    如果最后没提示出错，就代表正确安装了\n\n-   添加软链接\n\n    ```sh\n    # 做好原始数据的备份\n    mv /usr/bin/python /usr/bin/python2.backup \n    mv /usr/bin/pip /usr/bin/pip2.backup\n    \n    # 设置软连接\n    ln -s /usr/local/python3/bin/python3.7 /usr/bin/python\n    ln -s /usr/local/python3/bin/pip3.7 /usr/bin/pip\n    \n    # 检测\n    python -V\n    pip -V\n    ```\n\n-   保证系统可用\n\n    更改 yum 配置，因为其要用到 python2 才能执行，否则会导致 yum 不能正常使用（不管安装 python3 的那个版本，都必须要做的）\n\n    ```yaml\n    # 把 #! /usr/bin/python 修改为 #! /usr/bin/python2 \n    vi /usr/bin/yum \n    vi /usr/libexec/urlgrabber-ext-down \n    ```\n\n### 部署 PostgreSQL\n\n-   安装 PostgreSQL 仓库\n\n    ```sh\n    $ yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm\n    ```\n\n-   安装客户端\n\n    ```sh\n    $ yum install postgresql10\n    ```\n\n-   安装服务端\n\n    ```sh\n    $ yum install postgresql10-server\n    ```\n\n-   加入开机启动项\n\n    ```sh\n    $ systemctl enable postgresql-10.service\n    ```\n\n-   初始化数据库\n\n    ```sh\n    $ /usr/pgsql-10/bin/postgresql-10-setup initdb\n    ```\n\n-   启动数据库服务\n\n    ```sh\n    $ systemctl start postgresql-10\n    ```\n\n-   检查运行状态\n\n    ```sh\n    $ systemctl status postgresql-10\n    ```\n\n-   设置用户密码\n\n    ```sh\n    $ su - postgres\n    Last login: Mon Aug  5 11:09:14 CST 2019 on pts/0\n    # 默认用户postgres\n    -bash-4.2$ psql\n    psql (10.9)\n    Type \"help\" for help.\n    \n    postgres=# \\password\n    # 设置密码为 '******'\n    Enter new password:\n    Enter it again:\n    # 保存退出\n    postgres=# \\q\n    ```\n\n-   修改监听地址\n\n    `vi /var/lib/pgsql/10/data/postgresql.conf `\n\n    ```sh\n    listen_addresses = '*'\n    #listen_addresses = 'localhost'\n    ```\n\n-   修改客户端认证方式\n\n    `vi /var/lib/pgsql/10/data/pg_hba.conf`\n\n    ```sh\n    # replication privilege.\n    #local   replication     all                                     peer\n    #host    replication     all             127.0.0.1/32            ident\n    #host    replication     all             ::1/128                 ident\n    host    all     all             0.0.0.0/0                 md5\n    ```\n\n-   重启服务\n\n    ```sh\n    $ systemctl restart postgresql-10\n    ```\n\n-   连接测试\n\n    ```sh\n    $ psql -h 192.168.1.2 -U postgres\n    ```\n\n### 部署 RabbitMQ\n\n**安装 Erlang**\n\nRabbitMQ 是使用 Erlang 开发的，所以需要首先安装 Erlang，本文安装其最新版本\n\n-   添加 repo 文件：\n\n    ```sh\n    $ vi /etc/yum.repos.d/rabbitmq_erlang.repo\n    ```\n\n    文件内容：\n\n    ```sh\n    [rabbitmq_erlang]\n    name=rabbitmq_erlang\n    baseurl=https://packagecloud.io/rabbitmq/erlang/el/7/$basearch\n    repo_gpgcheck=1\n    gpgcheck=0\n    enabled=1\n    gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey\n    sslverify=1\n    sslcacert=/etc/pki/tls/certs/ca-bundle.crt\n    metadata_expire=300\n    \n    [rabbitmq_erlang-source]\n    name=rabbitmq_erlang-source\n    baseurl=https://packagecloud.io/rabbitmq/erlang/el/7/SRPMS\n    repo_gpgcheck=1\n    gpgcheck=0\n    enabled=1\n    gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey\n    sslverify=1\n    sslcacert=/etc/pki/tls/certs/ca-bundle.crt\n    metadata_expire=300\n    ```\n\n-   安装：\n\n    ```sh\n    $ yum -y install erlang socat\n    ```\n\n**安装 RabbitMQ**\n\n-   下载 RPM 包：\n\n    ```sh\n    $ wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.17/rabbitmq-server-3.7.17-1.el7.noarch.rpm\n    ```\n\n-   导入 GPG key：\n\n    ```sh\n    $ rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc\n    ```\n\n-   安装 RabbitMQ：\n\n    ```sh\n    $ rpm -Uvh rabbitmq-server-3.7.17-1.el7.noarch.rpm\n    ```\n\n-   启动 RabbitMQ：\n\n    ```sh\n    $ systemctl start rabbitmq-server\n    ```\n\n-   查看 RabbitMQ 运行状态\n\n    ```sh\n    $ systemctl status rabbitmq-server\n    ```\n\n-   将 RabbitMQ 加入开机自启动：\n\n    ```sh\n    $ systemctl enable rabbitmq-server\n    ```\n\n**RabbitMQ 配置**\n\n-   启用 RabbitMQ 网页管理插件\n\n    ```sh\n    $ rabbitmq-plugins enable rabbitmq_management\n    ```\n\n-   创建管理员用户并授权：\n\n    ```sh\n    $ rabbitmqctl add_user admin 你的密码\n    $ rabbitmqctl set_user_tags admin administrator\n    $ rabbitmqctl set_permissions -p / admin \".*\" \".*\" \".*\"\n    ```\n\n在浏览器访问 [http://IP:15672](http://ip:15672/) 即可进入到 RabbitMQ 网页管理页面\n\n## 部署 Airflow\n\n### 通过 pip 安装 airflow 脚手架\n\n安装之前需要设置一下临时环境变量 `SLUGIFY_USES_TEXT_UNIDECODE` ，不然，会导致安装失败，命令如下：\n\n```sh\nexport SLUGIFY_USES_TEXT_UNIDECODE=yes\n```\n\n-   安装 airflow 脚手架:\n\n    ```sh\n    sudo pip install apache-airflow===1.10.4\n    ```\n\n    airflow 会被安装到 python3 下的 site-packages 目录下，完整目录为:`${PYTHON_HOME}/lib/python3.6/site-packages/airflow`，我的 airflow 目录如下所示：\n\n    ```sh\n    [root@n71 airflow]# pwd\n    /usr/local/python3/lib/python3.7/site-packages/airflow\n    ```\n\n-   添加环境变量\n\n    `vi ~/.bash_profile`\n\n    ```sh\n    # User specific environment and startup programs\n    AIRFLOW_HOME=/home/airflow\n    SITE_AIRFLOW_HOME=/usr/local/python3/lib/python3.7/site-packages/airflow\n    PYTHON3=/usr/local/python3\n    \n    PATH=$PATH:$HOME/bin:$SITE_AIRFLOW_HOME/bin:$PYTHON3/bin\n    \n    export AIRFLOW_HOME\n    export SITE_AIRFLOW_HOME\n    export PATH\n    export C_FORCE_ROOT=true \n    ```\n\n    使修改后的使环境变量生效：`sudo source /etc/profile`\n\n### Airflow 相关操作\n\n-   执行 `airflow` 命令做初始化操作\n\n    ```sh\n    airflow\n    ```\n\n    airflow 会在刚刚的 `AIRFLOW_HOME` 目录下生成一些文件。当然，执行该命令时可能会报一些错误，可以不用理会！生成的文件列表如下所示：\n\n    ```sh\n    [root@n71 airflow]# ls\n    airflow.cfg  logs  unittests.cfg\n    ```\n\n-   为 `airflow` 安装依赖模块\n\n    ```sh\n    pip install 'apache-airflow[postgres,celery,hive,rabbitmq]'\n    ```\n\n    airflow 的包依赖安装均可采用该方式进行安装，具体可参考 [airflow 官方文档](https://link.juejin.im/?target=https%3A%2F%2Fairflow.apache.org%2Finstallation.html)\n\n### **遇到的坑以及解决方案**\n\n-   **为 `airflow` 安装 [rabbitmq] 依赖模块报错**\n\n    具体可以参看这个 `repositories` https://github.com/celery/librabbitmq\n\n    **解决方案：**\n\n    ```sh\n    git clone https://github.com/celery/librabbitmq.git\n    \n    cd librabbitmq\n    \n    checkout 1.6\n    \n    yum install install autoconf automake libtool\n    \n    make install\n    \n    # 在安装依赖模块\n    pip install 'apache-airflow[rabbitmq]'\n    ```\n\n-   **启动 webserver 组件时报错**\n\n    错位如下：\n\n    ```sh\n    Error: 'python:airflow.www.gunicorn_config' doesn‘t exist\n    ```\n\n    或者是：\n\n    ```sh\n    FileNotFoundError: [Errno 2] No such file or directory: 'gunicorn': 'gunicorn'\n    ```\n\n    **解决方案：**\n\n    ```sh\n    # 1 :  添加软连接\n    ln -s /usr/local/python3/bin/gunicorn /usr/bin/gunicorn\n    \n    # 2  :  添加 python 环境变量\n    PYTHON3=/usr/local/python3\n    PATH=$PATH:$HOME/bin:$SITE_AIRFLOW_HOME/bin:$PYTHON3/bin\n    ```\n\n-   **`airflow worker` 角色不能使用 root 启动**\n\n    ==原因：不能用根用户启动的根本原因，在于 airflow 的 worker 直接用的 celery，而 celery 源码中有参数默认不能使用 ROOT 启动，否则将报错：==\n\n    ```sh\n        C_FORCE_ROOT = os.environ.get('C_FORCE_ROOT', False)\n    \n        ROOT_DISALLOWED = \"\"\"\\\n        Running a worker with superuser privileges when the\n        worker accepts messages serialized with pickle is a very bad idea!\n    \n        If you really want to continue then you have to set the C_FORCE_ROOT\n        environment variable (but please think about this before you do).\n    \n        User information: uid={uid} euid={euid} gid={gid} egid={egid}\n        \"\"\"\n    \n        ROOT_DISCOURAGED = \"\"\"\\\n        You're running the worker with superuser privileges: this is\n        absolutely not recommended!\n    \n        Please specify a different user using the --uid option.\n    \n        User information: uid={uid} euid={euid} gid={gid} egid={egid}\n        \"\"\"\n    ```\n\n    **解决方案：**\n\n    ```sh\n    # 设置环境变量,  强制celery worker运行采用root模式\n     export C_FORCE_ROOT=True\n    ```\n\n-   **`airflow remote worker log hostname` 问题**\n\n    当 worker 节点不是跟 webserver 部署在同一台机器的时候，有时从 webserver 查看该 worker 节点日志，出现如下错误：\n\n    ```go\n    *** Log file isn't local.\n    *** Fetching here: http://n73:8793/log/.../1.log\n    *** Failed to fetch log file from worker. HTTPConnectionPool(host='kaimanas.serveriai.lt', port=8793): Max retries exceeded with url: /log/.../1.log (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f64da2fab38>: Failed to establish a new connection: [Errno 111] Connection refused',))\n    ```\n\n    n73 (或是其他) 不是 webserver 节点所在的 hostname\n\n    **解决方案：**\n\n    配置 worker 节点的 `/etc/hosts` 的 hostname 映射，把 worker 节点的 ip 映射为本机的 hostname，如下：\n\n    ```sh\n    192.168.50.71 n71\n    192.168.50.72 n72\n    192.168.50.73 n73\n    ```\n\n## 配置 airflow.cfg\n\n-   修改 Executor 为 CeleryExecutor\n\n    ```\n    executor = CeleryExecutor\n    ```\n\n-   指定元数据库（metestore)\n\n    ```go\n    sql_alchemy_conn = postgresql+psycopg2://postgres:postgres@192.168.50.73:5432/airflow\n    ```\n\n-   设置中间人（broker)\n\n    ```go\n    broker_url = amqp://admin:datatom.com@192.168.50.73:5672/\n    ```\n\n-   设定结果存储后端 backend\n\n    ```go\n    celery_result_backend = db+postgres://postgres:postgres@192.168.50.73:5432/airflow\n    result_backend = db+postgres://stork:stork@192.168.50.73:14103/airflow\n    ```\n\n-   置 dags 初始化后为暂停状态(启动状态)\n\n    ```go\n    dags_are_paused_at_creation = True(False)\n    ```\n\n-   不引用实例脚本\n\n    ```go\n    load_examples = False\n    ```\n\n-   当定义的 dag 文件过多的时候，airflow 的 scheduler 节点运行效率缓慢\n\n    ```go\n    [scheduler]\n    # The scheduler can run multiple threads in parallel to schedule dags.\n    # This defines how many threads will run.\n    #默认是2这里改为50\n    max_threads = 30\n    \n    worker_concurrency = 5\n    worker_max_tasks_per_child = 10\n    ```\n\n-   修改检测新 DAG 间隔，如果 scheduler 检测 DAG 过于频繁，会导致 CPU 负载非常高。而默认 scheduler 检测时间为 0，也就是没有时间间隔\n\n    ```go\n    min_file_process_interval = 5\n    ```\n\n-   定期刷新 DAG 定义目录中的文件列表，默认300s\n\n    ```go\n    dag_dir_list_interval = 10\n    ```\n\n-   Airflow 的 DAG 并行度控制\n\n    `dag_concurrency`：表示一个 DAG，在同一时间点最大可以运行多少个 Task\n    `max_active_runs_per_dag`：表示一个 DAG，在同一时间点最多可以被运行几个\n\n    ```go\n    # 默认值都为16\n    dag_concurrency = 16\n    max_active_runs_per_dag = 16\n    ```","tags":["Python","Airflow"],"categories":["折腾不止"]},{"title":"GFS 一致性模型","path":"/2019/gfs-consistency.html","content":"前言quote, 最近，部门内部组织了学习活动，前两课就是研读著名的可扩展分布式文件系统 GFS 论文，并布置了学习作业，就是整理 GFS 中提出的一致性模型，如下文：一致性背景分布式存储系统中，不管是文件系统还是数据库，只要数据存在多个副本，都涉及一致性问题。其中一致性包括内部一致性和副本一致性，内部一致性即单机版数据库中的数据满足一定的约束条件。副本一致性表示同一数据的多个副本的值相同。GFS 作为一种分布式文件系统，采用了多副本机制，自然也会有一致性问题一致性模型具体操作**修改操作：** 包括写操作和追加操作，写操作需要指定文件块 + offset。追加操作成功后系统会将追加成功的偏移量返回给客户端。**并发写：** 如果两个客户端同时写同一个文件块的同一偏移量，那么就有个先后顺序问题，如果接近同时，系统不保证这个顺序。那么客户端再去读，就不一定能读到自己刚写的数据。**追加失败：** 追加操作会保证至少成功一次。追加操作时，假设配置三副本，但是只有两个副本写成功，最后一个副本超时了（可能对应块服务器宕机，当然重启后 GFS 会用 chunk version 来标记其过期 stale 了，从而跳过该 offset。），那么追加操作会重试，并且失败数据不会删除，但是 GFS 有对齐操作，即重试成功后，三个副本中该追加数据的起始偏移量是定义的（也就是一致的），那么其中那个上次失败的副本就会有个空洞，系统会用特殊字符填充。 {% note info, 结论：定义未定义针对的是多客户端并发写同一个偏移量的覆盖顺序问题；一致不一致针对的是多个副本相同偏移量的内容是否相同 %}概念解析**已定义（defined）**：客户端写某个偏移量后，再读，读到的一定是自己的。**未定义的但是一致的（undefined but consistent）**：多个客户端并发写同一个偏移量，不确定谁会覆盖谁（这个顺序由 Primary Replica 所在 Chunkserver 来安排，后面将会讲），即写完后再读，不确定是自己写的还是其他人写的。但是保证最终一致性，即并发写完成后，最后几个副本是一致的。**不一致的（inconsistent）**：即修改操作后，所有副本同一偏移量的数据并不完全相同。","tags":["分布式"],"categories":["解决方案"]},{"title":"go pprof 性能分析","path":"/2019/go-pprof-analysis.html","content":"起因color:warning 线上运行的基础平台文件管理服务进程出现内存泄露的现象 下图是 `grafana` 针对该服务的监控指标情况，可以发现服务刚起时，内存使用量为 **20M** 左右，经过操作后，内存会稳定在 **300M** 左右，不会持续上升，也不会下降，一开始找不到原因，所以尝试使用一下 golang pprof 性能分析工具分析一下程序到底哪出问题了添加 pprof 模块现在最新版本的 go tool 分析工具已经很人性化了，pprof 采样数据主要有三种获取方式:- **runtime/pprof**: 手动调用`runtime.StartCPUProfile`或者`runtime.StopCPUProfile`等 API 来生成和写入采样文件，灵活性高，适用于`应用程序`- **net/http/pprof**: 通过 http 服务获取 Profile 采样文件，简单易用，适用于对应用程序的整体监控，通过 runtime/pprof 实现，适用于`web服务程序、服务进程`- **go test**: 通过 `go test -bench . -cpuprofile prof.cpu`生成采样文件 适用对函数进行针对性测试 其实 net/http/pprof 中只是使用 runtime/pprof 包来进行封装了一下，并在 http 端口上暴露出来，让我们可以在浏览器查看程序的性能分析。可以自行查看 net/http/pprof 中代码，只有一个文件 pprof.go。以上获取方式就不详细演示了，毕竟着重于解决当下问题，由于所要分析的服务程序依赖于 `gin web 框架` ，因此要在 `gin` 中集成 pprof；**Example：**```gopackage mainimport (\t\"github.com/gin-contrib/pprof\"  // step 1\t\"github.com/gin-gonic/gin\")func main() { router := gin.Default() pprof.Register(router) // step 2 router.Run(\":8080\")}```分析启动程序，通过服务端口即可访问 pprof 的数据查看当前总览：访问 `http://$HOSTIP:$PORT/debug/pprof````cpu（CPU Profiling）: $HOST/debug/pprof/profile，默认进行 30s 的 CPU Profiling，得到一个分析用的 profile 文件block（Block Profiling）：$HOST/debug/pprof/block，查看导致阻塞同步的堆栈跟踪goroutine：$HOST/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪heap（Memory Profiling）: $HOST/debug/pprof/heap，查看活动对象的内存分配情况mutex（Mutex Profiling）：$HOST/debug/pprof/mutex，查看导致互斥锁的竞争持有者的堆栈跟踪threadcreate：$HOST/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪```这里，我更多的是做程序的内存分析，并通过交互式终端使用；在 terminal 中使用 `go tool pprof http://$HOSTIP:$PORT/debug/pprof/heap` 可以进入 pprof 分析工具，比如输入 `top` 可以显示靠前的几项，go tool pprof 可以带上参数 `-inuse_space` (分析应用程序的常驻内存占用情况) 或者 `-alloc_space` (分析应用程序的内存临时分配情况)现在 go tool 可以直接可视化结果，只需要带上 `-http=:8081` 参数即可，如：```sh$ go tool pprof -http=:8081 http://$HOSTIP:$PORT/debug/pprof/heap```之后就会在浏览器弹出 `http://$HOSTIP:8081/ui`，里面包含程序内存分析的 dot 格式的图、火焰图、top 列表、source 列表等，如下：优化内存消耗停滞在一个值时，比如上述问题描述，其实不用称之为内存泄漏，而是不主动 GC，需要主动释放内存；导致这个问题的原因是由于上传文件时，采用 `multipart/form-data` 传输数据，`r.FormFile(\"file\")` 将导致调用Request.ParseMultipartForm()，并将32 MB用作maxMemory参数的值，创建 32M 的缓冲区；由于`bytes.Buffer` 用于读取内容，因此读取过程将从一个小的或空的缓冲区开始，并在需要更大的时候重新分配；有关详细信息，请参阅 **multipart.Reader.ReadFrom()** 的实现。```gor.ParseMultipartForm(32 << 20) // 32 MBfile, _, err := r.FormFile(\"file\")// ... rest of your handler``` 详细描述可以参考 **stackoverflow** 上的回答，Multipart form uploads + memory leaks in golang?这里优化的方案是在 `request`请求的 `body` 中只放文件数据，其余信息放到 `header` 中，这样就不需要使用 MultipartForm 去解析数据；```gofile = r.Body// ... rest of your handler```可以看到传输完成后，内存占用恢复到了服务初始的状态值参考Golang 大杀器之性能剖析 PProfMultipart form uploads + memory leaks in golang?","tags":["Go"],"categories":["设计开发"]},{"title":"Opeartor-SDK 简单上手","path":"/2019/operator-sdk-use.html","content":"## 前言\n\n>   本篇介绍了CoreOS（已被红帽收购）的开源项目 [Operator-SDK](https://github.com/operator-framework/operator-sdk) 的基本使用。该项目是 `Operator Framework` 的一个组件，它是一个开源工具包，以有效，自动化和可扩展的方式管理称为 `Operators` 的Kubernetes原生应用程序\n\n### 概述\n\n[Operators](https://coreos.com/operators/) 可以在Kubernetes之上轻松地管理复杂有状态的应用程序。然而，由于诸如使用低级API，编写样板以及缺乏模块导致重复性工作等挑战，导致目前编写Operator可能很困难\n\nOperator SDK是一个框架，旨在简化Operator的编写，它提供如下功能：\n\n-   高级API和抽象，更直观地编写操作逻辑\n-   用于脚手架和代码生成的工具，可以快速引导新项目\n-   扩展以涵盖常见的操作员用例\n\n## 工作流程\n\nSDK提供以下工作流程来开发新的Operator：\n\n1.  使用SDK命令行界面（CLI）创建新的Operator项目\n2.  通过添加自定义资源定义（CRD）定义新资源API\n3.  使用SDK API监控指定的资源\n4.  在指定的处理程序中定义Operator协调逻辑(对比期望状态与实际状态)，并使用SDK API与资源进行交互\n5.  使用SDK CLI构建并生成Operator部署manifests\n\nOperator使用SDK在用户自定义的处理程序中以高级API处理监视资源的事件，并采取措施来reconcile（对比期望状态与实际状态）应用程序的状态\n\n## 快速开始\n\n### 安装 Operator-SDK CLI\n\n```bash\n$ mkdir -p $GOPATH/src/github.com/operator-framework\n$ cd $GOPATH/src/github.com/operator-framework\n$ git clone https://github.com/operator-framework/operator-sdk\n$ cd operator-sdk\n$ git checkout master\n$ make dep\n$ make install\n```\n\n**注：**这里可知，`Operator-SDK` 默认采用 `dep` 作为包管理方式，但 `dep` 当前的执行效率的确不高，如果你的 project 依赖的外部包很多，那么等待的时间可能会很长。并且由于 dep 会下载依赖包，一旦下载 qiang 外的包，那么 dep 可能会 “阻塞” 在那里！因此这里可以选择自己拉包后 `go install`\n\n### 创建 app-operator\n\n```bash\n# 创建一个定义 App 用户资源的 app-operator 项目\n$ mkdir -p $GOPATH/src/github.com/<GitHub_ID>\n\n# 创建 app-operator 项目\n$ cd $GOPATH/src/github.com/<GitHub_ID>\n$ operator-sdk new app-operator  \n$ cd app-operator\n\n# 为AppService用户资源添加一个新的 API\n$ operator-sdk add api --api-version=app.example.com/v1alpha1 --kind=AppService\n# Required: --kind - 是 CRD 要定義的 kind\n# Required: --api-version - 是CRD 想定义的 group/version。\n\n# 添加一个新的控制器来监控 AppService\n$ operator-sdk add controller --api-version=app.example.com/v1alpha1 --kind=AppService\n\n# 构建并推送 app-operator 镜像到一个公开的 registry\n# 这里 build 镜像，使用的基础镜像，由于不可描述的原因，非常耗时\n# 可替换为 ： FROM docker.io/ericnie2017/helm-operator:latest\n$ operator-sdk build app-operator:v0.1.0\n$ docker push \n\n# 更新 operator manifest 来使用新构建的镜像\n$ sed -i 's|REPLACE_IMAGE|app-operator:v0.1.0|g' deploy/operator.yaml\n```\n\n**注：**这里采用 `operator-sdk new ` 创建 app-operator 时，会自动生成 `Gopkg.toml` 并使用 `dep` 下载依赖包，最好挂代理，不然非常耗时，也可以直接跳过，自己拉包编译\n\n### 创建 app-operator for Helm\n\n```bash\n# 其他步骤都一样\n# 只是再创建 app-operator 时，增加 --type=helm，并且再创建 helm 类型的 operator 时，可以直接 add api 和 kind\n$ operator-sdk new <project-name> --type=helm --kind=<kind> --api-version=<group/version> \n\n# 例如\n$ operator-sdk new app-operator api --api-version=app.example.com/v1alpha1 --kind=AppService --type=helm\n```\n\n### 部署 app-operator\n\n上述两种创建方式，都会自动生成 `/deploy` 文件夹，其中包含一组可以 deploy 到 K8s cluser 上的 resource files；\n\n-   **deploy/service_account.yaml**: 建立一个该自定义 operator 名称的 ServiceAccount\n-   **deploy/role.yaml**: 建立一个 role 定义它能存取 K8s cluster 的规则\n-   **deploy/role_binding.yaml**: 把上面的 ServiceAccount 和 Role 绑定起来，使该 ServiceAccount 拥有这个 Role 定义的存取 rule\n-   **deploy/operator.yaml**: 是 deploy operator 到 K8s cluster 上的 deployment，使用的 ServiceAccount 是我们 `deploy/service_account.yaml` 定义的名称\n-   **deploy/crds/GROUP_VERSION_CRDNAME_crd.yaml**: 就是我們自己定义 resource type，More detail: [Extend the Kubernetes API with CustomResourceDefinitions](https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/)\n-   **deploy/crds/GROUP_VERSION_CRDNAME_cr.yaml**: 是我们要 deploy 自定义的 resource，CR 代表 Custom Resource ，More detail: [Create custom objects](https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/#create-custom-objects) ，该文件中的 spec 就是完全复制 `helm-charts` 下的 values.yaml，所以原本用 helm 怎么定义 values.yaml 中的值，该文件中就怎么写\n\n```bash\n# 建立Service Account\n$ kubectl create -f deploy/service_account.yaml\n\n# 建立RBAC\n$ kubectl create -f deploy/role.yaml\n$ kubectl create -f deploy/role_binding.yaml\n\n# 建立CRD\n$ kubectl create -f deploy/crds/app_v1alpha1_appservice_crd.yaml\n\n# 部署app-operator\n# 这里部署时，由于自动生成的 operator.yaml 文件中的 拉取镜像，默认为 imagePullPolicy: Always ；到镜像仓库拉取\n# 我一般镜像打包到本地，所以替换为  imagePullPolicy: IfNotPresent ；本地有，就不到镜像仓库拉取\n$ kubectl create -f deploy/operator.yaml\n\n# 创建一个AppService用户资源\n# 默认控制器将监视AppService对象并为每一个CR创建一个pod\n$ kubectl create -f deploy/crds/app_v1alpha1_appservice_cr.yaml\n\n# 验证pod是否创建\n$ kubectl get pod -l app=example-appservice\nNAME                     READY     STATUS    RESTARTS   AGE\nexample-appservice-pod   1/1       Running   0          1m\n```\n\n## 最后\n\n这样通过 `operator-framework/operator-sdk ` 要完成自己的 CRD 和 operator 真的很快速和方便，可以预见，如果是开发或运维人员，在了解需求后，可以不用写很多的 operator 复杂和繁琐的重复程序，就可以快速开发和部署 operator ，且后续一样可以很方便的使用 K8s 的 API 资源；不过，是否要使用 `operator-framework/operator-sdk` ，一切还是需要自行的评估和结合当前应用服务的体量来看是否适合使用，小心服用。","tags":["Cloud Navite","Kubernetes"],"categories":["技术加油站"]},{"title":"Select -- 无阻塞读写 channel","path":"/2019/go-channel-select.html","content":"## 通道阻塞\n\n在之前的 [**Go 的并发模型**](https://leeif.me/2019/01/go-concurrent-model.html) 可以了解到，FAN 流水模型可以多个 Goroutine 读一个 Channel 中的数据(FAN-OUT)，或者多个 Chanel 将数据发送到一个 Goroutine 中接收(FAN-IN)，**但是无论是无缓冲通道，还是有缓冲通道，都存在阻塞的情况**\n\n### 无缓冲通道\n\n> 特点：发送的数据需要被读取后，发送才会完成\n\n**阻塞场景：**\n\n- 通道中无数据，但执行都通道\n- 通道中无数据，向通道中写数据，但无其他协程读取该通道中的数据\n\n**代码示例：**\n\n```go\n// 场景 1\nfunc ReadNoDataFromNoBufCh(){\n    noBufCh := make(chan int)\n    // 通道中无数据\n    <- noBufCh\n    fmt.Println(\"read from no buffer channel success\")\n\n    // Output:\n    // fatal error: all goroutines are asleep - deadlock!\n}\n\n// 场景 2\nfunc WriteNoBufCh(){\n    ch := make(chan int)\n    ch <- 1\n    fmt.Println(\"write success no block\")\n\n    // Output:\n    // fatal error: all goroutines are asleep - deadlock!\n}\n```\n\n### 有缓冲通道\n\n> 特点：有缓存时可以向通道中写入数据后直接返回，缓存中有数据时可以从通道中读到数据直接返回，这时有缓存通道是不会阻塞的\n\n**阻塞场景：**\n\n- 通道的缓存无数据，但执行读通道\n- 通道的缓存已经占满，向通道写数据，但无协程读\n\n**代码示例：**\n\n```go\n// 场景 1\nfunc ReadNoDataFromBufCh(){\n    bufCh := make(chan int, 1)\n    // 通道中无数据\n    <- bufCh\n    fmt.Println(\"read from no buffer channel success\")\n\n    // Output:\n    // fatal error: all goroutines are asleep - deadlock!\n}\n\n// 场景 2\nfunc WriteBufChButFull(){\n    ch := make(chan int, 1)\n    // 写数据，占满缓冲\n    ch <- 1\n    \n    // 无协程读取缓冲中的数据，继续写，阻塞\n    ch <- 2\n    fmt.Println(\"write success no block\")\n\n    // Output:\n    // fatal error: all goroutines are asleep - deadlock!\n}\n```\n\n## Select 功能\n\n**Select** 由关键字 `select` 和 `case` 组成，`default` 不是必须的，如果没其他事可做，可以省略 `default`，**在多个通道上进行读或写操作，让函数可以处理多个事情，但 1 次只处理 1 个**，有以下特性：\n\n- 每次执行 `select`，都会只执行其中 1 个 `case` 或者执行 `default` 语句\n- 当没有 case 或者 default 可以执行时，select 则阻塞，等待直到有 1 个 case 可以执行\n- 当有多个 case 可以执行时，则随机选择 1 个 case 执行\n- case 后面跟的必须是读或者写通道的操作，否则编译出错","tags":["Go"],"categories":["设计开发"]},{"title":"Kuberntes 创建 LoadBalancer 类型服务","path":"/2019/k8s-deploy-metallb-LoadBalancer.html","content":"## 前言\n\n> 我们知道，Service 机制，以及 Kubernetes 里的 DNS 插件，都是在帮助我们解决同样一个问题，即：如何找到某一个容器；而 Service 是由 kube-proxy 组件，加上 iptables 来共同实现的；所谓 Service 的访问入口，其实就是每台宿主机上由 kube-proxy 生成的 iptables 规则，以及 kube-dns 生成的 DNS 记录。而一旦离开了这个集群，这些信息对用户来说，也就自然没有作用了\n\n在使用 Kubernetes 的 Service 时，一个必须要面对和解决的问题就是：**如何从外部（Kubernetes 集群之外），访问到 Kubernetes 里创建的 Service？**\n\n## 从外界连通 Service\n\n### 三种方式\n\n- NodePort\n- ExternalIP\n- LoadBalance\n\n这里 `NodePort` 和 `externalIPs` 是 K8S 集群本身就支持的特性，这两个方案让很多私有云用户成为了 K8S 世界中的二等公民，而 `NodePort` 也是我们最常用的；\n\n而 kubernetes  没有为裸机群集提供网络负载均衡器（类型为 `LoadBalancer` 的服务）的实现，如果你的 K8S 集群没有在公有云的 IaaS 平台（GCP，AWS，Azure …）上运行，则 LoadBalancers 将在创建时无限期地保持 “挂起” 状态，也就是说只有公有云厂商自家的 kubernetes 支持 LoadBalancer，对 LoadBalancer 类型的服务的支持应该是众多表面差异中最醒目的一个了\n\n### 纯软件解决方案: MetalLB\n\n> 该项目发布于 2017 年底，当前处于 Beta 阶段，旨在解决上述中的不平衡，通过提供与标准网络设备集成的网络 LB 实现来纠正这种不平衡，以便裸机集群上的外部服务也 “尽可能” 地工作；即 MetalLB 能够帮助你在 kubernetes 中创建 LoadBalancer 类型的 kubernetes 服务\n>\n> 项目地址：https://github.com/google/metallb\n>\n> 版本说明：https://metallb.universe.tf/release-notes/\n\n`Metallb` 会在 Kubernetes 内运行，监控服务对象的变化，一旦察觉有新的 LoadBalancer 服务运行，并且没有可申请的负载均衡器之后，就会完成两部分的工作：\n\n- **地址分配**\n\n  用户需要在配置中提供一个地址池，Metallb 将会在其中选取地址分配给服务。\n\n- **地址广播**\n\n  根据不同配置，Metallb 会以二层（ARP/NDP）或者 BGP 的方式进行地址的广播\n\n![基本原理图](https://leeifme.oss-cn-shanghai.aliyuncs.com/blog/2019/metallb.jpg )\n\n## 安装部署演示\n\n### 部署 Metallb 负载均衡器\n\nMetallb 支持 Helm 和 YAML 两种安装方法(这里推荐第二种)\n\n- Helm\n\n  ```sh\n  $ helm install --name metallb stable/metallb\n  ```\n\n- YAML\n\n  ```bash\n  $ kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yaml\n  ```\n\n很简单，`Metallb` 就会开始安装，会生成自己的命名空间以及 RBAC 配置\n\n```sh\n[root@lee ~]# kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yaml\nnamespace/metallb-system created\nserviceaccount/controller created\nserviceaccount/speaker created\nclusterrole.rbac.authorization.k8s.io/metallb-system:controller created\nclusterrole.rbac.authorization.k8s.io/metallb-system:speaker created\nrole.rbac.authorization.k8s.io/config-watcher created\nclusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created\nclusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created\nrolebinding.rbac.authorization.k8s.io/config-watcher created\ndaemonset.apps/speaker created\ndeployment.apps/controller created\n\n[root@lee ~]# kubectl get pods -n metallb-system -owide\nNAME                                             READY   STATUS  RESTARTS   AGE   IP               NODE   NOMINATED NODE\ncontroller-765899887-bdwdk   1/1     Running   0          82s   10.0.0.22                lee    <none>\nspeaker-qldl6                                  1/1     Running   0          82s   192.168.50.124   lee    <none>\n```\n\n目前还没有宣布任何内容，因为我们没有提供 ConfigMap，也没有提供负载均衡地址的服务；\n接下来我们要生成一个 ConfigMap文件，为 Metallb 设置网址范围以及协议相关的选择和配置\n\n### 提供 IP pool\n\n通过之前提到的原理图可知，需要创建一个 `ConfigMap` 文件，以提供 `IP 池`；\n\n```sh\n$ wget https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/example-layer2-config.yaml\n```\n\n**修改 ip 地址池和集群节点网段相同，且必须为一个 IP 区间**\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: my-ip-space\n      protocol: layer2\n      addresses:\n      # 与集群节点网段相同\n      - 192.168.50.211-192.168.50.220  \n```\n\n**IP 地址为 `无占用` **\n\n```bash\n[root@lee ~]# ping 192.168.50.211\nPING 192.168.50.211 (192.168.50.211) 56(84) bytes of data.\nFrom 192.168.50.124 icmp_seq=1 Destination Host Unreachable\nFrom 192.168.50.124 icmp_seq=2 Destination Host Unreachable\nFrom 192.168.50.124 icmp_seq=3 Destination Host Unreachable\nFrom 192.168.50.124 icmp_seq=4 Destination Host Unreachable\n^C\n--- 192.168.50.211 ping statistics ---\n5 packets transmitted, 0 received, +4 errors, 100% packet loss, time 4001ms\n```\n\n部署 `example-layer2-config.yaml` 文件\n\n```sh\n$ kubectl apply -f example-layer2-config.yaml\n```\n\n### 部署应用服务测试\n\n```sh\n$ wget https://raw.githubusercontent.com/google/metallb/master/manifests/tutorial-2.yaml\n$ kubectl apply -f tutorial-2.yaml\n```\n\n查看 yaml 文件配置，包含了一个 deployment 和一个 LoadBalancer 类型的 service，默认即可；\n\n**查看 service 分配的 EXTERNAL-IP**\n\n```bash\n[root@lee ~]# kubectl get svc -owide\nNAME               TYPE             CLUSTER-IP     EXTERNAL-IP         PORT(S)                 AGE   SELECTOR\nnginx           LoadBalancer   10.0.228.36      192.168.50.211     80:31796/TCP        65s   app=nginx\n```\n\nping 该 ` EXTERNAL-IP` 地址，发现该地址可以访问了\n\n```sh\n[root@lee ~]# ping 192.168.50.211\nPING 192.168.50.211 (192.168.50.211) 56(84) bytes of data.\n64 bytes from 192.168.50.211: icmp_seq=1 ttl=64 time=0.050 ms\n64 bytes from 192.168.50.211: icmp_seq=2 ttl=64 time=0.082 ms\n64 bytes from 192.168.50.211: icmp_seq=3 ttl=64 time=0.068 ms\n```\n\n集群内访问该 ` EXTERNAL-IP` 地址\n\n```bash\n[root@lee ~]# curl 192.168.50.211\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n...............\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n```\n\n从集群外访问该 IP 地址\n\n```bash\nAdministrator at 16:47:09 / $ curl 192.168.50.211\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   612  100   612    0     0   597k      0 --:--:-- --:--:-- --:--:--  597k<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n................\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n```\n\n另外使用 `Node IP + NodePort` 也可以访问\n\n```bash\nAdministrator at 16:47:09 / $ curl 192.168.50.124:31796\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   612  100   612    0     0   597k      0 --:--:-- --:--:-- --:--:--  597k<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n................\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n```","tags":["Cloud Navite","Kubernetes"],"categories":["解决方案"]},{"title":"Go 并发模型","path":"/2019/go-concurrent-model.html","content":"## 前言\n\n> Go 语言是为并发而生的语言，Go 语言是为数不多的在语言层面实现并发的语言；也正是 Go 语言的并发特性，吸引了全球无数的开发者\n\n## 并发 (concurrency) 和并行(parallellism)\n\n在了解 **Go** 的并发原理之前，先了解什么是并发什么是并行；\n\n- 并发 **( concurrency )**\n\n  两个或两个以上的任务在一段时间内被执行。我们不必 care 这些任务在某一个时间点是否是同时执行，可能同时执行，也可能不是，我们只关心在一段时间内，哪怕是很短的时间（一秒或者两秒）是否执行解决了两个或两个以上任务\n\n- 并行  **( parallellism )**\n\n  两个或两个以上的任务在同一时刻被同时执行\n\n并发说的是逻辑上的概念，而并行，强调的是物理运行状态；并发 “包含” 并行；( 详情请见：**Rob Pike** 的 [PPT](https://talks.golang.org/2012/concurrency.slide#1))\n\n## CSP 并发模型\n\nGo 实现了两种并发形式。第一种是大家普遍认知的：多线程共享内存。其实就是 Java 或者 C++ 等语言中的多线程开发。另外一种是 Go 语言特有的，也是 Go 语言推荐的：`CSP`（communicating sequential processes）并发模型\n\n请记住下面这句话：\n\n> **Do not communicate by sharing memory; instead, share memory by communicating.**\n> “不要以共享内存的方式来通信，相反，要通过通信来共享内存”\n\n普通的线程并发模型，就是像 Java、C++、或者 Python，他们线程间通信都是通过共享内存的方式来进行的。非常典型的方式就是，在访问共享数据（例如数组、Map、或者某个结构体或对象）的时候，通过锁来访问，因此，在很多时候，衍生出一种方便操作的数据结构，叫做 “线程安全的数据结构”\n\nGo 的 CSP 并发模型，是通过`goroutine`和`channel`来实现的。\n\n- `goroutine:` 是 Go 语言中并发的执行单位，有点抽象，其实就是和传统概念上的`线程 `类似，但它比线程更为轻量，称之为`协程`\n- `channel：` 是 Go 语言中各个并发结构体 (`goroutine`) 之前的通信机制。 通俗的讲，就是各个`goroutine`之间通信的” 管道 “，有点类似于 Linux 中的管道\n\n创建一个 `goroutine` 很简单，只要使用 `go` 关键字就可以了，如下；\n\n```go\ngo func()\n```\n\n通信机制 `channel` 也很方便，传数据用 `channel <- data` ，取数据用 `<-channel`\n\n在通信过程中，传数据 `channel <- data` 和取数据 `<-channel` 必然会成对出现，因为这边传，那边取，两个`goroutine`之间才会实现通信，而且不管传还是取，必阻塞，直到另外的`goroutine`传或者取为止\n\n<img src=\"https://leeifme.oss-cn-shanghai.aliyuncs.com/blog/2019/go-cps.png\">\n\n这便是 `Golang CSP` 并发模型最基本的形式，本问内容不详细阐述并发原理\n\n## 并发模型的运用\n\n### 流水线模型\n\n>Golang 并发核心思路是关注数据流动。数据流动的过程交给 channel，数据处理的每个环节都交给 goroutine，把这些流程画起来，有始有终形成一条线，那就能构成流水线模型\n\n流水线并不是什么新奇的概念，它能极大的提高生产效率，在当代社会流水线非常普遍，我们用的几乎任何产品（手机、电脑、汽车、水杯），都是从流水线上生产出来的；**在 Golang 中，流水线由多个阶段组成，每个阶段之间通过 channel 连接，每个节点可以由多个同时运行的 goroutine 组成**\n\n![](https://leeifme.oss-cn-shanghai.aliyuncs.com/blog/2019/20190124110810.png)\n\n如上图，从最简单的流水线入手，由 3 个阶段组成，分别是 A、B、C；第一个阶段的协程是**生产者**，它们只生产数据，最后一个阶段的协程是**消费者**，A 是生成者，C 是消费者，而 B 只是中间过程的处理者；A 和 B 之间是通道`aCh`，B 和 C 之间是通道`bCh`，A 生成数据传递给 B，B 生成数据传递给 C\n\n> 举个例子，设计一个程序：计算一个整数切片中元素的平方值并把它打印出来。非并发的方式是使用 for 遍历整个切片，然后计算平方，打印结果\n\n我们使用流水线模型实现这个简单的功能，从流水线的角度，可以分为 3 个阶段：\n\n1. 遍历切片，这是生产者。\n2. 计算平方值。\n3. 打印结果，这是消费者。\n\n具体代码，参考 [**simple.go**](https://github.com/leeifme/Go-test/blob/master/go-concurrent/assembly-line/simple.go)\n\n- `producer()`负责生产数据，它会把数据写入通道，并把它写数据的通道返回\n- `square()`负责从某个通道读数字，然后计算平方，将结果写入通道，并把它的输出通道返回\n- `main()`负责启动 producer 和 square，并且还是消费者，读取 suqre 的结果，并打印出来\n\n**流水线的特点**\n\n1. 每个阶段把数据通过 channel 传递给下一个阶段\n2. 每个阶段要创建 1 个 goroutine 和 1 个通道，这个 goroutine 向里面写数据，函数要返回这个通道\n3. 有 1 个函数来组织流水线，我们例子中是 main 函数\n\n### 流水线 FAN 模式\n\n> 流水线模型进阶，FAN-IN 和 FAN-OUT 模式，FAN 模式可以让我们的流水线模型更好的利用 Golang 并发，提高软件性能\n\n这里还是以生产汽车的流水线为例，汽车生产线上有个阶段是给小汽车装 4 个轮子，可以把这个阶段任务交给 4 个人同时去做，这 4 个人把轮子都装完后，再把汽车移动到生产线下一个阶段；这个过程中，就有任务的分发，和任务结果的收集；**其中任务分发是 FAN-OUT，任务收集是 FAN-IN**\n\n- **FAN-OUT 模式：多个 goroutine 从同一个通道读取数据，直到该通道关闭；**OUT 是一种张开的模式，所以又被称为扇出，可以用来分发任务\n- **FAN-IN 模式：1 个 goroutine 从多个通道读取数据，直到这些通道关闭；**IN 是一种收敛的模式，所以又被称为扇入，用来收集处理的结果\n\n如下图所示，\n\n![](https://leeifme.oss-cn-shanghai.aliyuncs.com/blog/2019/20190124112954.png)\n\n依然延用上面的案例需求，计算一个整数切片中元素的平方值并把它打印出来，这次我们修改一下，添加 `merge()` 方法，具体代码参考 [**fan.go**](https://github.com/leeifme/Go-test/blob/master/go-concurrent/assembly-line/fan.go)\n\n- `producer()`保持不变，负责生产数据\n- `squre()`也不变，负责计算平方值\n- 修改`main()`，启动 3 个 square，这 3 个 squre 从 producer 生成的通道读数据，**这是 FAN-OUT**\n- 增加`merge()`，入参是 3 个 square 各自写数据的通道，给这 3 个通道分别启动 1 个协程，把数据写入到自己创建的通道，并返回该通道，**这是 FAN-IN**","tags":["Go"],"categories":["设计开发"]},{"title":"简化 Kubernetes 应用部署工具 -- Helm","path":"/2018/k8s-deploy-tool-helm.html","content":"### 先区分下概念\n\n- **`Docker`**: 镜像是把一个单纯的 App 和它的安装环境整合在一起。\n- **`Kubertnetes`**: 管理 Docker 容器的生成和毁灭，保证 Docker 容器对应 App 的高可用（监控、自动创建）和易维护（部署和对外暴露、动态扩容、启动停止删除等）。\n- **`Helm`**: 是为了方便配置和部署、升级和回滚应用，尤其是多个 Service 组合创建的一个大型应用，比如网站\n\n### 为什么要用？\n\n> 首先在原来项目中都是基于 yaml 文件来进行部署发布的，而目前项目大部分微服务化或者模块化，会分成很多个组件来部署，每个组件可能对应一个 deployment.yaml, 一个 service.yaml, 一个 Ingress.yaml 还可能存在各种依赖关系，这样一个项目如果有 5 个组件，很可能就有 15 个不同的 yaml 文件，这些 yaml 分散存放，如果某天进行项目恢复的话，很难知道部署顺序，依赖关系等，而所有这些包括\n>\n> - 基于 yaml 配置的集中存放\n> - 基于项目的打包\n> - 组件间的依赖\n>\n> 都可以通过 helm 来进行解决\n\n \n\n### Helm 基本概念\n\n> Helm 可以理解为 Kubernetes 的包管理工具，可以方便地发现、共享和使用为 Kubernetes 构建的应用，它包含几个基本概念\n>\n> - Chart：一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义\n> - Release: 在 Kubernetes 集群上运行的 Chart 的一个实例。在同一个集群上，一个 Chart 可以安装很多次每次安装都会创建一个新的 release。例如一个 MySQL Chart，如果想在服务器上运行两个数据库，就可以把这个 Chart 安装两次。每次安装都会生成自己的 Release，会有自己的 Release 名称\n> - Repository：用于发布和存储 Chart 的仓库\n\n#### 要点\n\n- Helm 是一个 Chart 管理器: [GitHub - kubernetes/helm: The Kubernetes Package Manager](https://github.com/kubernetes/helm)\n- Charts 是一组配置好的 Kubernetes 资源（定义）组合\n- Release 是一组已经部署到 Kubernetes 上的资源集合\n\n#### Chart 的基本结构\n\n```\n.\n├── Chart.yaml\n├── README.md\n├── templates\n│   ├── NOTES.txt\n│   ├── _helpers.tpl\n│   ├── deployment.yaml\n│   ├── pvc.yaml\n│   ├── secrets.yaml\n│   └── svc.yaml\n└── values.yaml\n```\n\n#### 用途\n\n1. 创建可配置的 Release\n2. 升级、删除、查看由 Helm 创建的 Release\n\n#### 组成\n\n1. **`Helm Client`** 客户端\n   - 制作、拉取、查找和验证 Chart\n   - 安装服务端 Tiller\n   - 指示服务端 Tiller 做事，比如根据 chart 创建一个 Release\n2. helm 服务端 **`tiller`**\n   安装在 Kubernetes 集群内的一个应用， 用来执行客户端发来的命令，管理 Release\n\n\n\n### Helm的安装\n\n#### `Helm Client` 安装\n\n下载 helm 的相关版本: https://github.com/kubernetes/helm/releases\n\n安装过程如下：\n\n1. 下载 Helm \n2. 解包：tar -zxvf helm-v2.11.0-linux-amd64.tgz\n3. helm 二进制文件移到 / usr/local/bin 目录\n\n#### `Helm Tiller ` 安装\n\n> 因为 Kubernetes APIServer 开启了 RBAC 访问控制，所以需要创建 tiller 使用的 service account: tiller 并分配合适的角色给它。这里简单起见直接分配 cluster-admin 这个集群内置的 ClusterRole 给它。创建 rbac-config.yaml 文件：\n\n```yaml\n# rbac-config.yaml\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: tiller\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: tiller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n  - kind: ServiceAccount\n    name: tiller\n    namespace: kube-system\n```\n\n接下来使用 helm 部署 tiller:\n\n```bash\nhelm init --service-account tiller --skip-refresh\n```\n\n如果直接执行部署语句，要链接 https://kubernetes-charts.storage.googleapis.com 去下载镜像；在国内这个地址不能直接访问，所以需要下载其他镜像；docker pull fengzos/tiller:v2.11.0 这个镜像是直接从 gcr.io/kubernetes-helm/tiller:v2.11.0 继承过来的，可以直接使用。\n\n```bash\ndocker pull fengzos/tiller\nhelm init --service-account tiller --upgrade -i fengzos/tiller:latest  --skip-refresh\n```\n\n#### 帮助文档\n\n1. `helm help` 查看 helm 支持的命令\n2. `helm somecommand -h` 查看某个命令的使用方法\n3. `helm version` 查看客户端和服务端的版本，如果只显示了客户端版本，说明没有连上服务端。 它会自动去 K8s 上 kube-system 命名空间下查找是否有 Tiller 的 Pod 在运行，除非你通过 `--tiller-namespace`标签 or `TILLER_NAMESPACE`环境变量指定\n\n### Helm的使用\n\n#### 使用 Chart\n\n- `helm search` 查找可用的 Charts\n- `helm inspect` 查看指定 Chart 的基本信息\n- `helm install` 根据指定的 Chart 部署一个 Release 到 K8s\n- `helm create` 创建自己的 Chart\n- `helm package` 打包 Chart，一般是一个压缩包文件\n\n#### 管理 Release\n\n- `helm list` 列出已经部署的 Release\n- `helm delete [RELEASE]` 删除一个 Release. 并没有物理删除， 出于审计需要，历史可查\n- `helm delete --purge [RELEASE]` 移除所有与指定 Release 相关的 K8s资源和所有这个 Release 的记录\n- `helm status [RELEASE]` 查看指定的 Release 信息，即使使用`helm delete`命令删除的 Release.\n- `helm upgrade` 升级某个 Release\n- `helm rollback [RELEASE] [REVISION]` 回滚 Release 到指定发布序列\n- `helm get values [RELEASE]` 查看 Release 的配置文件值\n\n#### 管理 Chart Repository\n\n- `helm repo list`\n- `helm repo add [RepoName] [RepoUrl]`\n- `helm repo update`","tags":["Cloud Navite","Kubernetes"],"categories":["技术加油站"]},{"title":"vscode + sftp 开发环境同步差异文件","path":"/2018/sftp-sync-project.html","content":"前言{% note radiation, 解决需求：本地是 win10 系统，代码需要在 linux 下跑，又不想装虚拟机或双系统；所以，项目用到连接远程测试服务器进行开发联调，需要安装 SFTP/FTP 的扩展插件才能同步代码；还有其他实现方法，如，Git 工作流、winscp、rzlz 等，但大都不太灵活，甚至麻烦 %}CentOS 7 配置使用 SFTP 服务器何为 SFTP？SFTP，即 SSH 文件传输协议（ SSH File Transfer Protocol ），或者说是安全文件传输协议（ Secure File Transfer Protocol ）。SFTP 是一个独立的 SSH 封装协议包，通过安全连接以相似的方式工作。它的优势在于可以利用安全的连接传输文件，还能浏览本地和远程系统上的文件系统。在很多情况下，SFTP 都比 FTP 更可取，因为它具有最基本的安全特性和能利用 SSH 连接的能力，FTP 是一种不安全的协议，只能在有限的情况下或在您信任的网络上使用。**先决条件：**服务器 `OpenSSH-Server` 版本最低 4.8p1，因为配置权限需要版本添加的新配置项 `ChrootDirectory` 来完成。如何查看 OpenSSH 版本，命令如下：```shell$ ssh -VOpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017```创建用户信息添加用户组：```shell$ groupadd sftp```添加用户：```shell$ useradd -g sftp -s /sbin/nologin -M leeifme```参数注解：```shell-g # 加入用户组-s # 指定用户登入后所使用的shell/sbin/nologin # 用户不允许登录-M # 不要自动建立用户的登入目录```设置用户密码：```shell$ passwd leeifme```创建用户目录并设置权限创建 sftp 主目录：```sh$ mkdir /home/danaos```设置 sftp 主目录权限：```sh$ chown root:sftp /home/danaos```文件夹所有者必须是 root，用户组可以不是 root```sh$ chmod 755 /home/danaos```权限不能超过 755 但不包括 755，否则会导致登录报错创建上传目录并设置权限在`/home/danaos/`主目录下创建`archer`项目文件夹，并设置所有者是：`leeifme`，用户组隶属：`sftp`，这样新增的帐号才能有上传编辑的权限。```sh$ mkdir -p /home/danaos/archer$ chown leeifme:sftp /home/danaos/archer```修改 sshd_config 配置文件```shell$ vim /etc/ssh/sshd_config```将此行注释掉，例如：```sh#Subsystem sftp /usr/libexec/openssh/sftp-server```在此行下面添加如下内容：```shSubsystem sftp internal-sftp # 指定使用sftp服务使用系统自带的internal-sftpMatch Group sftp # 匹配sftp组的用户,若要匹配多个组,可用逗号分开ChrootDirectory /home/danaos # 限制用户的根目录ForceCommand internal-sftp # 只能用于sftp登录AllowTcpForwarding no # 禁止用户使用端口转发X11Forwarding no # 禁止用户使用端口转发```重启 SSH 服务```shell$ systemctl restart sshd```测试是否能够登录、上传、下载等操作在`10.28.204.61`服务器执行以下命令登录：```sh$ sftp leeifme@192.168.50.124leeifme@192.168.50.124's password:Connected to leeifme@192.168.50.124.sftp> lsarchersftp> cd archer/sftp>```**上传**```shsftp> put test.goUploading test.go to /archer/test.gotest.go 100% 3824 626.2KB/s 00:00sftp>```**下载**```shsftp> get test.goFetching /archer/test.go to test.go/archer/oplog.go 100% 3824 475.1KB/s 00:00sftp>```**删除**```shsftp> rm test.goRemoving test.go```**更多命令请参阅**```shellsftp> help```vscode 配置 sftp下载 sftp 插件- 在 vscode 中快捷键 `ctrl+shift+P` 打开指令窗口，输入`extension:install`，回车，左侧即打开扩展安装的界面 - 在搜索框中输入`sftp`，第一个就是需要安装的，点安装(可以参考下载数，选择适合自己的插件，功能大都大同小异)在 vscode 的工程中配置 sftp.json然后快捷键 `ctrl+shift+P` 打开指令窗口，输入`sftp:config`，回车，就会在当前工作工程的`.vscode`文件夹下生成一个`sftp.json`文件，不知道哪天似乎是插件更新了，默认的文件非常空，我们只能手动配置文件的参数了。配置好`host, port, username, privateKeyPath, remotePath, ignore`这参数即可：- host：工作站的 IP 地址- port：ssh 的端口- username：工作站自己的用户名- privateKeyPath：存放在本地的已配置好的用于登录工作站的密钥文件。和下面的使用密码二选一（可以是 openssh 格式的，也可以是 ppk 格式的）- password：工作站自己的用户密码。使用密钥和使用密码选用一种即可；使用密码的话工作站不用配置 ssh，但使用密钥的话工作站上需要配置好 ssh，password 就可以填 null- protocol：协议类型，默认选`\"sftp\"`- remotePath：工作站上与本地工程同步的文件夹路径，需要和本地工程文件根目录同名，且在使用 sftp 上传文件之前要手动在工作站上使用mkdir生成这个根目录，根目录下的其他子目录会自动对应生成- ignore：指定在使用`sftp: sync to remote`的时候忽略的文件及文件夹，注意每一行后面有逗号，最后一行没有逗号- debug： 默认是 false，如果设置为 true，可以看到通过菜单的 查看 -> 输出 打开输出界面，看到打印，怀疑自己连接有问题的可以打开看看- uploadOnSave: 默认是 false，建议设置成 true，这样每次修改后 ctrl+s 保存后会自动同步。否则就需要手动同步举个栗子：（**记住不能有任何注释内容**）```json{ \"protocol\": \"sftp\", \"host\": \"192.168.50.124\", \"port\": 22, \"username\": \"leeifme\", \"password\": \"XXXXXXXXXX\", \"remotePath\": \"archer/\", \"watcher\": { \"files\": \"**/\", \"autoUpload\": true, \"autoDelete\": true }, \"ignore\": [ \"**/.git/**\" ]}```","tags":["VSCode","Linux"],"categories":["折腾不止"]},{"title":"暴力学习 k8s - 集群搭建","path":"/2018/k8s-cluster-deploy.html","content":"## 前言\n\n> 其实，搭建一个 Kubernetes（K8S）集群不是一件容易的事情，主要困难有两个：\n>\n> - 那一道厚厚的墙\n> - 对 K8S 的知识不熟悉\n>\n> 只要能解决上面两个问题，搭建的过程实际上就没有那么复杂了。\n>\n> 本系列是我在搭建过程中踩的无数坑 、以及查阅众多相关问题解决的文章的一些记录和总结。\n\n## 集群规划\n\n### 网络配置\n\n- 节点网络： 192.168.31.0/24\n- service 网络： 10.96.0.0/12\n- pod 网络： 10.244.0.0/16\n\n### kubeadm 部署\n\n#### 基本情况\n\n- kubeadm 项目[链接地址](https://github.com/kubernetes/kubeadm)\n- master、node： 安装 `kubelet`、 `kubeadm`、 `docker`\n- master： `kubeadm init`\n- node： `kubeadm join`\n- `apiserver`、`scheduler`、`Controller-manager`、`etcd` 在 master 上以 Pod 运行\n- `kubeproxy` 以 Pod 方式运行在每一个 node 节点上。\n- 以上 pod 均为静态 Pod\n- 每一个节点都需要运行 `flannel`（也是以 Pod 方式运行），以提供 Pod 网络\n- kubeadm 的[介绍](https://github.com/kubernetes/kubeadm/blob/master/docs/design/design_v1.10.md)\n\n#### 安装步骤\n\n1. master，node 需要安装 kubelet， kubeadm， docker\n2. master 节点上运行 `kubeadm init`\n3. node 节点上运行 `kubeadm join` 加入集群\n\n## 准备环境\n\n### 我的环境\n\n```sh\n[root@master yum.repos.d]# cat /etc/redhat-release \nCentOS Linux release 7.4.1708 (Core) \n[root@master yum.repos.d]# uname -a\nLinux master 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n```\n\n### 节点解析\n\n通过 `/etc/hosts` 文件解析\n\n```sh\n192.168.31.81 master.test.com master\n192.168.31.82 node01.test.com node01\n192.168.31.83 node02.test.com node02\n```\n\n**集群通过时间服务器做时钟同步**，我没做\n\n### 节点互信\n\n可以按照此[文档](https://www.cnblogs.com/jyzhao/p/3781072.html)配置节点互信，也没有做\n\n### 选择版本\n\n使用 kubernetes v1.11.2\n\n## 开始部署\n\n**确保 iptables firewalld 等未启动, 且不开机自启动**，可参考我之前的 CentOS 安装\n\n### 配置 yum 仓库\n\n使用 aliyun 源，[链接](https://opsx.alibaba.com/mirror)\n\n#### docker 源使用如下命令获取\n\n```sh\ncd /etc/yum.repos.d\nwget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n```\n\n#### kubernetes 源\n\n```sh\n[root@master yum.repos.d]# cat kubernetes.repo \n[kubernetes]\nname=Kubernetes Repo\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nenabled=1\n```\n\n#### 查看源是否生效\n\n```\n# yum clean all\n# yum repolist\n*****\n*****\nDetermining fastest mirrors\nkubernetes                                                         243/243\nrepo id                         repo name                            status\nbase/7/x86_64                   CentOS-7 - Base - 163.com            9,911\ndocker-ce-stable/x86_64         Docker CE Stable - x86_64               16\nextras/7/x86_64                 CentOS-7 - Extras - 163.com            370\nkubernetes                      Kubernetes Repo                        243\nupdates/7/x86_64                CentOS-7 - Updates - 163.com         1,054\nrepolist: 11,594\n```\n\n### 安装软件\n\n**三台机器都需要安装**\n\n使用 `yum install docker-ce kubelet kubeadm kubectl` 安装\n\n安装的软件包如下：\n\n```\n  Installing : kubectl-1.11.2-0.x86_64                                 1/7 \n  Installing : cri-tools-1.11.0-0.x86_64                               2/7 \n  Installing : socat-1.7.3.2-2.el7.x86_64                              3/7 \n  Installing : kubernetes-cni-0.6.0-0.x86_64                           4/7 \n  Installing : kubelet-1.11.2-0.x86_64                                 5/7 \n  Installing : kubeadm-1.11.2-0.x86_64                                 6/7 \n  Installing : docker-ce-18.06.0.ce-3.el7.x86_64                       7/7 \n```\n\n### 启动 docker 服务等\n\n由于国内网络原因，kubernetes 的镜像托管在 google 云上，无法直接下载，需要设置 proxy\n在 `/usr/lib/systemd/system/docker.service` 文件中添加如下两行\n\n```shell\n[root@master ~]# cat /usr/lib/systemd/system/docker.service |grep PROXY\nEnvironment=\"HTTPS_PROXY=http://www.ik8s.io:10080\"\nEnvironment=\"NO_PROXY=127.0.0.0/8,192.168.31.0/24\"\n```\n\n之后，启动 docker\n\n```shell\nsystemctl daemon-reload\nsystemctl start docker\nsystemctl enable docker\n```\n\n确认 proc 的这两个参数如下，均为 1\n\n```shell\n[root@master ~]# cat /proc/sys/net/bridge/bridge-nf-call-iptables \n1\n[root@master ~]# cat /proc/sys/net/bridge/bridge-nf-call-ip6tables \n1\n\n解决方法：修改系统文件是的机器 bridge 模式开启\n\n设置机器开机启动的时候执行下面两条命令\n\n编辑 vim  /etc/rc.d/rc.local 添加下面两条命令\n\n        echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables\n\n        echo 1 > /proc/sys/net/bridge/bridge-nf-call-ip6tables\n\ncentos7 需要增加执行权限：\n\n        chmod +x　/etc/rc,d/rc.local\n\n重启系统\n```\n\n### 设置 kubelet\n\n查看 kubelet 安装生成了哪些文件\n\n```shell\n[root@master ~]# rpm -ql kubelet\n/etc/kubernetes/manifests              # 清单目录\n/etc/sysconfig/kubelet                 # 配置文件\n/etc/systemd/system/kubelet.service    # unit file\n/usr/bin/kubelet                       # 主程序\n```\n\n**默认**的配置文件\n\n```shell\n[root@master ~]# cat /etc/sysconfig/kubelet\nKUBELET_EXTRA_ARGS=\n```\n\n修改 kubelet 的配置文件\n\n```shell\n[root@master ~]# cat /etc/sysconfig/kubelet\nKUBELET_EXTRA_ARGS=\"--fail-swap-on=false\"\n```\n\n此时还无法正常启动 kubelet，先设置 kubelet 开机自启动，使用如下命令： `systemctl enable kubelet` 。\n\n### kubeadm init\n\n在 master 节点上执行\n\n```shell\nkubeadm init --kubernetes-version=v1.11.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap\n```\n\nkubeadm init 的输出可见于此[链接](https://segmentfault.com/n/1330000016057102)\n\n此命令，下载了如下 image\n\n```shell\n[root@master ~]# docker images\nREPOSITORY                                 TAG                 IMAGE ID            CREATED             SIZE\nk8s.gcr.io/kube-proxy-amd64                v1.11.2             46a3cd725628        7 days ago          97.8MB\nk8s.gcr.io/kube-apiserver-amd64            v1.11.2             821507941e9c        7 days ago          187MB\nk8s.gcr.io/kube-controller-manager-amd64   v1.11.2             38521457c799        7 days ago          155MB\nk8s.gcr.io/kube-scheduler-amd64            v1.11.2             37a1403e6c1a        7 days ago          56.8MB\nk8s.gcr.io/coredns                         1.1.3               b3b94275d97c        2 months ago        45.6MB\nk8s.gcr.io/etcd-amd64                      3.2.18              b8df3b177be2        4 months ago        219MB\nk8s.gcr.io/pause                           3.1                 da86e6ba6ca1        7 months ago        742kB\n```\n\n现在，正在运行的 docker 如下\n\n```sh\n[root@master ~]# docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS               NAMES\n1c03e043e6b7        46a3cd725628           \"/usr/local/bin/kube??   3 minutes ago       Up 3 minutes                            k8s_kube-proxy_kube-proxy-6fgjm_kube-system_f85e8660-a090-11e8-8ee7-000c29f71e04_0\n5f166bd11566        k8s.gcr.io/pause:3.1   \"/pause\"                 3 minutes ago       Up 3 minutes                            k8s_POD_kube-proxy-6fgjm_kube-system_f85e8660-a090-11e8-8ee7-000c29f71e04_0\n0f306f98cc52        b8df3b177be2           \"etcd --advertise-cl??   3 minutes ago       Up 3 minutes                            k8s_etcd_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0\n8f01317b9e20        37a1403e6c1a           \"kube-scheduler --ad??   3 minutes ago       Up 3 minutes                            k8s_kube-scheduler_kube-scheduler-master_kube-system_a00c35e56ebd0bdfcd77d53674a5d2a1_0\n4e6a71ab20d3        821507941e9c           \"kube-apiserver --au??   3 minutes ago       Up 3 minutes                            k8s_kube-apiserver_kube-apiserver-master_kube-system_d25d40ebb427821464356bb27a38f487_0\n69e4c5dae335        38521457c799           \"kube-controller-man??   3 minutes ago       Up 3 minutes                            k8s_kube-controller-manager_kube-controller-manager-master_kube-system_6363f7ebf727b0b95d9a9ef72516a0e5_0\nda5981dc546a        k8s.gcr.io/pause:3.1   \"/pause\"                 3 minutes ago       Up 3 minutes                            k8s_POD_kube-controller-manager-master_kube-system_6363f7ebf727b0b95d9a9ef72516a0e5_0\nb7a8fdc35029        k8s.gcr.io/pause:3.1   \"/pause\"                 3 minutes ago       Up 3 minutes                            k8s_POD_kube-apiserver-master_kube-system_d25d40ebb427821464356bb27a38f487_0\nb09efc7ff7bd        k8s.gcr.io/pause:3.1   \"/pause\"                 3 minutes ago       Up 3 minutes                            k8s_POD_kube-scheduler-master_kube-system_a00c35e56ebd0bdfcd77d53674a5d2a1_0\nab11d6ffadab        k8s.gcr.io/pause:3.1   \"/pause\"                 3 minutes ago       Up 3 minutes                            k8s_POD_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0\n```\n\nnode 节点可以通过如下命令加入集群 `kubeadm join 192.168.31.81:6443 --token n84v6t.c7d83cn4mo2z8wyr --discovery-token-ca-cert-hash sha256:b946c145416fe1995e1d4d002c149e71a897acc7b106d94cee2920cb2c85ce29` \n\n在 kubeadm init 的[输出](https://segmentfault.com/a/1190000016026998)中，提示我们需要以普通用户做如下操作，我此时用 root 执行\n\n```sh\n[root@master ~]# mkdir -p $HOME/.kube\n[root@master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n```\n\n此时可以通过 `kubelet get` 获取各种资源信息。比如\n\n```sh\n[root@master ~]# kubectl get cs\nNAME                 STATUS    MESSAGE              ERROR\nscheduler            Healthy   ok                   \ncontroller-manager   Healthy   ok                   \netcd-0               Healthy   {\"health\": \"true\"} \n```\n\n此时的监听状态\n\n```sh\n[root@master ~]# ss -tnl\nState       Recv-Q Send-Q Local Address:Port               Peer Address:Port              \nLISTEN      0      128    127.0.0.1:2379                  *:*                  \nLISTEN      0      128    127.0.0.1:10251                 *:*                  \nLISTEN      0      128    127.0.0.1:2380                  *:*                  \nLISTEN      0      128    127.0.0.1:10252                 *:*                  \nLISTEN      0      128       *:22                    *:*                  \nLISTEN      0      128    127.0.0.1:33881                 *:*                  \nLISTEN      0      100    127.0.0.1:25                    *:*                  \nLISTEN      0      128    192.168.18.128:10010                 *:*                  \nLISTEN      0      128    127.0.0.1:10248                 *:*                  \nLISTEN      0      128    127.0.0.1:10249                 *:*                  \nLISTEN      0      128      :::6443                 :::*                  \nLISTEN      0      128      :::10256                :::*                  \nLISTEN      0      128      :::22                   :::*                  \nLISTEN      0      100     ::1:25                   :::*                  \nLISTEN      0      128      :::10250                :::*         \n```\n\n此时的节点状态\n\n```sh\n[root@master ~]# kubectl get nodes\nNAME      STATUS     ROLES     AGE       VERSION\nmaster    NotReady   master    9m        v1.11.2\n```\n\n状态为 `NotReady` ， 需要部署 flannel，[链接](https://github.com/coreos/flannel)\n\n### 部署 flannel\n\n在文档中，找到如下命令，部署\n\n```sh\n[root@master ~]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\nclusterrole.rbac.authorization.k8s.io/flannel created\nclusterrolebinding.rbac.authorization.k8s.io/flannel created\nserviceaccount/flannel created\nconfigmap/kube-flannel-cfg created\ndaemonset.extensions/kube-flannel-ds-amd64 created\ndaemonset.extensions/kube-flannel-ds-arm64 created\ndaemonset.extensions/kube-flannel-ds-arm created\ndaemonset.extensions/kube-flannel-ds-ppc64le created\ndaemonset.extensions/kube-flannel-ds-s390x created\n```\n\n按如下方法查看：\n\n```sh\n[root@master ~]# kubectl get pods -n  kube-system\nNAME                             READY     STATUS    RESTARTS   AGE\ncoredns-78fcdf6894-cv4gp         1/1       Running   0          13m\ncoredns-78fcdf6894-wmd25         1/1       Running   0          13m\netcd-master                      1/1       Running   0          49s\nkube-apiserver-master            1/1       Running   0          49s\nkube-controller-manager-master   1/1       Running   0          48s\nkube-flannel-ds-amd64-r42wr      1/1       Running   0          2m\nkube-proxy-6fgjm                 1/1       Running   0          13m\nkube-scheduler-master            1/1       Running   0          48s\n[root@master ~]# docker images |grep flannel\nquay.io/coreos/flannel                     v0.10.0-amd64       f0fad859c909        6 months ago        44.6MB\n[root@master ~]# kubectl get nodes\nNAME      STATUS    ROLES     AGE       VERSION\nmaster    Ready     master    14m       v1.11.2\n```\n\n此时 master 节点状态变为 `Ready` 。\n\n### 在 node 节点上执行 `kubeadm join` 命令\n\n使用 master 节点执行 `kubeadm init` 命令的输出，在 node 上执行，使其加入集群。\n\n```sh\n[root@node01 ~]#   kubeadm join 192.168.18.128:6443 --token n84v6t.c7d83cn4mo2z8wyr --discovery-token-ca-cert-hash sha256:b946c145416fe1995e1d4d002c149e71a897acc7b106d94cee2920cb2c85ce29 --ignore-preflight-errors=Swap\n\n[preflight] running pre-flight checks\n    [WARNING RequiredIPVSKernelModulesAvailable]: the IPVS proxier will not be used, because the following required kernel modules are not loaded: [ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh] or no builtin kernel ipvs support: map[ip_vs_sh:{} nf_conntrack_ipv4:{} ip_vs:{} ip_vs_rr:{} ip_vs_wrr:{}]\nyou can solve this problem with following methods:\n 1. Run 'modprobe -- ' to load missing kernel modules;\n2. Provide the missing builtin kernel ipvs support\n\n    [WARNING Swap]: running with swap on is not supported. Please disable swap\nI0815 22:02:30.751069   15460 kernel_validator.go:81] Validating kernel version\nI0815 22:02:30.751145   15460 kernel_validator.go:96] Validating kernel config\n    [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.06.0-ce. Max validated version: 17.03\n[discovery] Trying to connect to API Server \"192.168.18.128:6443\"\n[discovery] Created cluster-info discovery client, requesting info from \"https://192.168.18.128:6443\"\n[discovery] Requesting info from \"https://192.168.18.128:6443\" again to validate TLS against the pinned public key\n[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server \"192.168.18.128:6443\"\n[discovery] Successfully established connection with API Server \"192.168.18.128:6443\"\n[kubelet] Downloading configuration for the kubelet from the \"kubelet-config-1.11\" ConfigMap in the kube-system namespace\n[kubelet] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[preflight] Activating the kubelet service\n[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...\n[patchnode] Uploading the CRI Socket information \"/var/run/dockershim.sock\" to the Node API object \"node01\" as an annotation\n\nThis node has joined the cluster:\n* Certificate signing request was sent to master and a response\n  was received.\n* The Kubelet was informed of the new secure connection details.\n\nRun 'kubectl get nodes' on the master to see this node join the cluster.\n```\n\n在两个节点上，执行完毕上述命令后，在 master 上查看\n\n```sh\n[root@master ~]# kubectl get nodes\nNAME      STATUS    ROLES     AGE       VERSION\nmaster    Ready     master    23m       v1.11.2\nnode01    Ready     <none>    2m        v1.11.2\nnode02    Ready     <none>    1m        v1.11.2\n```\n\n部署成功。\n\n## 部署完成后的观察\n\n**检查现在正在运行的 pod**\n\n```sh\n[root@master ~]# kubectl get pods -n kube-system -o wide\nNAME                             READY     STATUS    RESTARTS   AGE       IP               NODE      NOMINATED NODE\ncoredns-78fcdf6894-cv4gp         1/1       Running   0          28m       10.244.0.3       master    <none>\ncoredns-78fcdf6894-wmd25         1/1       Running   0          28m       10.244.0.2       master    <none>\netcd-master                      1/1       Running   0          15m       192.168.18.128   master    <none>\nkube-apiserver-master            1/1       Running   0          15m       192.168.18.128   master    <none>\nkube-controller-manager-master   1/1       Running   0          15m       192.168.18.128   master    <none>\nkube-flannel-ds-amd64-48rvq      1/1       Running   3          6m        192.168.18.130   node02    <none>\nkube-flannel-ds-amd64-7dw42      1/1       Running   3          7m        192.168.18.129   node01    <none>\nkube-flannel-ds-amd64-r42wr      1/1       Running   0          16m       192.168.18.128   master    <none>\nkube-proxy-6fgjm                 1/1       Running   0          28m       192.168.18.128   master    <none>\nkube-proxy-6mngv                 1/1       Running   0          7m        192.168.18.129   node01    <none>\nkube-proxy-9sh2n                 1/1       Running   0          6m        192.168.18.130   node02    <none>\nkube-scheduler-master            1/1       Running   0          15m       192.168.18.128   master    <none>\n```\n\n可以发现：\n\n1. kube-apiserver， kube-scheduler， kube-controller，etcd-master 运行在 master 上，\n2. kube-flannel 在三个节点上均有运行\n3. kube-proxy 在三个节点均有运行","tags":["Cloud Navite","Kubernetes"],"categories":["折腾不止"]},{"title":"开启云原生之门","path":"/2018/open-cloud-native-study.html","content":"## 什么是云原生 \n\n### CNCF组织\n\n在讲云原生之前，我们先了解一下 CNCF ，即云原生计算基金会，2015年由谷歌牵头成立，基金会成员目前已有一百多企业与机构，包括亚马逊、微软。思科等巨头。目前 CNCF 所托管的应用已达14个，下图为其公布的Cloud Native Landscape，给出了云原生生态的参考体系：\n\n<img src = \"https://leeifme-1252179361.cos.ap-shanghai.myqcloud.com/blog/CNCF.png\">\n\n### 云原生(Cloud Native)\n\nCNCF 给出了云原生应用的三大特征：\n\n- 容器化封装：以容器为基础，提高整体开发水平，形成代码和组件重用，简化云原生应用程序的维护。在容器中运行应用程序和进程，并作为应用程序部署的独立单元，实现高水平资源隔离。\n- 动态管理：通过集中式的编排调度系统来动态的管理和调度。\n- 面向微服务：明确服务间的依赖，互相解耦。\n\n云原生包含了一组应用的模式，用于帮助企业快速，持续，可靠，规模化地交付业务软件。云原生由微服务架构，DevOps 和以容器为代表的敏捷基础架构组成。这边引用网上关于云原生所需要的能力和特征总结：\n\n<img src = \"https://leeifme-1252179361.cos.ap-shanghai.myqcloud.com/blog/yunyuansheng.jpg\">\n\n### 应用部署运行模式的变迁\n\n> 学习一个新事物之前呢，我们应该先了解\t该事物发展的历程和规律，`Kubernetes` 的出现就是应用部署运行模式在外部条件需求变更的情况下，演化出来的结果\n\n**物理机模式**(物理机-操作系统-应用)\n\n**虚拟化模式**(虚拟机-应用)\n\n**容器化模式**\n\n- 以 Docker为代表的内核容器技术不是新技术,而是将已有技术(LXC、 groups、 Union fs)进行了更好的整合和包装,并形成了\n  一种标准镜像格式\n- 与VM相比,容器具有开发交付流程操作对象同步、执行更为高效资源占用更为集约等优势。\n- 计算基本单元由虚拟机变为了容器,越来越多应用的构建、部署与运行选择在容器中进行。\n\n**云原生模式**\n\n- 随着容器技术的岀现以及应用所面临的外部环境的变化,云原生逐渐成为一种应用云化开发、部署和运行的主流方式\n- 基础前提:应用的容器化和微服务化。容器,作为应用部署、运行和管理的基本单元\n- 核心:借助容器管理自动化平台进行动态编排和资源优化利用\n\n## 云原生应用的三大特征\n\n###  容器化封装\n\n最近几年Docker容器化技术很火，经常在各种场合能够听到关于 `Docker` 的分享。`Docker` 让开发工程师可以将他们的应用和依赖封装到一个可移植的容器中。`Docker` 背后的想法是创建软件程序可移植的轻量容器，让其可以在任何安装了 `Docker` 的机器上运行，而不用关心底层操作系统。\n\n`Docker` 可以解决虚拟机能够解决的问题，同时也能够解决虚拟机由于资源要求过高而无法解决的问题。其优势包1括：\n\n- 隔离应用依赖\n- 创建应用镜像并进行复制\n- 创建容易分发的即启即用的应用\n- 允许实例简单、快速地扩展\n- 测试应用并随后销毁它们\n\n自动化运维工具可以降低环境搭建的复杂度，但仍然不能从根本上解决环境的问题。在看似稳定而成熟的场景下，使用 `Docker` 的好处越来越多。\n\n### 服务编排 动态管理\n\n[Jimmy Song](https://jimmysong.io/posts/from-kubernetes-to-cloud-native/) 对云原生架构中运用服务编排的总结是：\n\n> Kubernetes——让容器应用进入大规模工业生产\n\n编排调度的开源组件还有：`Kubernetes`、`Mesos` 和 `Docker Swarm`;\n\n他们为云原生应用提供的强有力的编排和调度能力，它们是云平台上的分布式操作系统。在单机上运行容器，无法发挥它的最大效能，只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势\n\n### 微服务架构\n\n近几年微服务架构（`Micro-Service`，`Archeticture`）是最流行的架构风格，旨在通过将功能模块分解到各个独立的子系统中以实现解耦，它并没有一成不变的规定，而是需要根据业务来做设计。微服务架构是对SOA的传承，是SOA的具体实践方法。微服务架构中，每个微服务模块只是对简单、独立、明确的任务进行处理，通过REST API返回处理结果给外部。在微服务推广实践角度来看，微服务将整个系统进行拆分，拆分成更小的粒度，保持这些服务独立运行，应用容器化技术将微服务独立运行在容器中。过去设计架构时，是在内存中以参数或对象的方式实现粒度细化。微服务使用各个子服务控制模块的思想代替总线。不同的业务要求，服务控制模块至少包含服务的发布、注册、路由、代理功能。\n\n容器化的出现，一定程度上带动了微服务架构。架构演化从单体式应用到分布式，再从分布式架构到云原生架构，微服务在其中有着不可或缺的角色。微服务带给我们很多开发和部署上的灵活性和技术多样性，但是也增加了服务调用的开销、分布式系事务、调试与服务治理方面的难题。  \n\n## 总结\n\n技术架构的演变非常快，各种新的名词也是层出不穷。本文主要是对云原生的概述。云原生应用的三大特征：容器化封装、动态管理、面向微服务。首先由CNCF组织介绍了云原生的概念，然后分别对这三个特征进行详述。云原生架构是当下很火的讨论话题，是不同思想的集合，集目前各种热门技术之大成","tags":["Docker","Cloud Navite","Kubernetes"],"categories":["设计开发"]},{"title":"优化睡觉的沙发","path":"/2018/optimization-blog-theme.html","content":"> 博客太久没动了，刚好没事做的时候，就特别改博客主题，感觉像是强迫症，得改~\n>\n> 玩博客久了，就像谈恋爱，刚开始很美好，久而久之，问题就冒出来，总想让她变的更好，\n>\n> 其实这些都是次要的，我也知道更应该专注文章的内容，哎......\n\n## 集成Gitment\n\n[**Gitment**](https://github.com/imsun/gitment) 是作者实现的一款基于 GitHub Issues 的评论系统。支持在前端直接引入，不需要任何后端代码。可以在页面进行登录、查看、评论、点赞等操作，同时有完整的 Markdown / GFM 和代码高亮支持。尤为适合各种基于 GitHub/Coding Pages 的静态博客或项目页面\n\n- [**项目地址**](https://github.com/imsun/gitment)\n- [**示例页面**](https://imsun.github.io/gitment/)\n\n当然，人家作者也说了，着这个项目的时候考虑过到底有没有滥用 GitHub ，为此还特地 Email 了官方，GitHub 给出的回复是：\n\n> We’re pleased to see you making use of the tools and resources available on GitHub.\n\n所以啊，我们在使用的时候，也要恪尽职守，维护一个好的开源环境，善用 `GitHub`\n\n好了，说多了，下面开始：\n\n### 注册 OAuth Application\n\n[点击此处](https://github.com/settings/applications/new) 来注册一个新的 OAuth Application，成功之后就会拿到 `Client ID` 和 `Client Secret`\n\n### 修改主题配置文件\n\n```yaml\n##############################################################################\n# Plugins\n##############################################################################\n\n## Gitment\ngitment:\n  enable: true\n  owner: your_id\n  repo: your_repo\n  client_id: your_client_id\n  client_secret: your_client_secret\n```\n\n### 为 Gitment 添加 layout 布局\n\n这里以我的主题 [**cactus**](https://github.com/probberechts/hexo-theme-cactus) 为例，在 `layout/_partial/comments.ejs` 下列代添加码：\n\n```ejs\n<% if(is_post() || page.comments) { %>\n<div id=\"gitment_title\" class=\"gitment_title\"></div>\n<div id=\"container\" style=\"display:none\"></div>\n<script src=\"https://imsun.github.io/gitment/dist/gitment.browser.js\"></script>\n<script src=\"https://code.jquery.com/jquery-3.3.1.min.js\"></script>\n<script>\n  const myTheme = {\n    render(state, instance) {\n      const container = document.createElement('div');\n      container.lang = \"en-US\";\n      container.className = 'gitment-container gitment-root-container';\n      container.appendChild(instance.renderHeader(state, instance));\n      container.appendChild(instance.renderEditor(state, instance));\n      container.appendChild(instance.renderComments(state, instance));\n      container.appendChild(instance.renderFooter(state, instance));\n      return container;\n    }\n  }\n\n  function showGitment() {\n    $(\"#gitment_title\").attr(\"style\", \"display:none\");\n    $(\"#container\").attr(\"style\", \"\").addClass(\"gitment_container\");\n    var gitment = new Gitment({\n      id: decodeURI(window.location.pathname),\n      theme: myTheme,\n      owner: \"<%=theme.gitment.owner%>\",\n      repo: \"<%=theme.gitment.repo%>\",\n      oauth: {\n\t      client_id: \"<%=theme.gitment.client_id%>\",\n\t      client_secret: \"<%=theme.gitment.client_secret%>\"\n      }\n    });\n    gitment.render('container');\n  }\n  showGitment();\n</script>\n<% } %>\n```\n\n### 为 Gitment 添加样式\n\n[**_gitment.styl**](https://github.com/leeifme/leeifme.github.io/blob/hexo/themes/cactus/source/css/_gitment.styl) 这是我自定义的 Gitment 的样式文件，比较契合我的主题 `cactus` ，可以自行修改；将样式文件拷贝到 `source/css/` 目录下\n\n**引入 Gitment 样式**\n\n在 `source/css/style.styl` 文件中，添加：\n\n```stylus\n@import \"_gitment.styl\"\n```\n\nok，更新博客，就可以看到评论了\n\n## 主题首页添加 一言\n\n> 一言：随机一句话副标题，\n>\n> 可以是一本书，一部电影，一句歌词，\n>\n> 可以是中文，英文，日语，\n>\n> 总之是一句话\n\n感谢作者：[**isecret**](https://github.com/isecret)，是从他他制作的 Hexo 主题 [**Hola**](https://github.com/isecret/Hola) 获取的灵感\n\n### 修改主题配置文件\n\n```yaml\n##############################################################################\n# Plugins\n##############################################################################\n\n## 一言\nhitokoto: enabled\n```\n\n### 为一言添加 layout 布局\n\n在 `layout/index.styl` 文件中的 `<section id=\"about\">` 内添加：\n\n```stylus\n<% if (theme.hitokoto == 'enabled') { %>\n    <p>\n      <script>\n          fetch('https://api.hitokoto.cn')\n              .then(function (res){\n                  return res.json();\n              })\n              .then(function (data) {\n                  var hitokoto = document.getElementById('hitokoto');\n                  hitokoto.innerText =  data.hitokoto + ' ——' + '『' + data.from + '』';\n              })\n              .catch(function (err) {\n                  console.error(err);\n              });\n      </script>\n      <a id=\"hitokoto\"></a>\n    </p>\n <% } %>\n```\n\n[**演示地址**](https://leeif.me/) \n\n## gulp 文件压缩\n\n### 安装 npm 依赖组件\n\n```bash\n# 在站点的根目录下执行以下命令\n\nnpm install gulp -g\nnpm install gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp --save\n\n# 模块作用\ngulp-htmlclean // 清理html\ngulp-htmlmin // 压缩html\ngulp-minify-css // 压缩css\ngulp-uglify // 混淆js\ngulp-imagemin // 压缩图片\n```\n\n### 新建 gulp 配置\n\n```js\n/* 在站点根目录添加 gulpfile.js 文件，内容如下： */\n\nvar gulp = require('gulp');\nvar minifycss = require('gulp-minify-css');\nvar uglify = require('gulp-uglify');\nvar htmlmin = require('gulp-htmlmin');\nvar htmlclean = require('gulp-htmlclean');\n// 压缩 public 目录 css\ngulp.task('minify-css', function() {\n    return gulp.src('./public/**/*.css')\n        .pipe(minifycss())\n        .pipe(gulp.dest('./public'));\n});\n// 压缩 public 目录 html\ngulp.task('minify-html', function() {\n  return gulp.src('./public/**/*.html')\n    .pipe(htmlclean())\n    .pipe(htmlmin({\n         removeComments: true,\n         minifyJS: true,\n         minifyCSS: true,\n         minifyURLs: true,\n    }))\n    .pipe(gulp.dest('./public'))\n});\n// 压缩 public/js 目录 js\ngulp.task('minify-js', function() {\n    return gulp.src('./public/**/*.js')\n        .pipe(uglify())\n        .pipe(gulp.dest('./public'));\n});\n// 执行 gulp 命令时执行的任务\ngulp.task('default', [\n    'minify-html','minify-css','minify-js'\n]);\n```\n\n### 部署命令\n\n在站点根目录执行 `gulp` 命令，就能压缩 `public` 文件夹里面的文件了\n\n```bash\nhexo g && gulp;\nhexo d;\n```\n\n\n\n> 后续有其他优化，会持续更新的......","tags":["Hexo"],"categories":["折腾不止"]},{"title":"你和大佬之间就差一个 vim","path":"/2018/vim-common-hotkey.html","content":"## 进入 vim\n\n| 命令                   | 描述                                              |\n| ---------------------- | ------------------------------------------------- |\n| vim filename           | 打开或新建文件, 并将光标置于第一行首              |\n| vim +n filename        | 打开文件，并将光标置于第 n 行首                   |\n| vim + filename         | 打开文件，并将光标置于最后一行首                  |\n| vim +/pattern filename | 打开文件，并将光标置于第一个与 pattern 匹配的串处 |\n| vim -r filename        | 在上次正用 vim 编辑时发生系统崩溃，恢复 filename  |\n| vim filename….filename | 打开多个文件，依次编辑                            |\n\n## vim 配置\n\n| 命令                       | 描述                                                         |\n| -------------------------- | ------------------------------------------------------------ |\n| :set number / set nonumber | 显示 / 不显示行号                                            |\n| :set ruler /set noruler    | 显示 / 不显示标尺                                            |\n| :set hlsearch              | 高亮显示查找到的单词                                         |\n| :set nohlsearch            | 关闭高亮显示                                                 |\n| :syntax on                 | 语法高亮                                                     |\n| :set nu                    | 显示行号                                                     |\n| :set tabstop=8             | 设置 tab 大小, 8 为最常用最普遍的设置                        |\n| :set softtabstop=8         | 4:4 个空格, 8: 正常的制表符, 12: 一个制表符 4 个空格, 16: 两个制表符 |\n| :set autoindent            | 自动缩进                                                     |\n| :set cindent               | C 语言格式里面的自动缩进                                     |\n\n## 移动光标\n\n| 命令      | 描述                                        |\n| --------- | ------------------------------------------- |\n| k nk      | 上 向上移动 n 行                            |\n| j nj      | 下 向下移动 n 行                            |\n| h nh      | 左 向左移动 n 行                            |\n| l nl      | 右 向右移动 n 行                            |\n| Space     | 光标右移一个字符                            |\n| Backspace | 光标左移一个字符                            |\n| Enter     | 光标下移一行                                |\n| w/W       | 光标右移一个字至字首                        |\n| b/B       | 光标左移一个字至字首                        |\n| e 或 E    | 光标右移一个字至字尾                        |\n| )         | 光标移至句尾                                |\n| (         | 光标移至句首                                |\n| }         | 光标移至段落开头                            |\n| {         | 光标移至段落结尾                            |\n| n$        | 光标移至第 n 行尾                           |\n| H         | 光标移至屏幕顶行                            |\n| M         | 光标移至屏幕中间行                          |\n| L         | 光标移至屏幕最后行                          |\n| 0         | （注意是数字零）光标移至当前行首            |\n| ^         | 移动光标到行首第一个非空字符上去            |\n| $         | 光标移至当前行尾                            |\n| gg        | 移到第一行                                  |\n| G         | 移到最后一行                                |\n| f         | 移动光标到当前行的字符 a 上                 |\n| F         | 相反                                        |\n| %         | 移动到与制匹配的括号上去（），{}，[]，<> 等 |\n| nG        | 移动到第 n 行上                             |\n| G         | 到最后一行                                  |\n\n## 屏幕滚动\n\n| 命令    | 描述                                                   |\n| ------- | ------------------------------------------------------ |\n| Ctrl+u  | 向文件首翻半屏                                         |\n| Ctrl+d  | 向文件尾翻半屏                                         |\n| Ctrl+f  | 向文件尾翻一屏                                         |\n| Ctrl＋b | 向文件首翻一屏                                         |\n| nz      | 将第 n 行滚至屏幕顶部，不指定 n 时将当前行滚至屏幕顶部 |\n\n## 插入文本类\n\n| 命令    | 描述                                                 |\n| ------- | ---------------------------------------------------- |\n| i       | 在光标前                                             |\n| I       | 在当前行首                                           |\n| a       | 光标后                                               |\n| A       | 在当前行尾                                           |\n| o       | 在当前行之下新开一行                                 |\n| O       | 在当前行之上新开一行                                 |\n| r       | 替换当前字符                                         |\n| R       | 替换当前字符及其后的字符，直至按 ESC 键              |\n| s       | 从当前光标位置处开始，以输入的文本替代指定数目的字符 |\n| S       | 删除指定数目的行，并以所输入文本代替之               |\n| ncw/nCW | 修改指定数目的字                                     |\n| nCC     | 修改指定数目的行                                     |\n\n## 删除命令\n\n| 命令      | 描述                                              |\n| --------- | ------------------------------------------------- |\n| x/X       | 删除一个字符，x 删除光标后的，而 X 删除光标前的   |\n| dw        | 删除一个单词 (删除光标位置到下一个单词开始的位置) |\n| dnw       | 删除 n 个单词                                     |\n| dne       | 也可，只是删除到单词尾                            |\n| do        | 删至行首                                          |\n| d$        | 删至行尾                                          |\n| dd        | 删除一行                                          |\n| ndd       | 删除当前行及其后 n-1 行                           |\n| dnl       | 向右删除 n 个字母                                 |\n| dnh       | 向左删除 n 个字母                                 |\n| dnj       | 向下删除 n 行, 当前行 + 其上 n 行                 |\n| dnk       | 向上删除 n 行, 当期行 + 其下 n 行                 |\n| cnw[word] | 将 n 个 word 改变为 word                          |\n| C$        | 改变到行尾                                        |\n| cc        | 改变整行                                          |\n| shift+j   | 删除行尾的换行符，下一行接上来了                  |\n\n## 复制粘贴\n\n| 命令 | 描述                     |\n| ---- | ------------------------ |\n| p    | 粘贴用 x 或 d 删除的文本 |\n| ynw  | 复制 n 个单词            |\n| yy   | 复制一行                 |\n| ynl  | 复制 n 个字符            |\n| y$   | 复制当前光标至行尾处     |\n| nyy  | 拷贝 n 行                |\n\n## 撤销\n\n| 命令      | 描述                 |\n| --------- | -------------------- |\n| u         | 撤销前一次的操作     |\n| shif+u(U) | 撤销对该行的所有操作 |\n\n## 搜索及替换\n\n| 命令                     | 描述                                                         |\n| ------------------------ | ------------------------------------------------------------ |\n| /pattern                 | 从光标开始处向文件尾搜索 pattern                             |\n| ?pattern                 | 从光标开始处向文件首搜索 pattern                             |\n| n                        | 在同一方向重复上一次搜索命令                                 |\n| N                        | 在反方向上重复上一次搜索命令                                 |\n| cw newword               | 替换为 newword                                               |\n| n                        | 继续查找                                                     |\n| .                        | 执行替换                                                     |\n| :s/p1/p2/g               | 将当前行中所有 p1 均用 p2 替代, g 表示执行 用 c 表示需要确认 |\n| :n1,n2 s/p1/p2/g         | 将第 n1 至 n2 行中所有 p1 均用 p2 替代                       |\n| :g/p1/s//p2/g            | 将文件中所有 p1 均用 p2 替换                                 |\n| :1,$ s/string1/string2/g | 在全文中将 string1 替换为 string2                            |\n\n## 书签\n\n| 命令   | 描述                                      |\n| ------ | ----------------------------------------- |\n| m[a-z] | 在文中做标记，标记号可为 a-z 的 26 个字母 |\n| `a     | 移动到标记 a 处                           |\n\n## visual 模式\n\n| 命令                              | 描述                                                         |\n| --------------------------------- | ------------------------------------------------------------ |\n| v                                 | 进入 visual 模式                                             |\n| V                                 | 进入行的 visual 模式                                         |\n| ctrl+v                            | 进如块操作模式用 o 和 O 改变选择的边的大小                   |\n| 在所有行插入相同的内容如 include< | 将光标移到开始插入的位置，按 CTRL+V 进入 VISUAL 模式，选择好模块后按 I（shift+i)，后插入要插入的文本，按 [ESC] 完成 |\n\n## 行方式命令\n\n| 命令                                                     | 描述                                                    |\n| -------------------------------------------------------- | ------------------------------------------------------- |\n| :n1,n2 co n3 或者 :n1,n2 copy n3                         | 将 n1 行到 n2 行之间的内容拷贝到第 n3 行下              |\n| :n1,n2 m n3 或者 :n1,n2 move n3                          | 将 n1 行到 n2 行之间的内容移至到第 n3 行下              |\n| :n1,n2 d                                                 | 将 n1 行到 n2 行之间的内容删除                          |\n| :n1,n2 w!command                                         | 将文件中 n1 行至 n2 行的内容作为 command 的输入并执行之 |\n| 若不指定 n1，n2，则表示将整个文件内容作为 command 的输入 |                                                         |\n\n## 宏\n\n| 命令   | 描述                                                         |\n| ------ | ------------------------------------------------------------ |\n| q[a-z] | 开始记录但前开始的操作为宏，名称可为【a-z】，然后用 q 终止录制宏 |\n| reg    | 显示当前定义的所有的宏，用 @[a-z] 来在当前光标处执行宏 [a-z] |\n\n## 窗口操作\n\n| 命令           | 描述                                       |\n| -------------- | ------------------------------------------ |\n| :split         | 分割一个窗口                               |\n| :split file.c  | 为另一个文件 file.c 分隔窗口               |\n| :nsplit file.c | 为另一个文件 file.c 分隔窗口，并指定其行数 |\n| ctrl＋w        | 在窗口中切换                               |\n| :close         | 关闭当前窗口                               |\n\n## 文件及其他\n\n| 命令         | 描述                                         |\n| ------------ | -------------------------------------------- |\n| :q           | 退出 vi                                      |\n| :q!          | 不保存文件并退出 vi                          |\n| :e filename  | 打开文件 filename 进行编辑                   |\n| :e!          | 放弃修改文件内容，重新载入该文件编辑         |\n| :w           | 保存当前文件                                 |\n| :wq          | 存盘退出                                     |\n| :ZZ          | 保存当前文档并退出 VIM                       |\n| :!command    | 执行 shell 命令 command                      |\n| :r!command   | 将命令 command 的输出结果放到当前行          |\n| :read file.c | 将文件 file.c 的内容插入到当前光标所在的下面 |\n\n## 常用正则\n\n- 删除行尾空格：`:%s/\\s+$//g`\n- 删除行首多余空格：`%s/^\\s*//` 或者 `%s/^ *//`\n- 删除沒有內容的空行：`%s/^$//` 或者 `g/^$/d`\n- 删除包含有空格组成的空行：`%s/^\\s*$//` 或者 `g/^\\s*$/d`\n- 删除以空格或 TAB 开头到结尾的空行：`%s/^[ |\\t]*$//` 或者 `g/^[ |\\t]*$/d`\n- 清空某一行或多行文本：`:n1,n2 s/\\w//g`\n- 给一行或多行首字符添加注释：`n1,n2 s/^/#/g`\n- 给一行或多行首字符删除注释：`n1,n2 s/^#//g`","tags":["Linux","Vim"],"categories":["安利系列"]},{"title":"gin-swagger 自动化构建 API 文档","path":"/2018/gin-swagger-build-document.html","content":"> 前后端的交互一般流程是这样的，后端暴露出 API 后，交给前端，前端根据 API 的响应，编写前端页面，一定程度上 API 是前后端的交互桥梁。 \n\nAPI 文档主要要包含:\n\n- 路由：包括路径参数、请求参数、还是请求体参数\n- 动作：HTTP 请求动作，GET、POST、DELETE、PUT\n- 响应：请求之后的返回值包含哪些信息，一般是 JSON\n\nswagger 可以将代码和 api 文档维护在一起，通过访问服务进程的 swagger 页面就可以得到完善的 api 文档，还可以直接 Try out。 \n\n## doc文档\n\n- [**gin-swagger**](https://github.com/swaggo/gin-swagger)\n- [**swagger-doc**](https://swaggo.github.io/swaggo.io/declarative_comments_format/)\n\n## 做法\n\n1. 要知道 swagger 注释的语法\n2. 如何在 gin 内怎么使用\n\n注释语法这个，全靠查文档。对着文档来。\n\n当然我觉得最好的方法是什么呢，是模仿，找一个别人已经写好的，修修改改，看看能不能编译通过，编译通过后是不是你预期的结果。不是的话，继续修修改改，再编译，再看是不是你希望的结果。如此反复。\n\n![mark](http://orj2jcr7i.bkt.clouddn.com/blog/180727/2im5i3b45e.png?imageslim)\n\n#### 1. 编写全局信息注释，在主函数上编写\n\n格式：`// @param info`\n\n```go\n// @title Swagger Example API\n// @version 1.0\n// @description This is a sample server Petstore server.\n// @termsOfService http://swagger.io/terms/\n\n// @contact.name API Support\n// @contact.url http://www.swagger.io/support\n// @contact.email support@swagger.io\n\n// @license.name Apache 2.0\n// @license.url http://www.apache.org/licenses/LICENSE-2.0.html\n\n// @host 127.0.0.1:8080\n// @BasePath /v1\nfunc main() {\n\tr := gin.Default()\n\tr.GET(\"/docs/*any\", ginSwagger.WrapHandler(swaggerFiles.Handler))\n\tr.GET(\"v1/hello/:name\", Name)\n\tr.Run()\n}\n```\n\n```\nr.GET(\"/docs/*any\", ginSwagger.WrapHandler(swaggerFiles.Handler))\n```\n\n这个路由和响应需要有，路由随便的定义，但我觉得我这种方式一目了然，知道是文档。\n\n其他注释对照着参考文档即可。\n\n#### 2. 编写应用注释\n\n即在响应函数的上方编写注释\n\n```go\n// Name will print hello name\n// @Summary Print\n// @Accept json\n// @Tags Name\n// @Security Bearer\n// @Produce  json\n// @Param name path string true \"name\"\n// @Resource Name\n// @Router /hello/{name} [get]\n// @Success 200 {object} main.Message\nfunc Name(c *gin.Context) {\n\tname := c.Param(\"name\")\n\n\tif name == \"\" {\n\t\treturn\n\t}\n\tvar message Message\n\n\tmessage = Message{\n\t\tMessageInfo: fmt.Sprintf(\"hello %s\", name),\n\t}\n\tc.JSON(http.StatusOK, message.Serializer())\n}\n\n```\n\n这里最好把响应体统一成结构体的形式。即\n\n```go\ntype Message struct {\n    MessageInfo string `json:\"message\"`\n}\n\nfunc (m *Message) Serializer()Message{\n    return Message{\n        MessageInfo: m.MessageInfo,\n    }\n\n}\n```\n\n#### 3. 目录下 执行命令\n\n```go\nswag init\n```\n\n自动生成 docs 文件夹，内含 swagger.json 、swagger.json 、 docs.go\n\n编译不通过，查看报错信息，修改注释。\n\n#### 4. 导入生成的 docs 文件\n\n```go\nimport (\n    \"github.com/swaggo/gin-swagger\"\n    \"github.com/swaggo/gin-swagger/swaggerFiles\"\n\n    _ \"./docs\" // docs is generated by Swag CLI, you have to import it.\n    \"github.com/gin-gonic/gin\"\n    \"net/http\"\n    \"fmt\"\n)\n```\n\n即这个  `./docs`\n\n#### 5. go run main.go\n\n访问：`http://127.0.0.1:8080/docs/index.html`\n\n即可查看 swagger 文档。\n\n![mark](http://orj2jcr7i.bkt.clouddn.com/blog/180727/hidH469gKB.png?imageslim)","tags":["Go"],"categories":["技术加油站"]},{"title":"高性能的 Go Web 框架 - gin","path":"/2018/gin-go-web-frame.html","content":"## Gin 的使用\n\n### 安装和更新\n\n首次安装，使用 `go get`命令获取即可。\n\n```sh\n$ go get github.com/gin-gonic/gin\n```\n\n更新就是常规的 `go get -u`。\n\n```sh\n$ go get -u github.com/gin-gonic/gin\n```\n\n### 快速运行\n\n在你的 main 包中，引入 gin 包并初始化。\n\n```go\npackage main\n\nimport (\n\t\"github.com/gin-gonic/gin\"\n\t\"net/http\"\n)\n\nfunc main() {\n\t// 初始化引擎\n\tengine := gin.Default()\n\t// 注册一个路由和处理函数\n\tengine.Any(\"/\", WebRoot)\n\t// 绑定端口，然后启动应用\n\tengine.Run(\":9205\")\n}\n\n/**\n* 根请求处理函数\n* 所有本次请求相关的方法都在 context 中，完美\n* 输出响应 hello, world\n*/\nfunc WebRoot(context *gin.Context) {\n\tcontext.String(http.StatusOK, \"hello, world\")\n}\n```\n\n一个最简单的应用就写好了，来运行下试试:\n\n```sh\n$ go run\n[GIN-debug] Listening and serving HTTP on :9205\n```\n\n访问 [http://127.0.0.1:9205](http://127.0.0.1:9205/) ，就可以得到响应 “hello, world” 。\n\n## 路由 (Router)\n\n### Restful Api\n\n你可以注册路由方法有 GET, POST, PUT, PATCH, DELETE 和 OPTIONS.\n\n使用很简单，直接调用同名的方法即可。\n\n```go\n// 省略的代码 ...\n\nfunc main() {\n\trouter := gin.Default()\n\n\trouter.GET(\"/someGet\", getting)\n\trouter.POST(\"/somePost\", posting)\n\trouter.PUT(\"/somePut\", putting)\n\trouter.DELETE(\"/someDelete\", deleting)\n\trouter.PATCH(\"/somePatch\", patching)\n\trouter.HEAD(\"/someHead\", head)\n\trouter.OPTIONS(\"/someOptions\", options)\n\n\t// 默认绑定 :8080\n\trouter.Run()\n}\n\n// 省略的代码 ...\n```\n\n### 动态路由（参数路由）\n\n有时候我们需要动态的路由，如 `/user/:id`，通过调用的 url 来传入不同的 id . 在 Gin 中很容易处理这种路由：\n\n```go\n// 省略的代码 ...\n\nfunc main() {\n\trouter := gin.Default()\n\n\t// 注册一个动态路由\n  \t// 可以匹配 /user/leeifme\n  \t// 不能匹配 /user 和 /user/\n\trouter.GET(\"/user/:name\", func(c *gin.Context) {\n\t\t// 使用 c.Param(key) 获取 url 参数\n\t\tname := c.Param(\"name\")\n\t\tc.String(http.StatusOK, \"Hello %s\", name)\n\t})\n\n  \t// 注册一个高级的动态路由\n\t// 该路由会匹配 /user/leeifme/ 和 /user/leeifme/send\n\t// 如果没有任何路由匹配到 /user/leeifme, 那么他就会重定向到 /user/leeifme/，从而被该方法匹配到\n\trouter.GET(\"/user/:name/*action\", func(c *gin.Context) {\n\t\tname := c.Param(\"name\")\n\t\taction := c.Param(\"action\")\n\t\tmessage := name + \" is \" + action\n\t\tc.String(http.StatusOK, message)\n\t})\n\n\trouter.Run(\":8080\")\n}\n\n// 省略的代码 ...\n```\n\n### 路由组\n\n一些情况下，我们会有统一前缀的 url 的需求，典型的如 Api 接口版本号 `/v1/something`。Gin 可以使用 Group 方法统一归类到路由组中：\n\n```go\n// 省略的代码 ...\n\nfunc main() {\n\trouter := gin.Default()\n\n\t// 定义一个组前缀\n  \t// /v1/login 就会匹配到这个组\n\tv1 := router.Group(\"/v1\")\n\t{\n\t\tv1.POST(\"/login\", loginEndpoint)\n\t\tv1.POST(\"/submit\", submitEndpoint)\n\t\tv1.POST(\"/read\", readEndpoint)\n\t}\n\n\t// 定义一个组前缀\n  \t// 不用花括号包起来也是可以的。上面那种只是看起来会统一一点。看你个人喜好\n\tv2 := router.Group(\"/v2\")\n\tv2.POST(\"/login\", loginEndpoint)\n\tv2.POST(\"/submit\", submitEndpoint)\n\tv2.POST(\"/read\", readEndpoint)\n\n\trouter.Run(\":8080\")\n}\n\n// 省略的代码 ...\n```\n\n## 中间件 (Middleware)\n\ngolang 的 net/http 设计的一大特点就是特别容易构建中间件。需要注意的是中间件只对注册过的路由函数起作用。对于分组路由，嵌套使用中间件，可以限定中间件的作用范围。中间件分为全局中间件，单个路由中间件和群组中间件。 \n\n现代化的 Web 编程，中间件已经是必不可少的了。我们可以通过中间件的方式，验证 Auth 和身份鉴别，集中处理返回的数据等等。Gin 提供了 Middleware 的功能，并与路由紧紧相连。\n\n### 单个路由中间件\n\n单个路由使用中间件，只需要在注册路由的时候指定要执行的中间件即可。\n\n```go\n// 省略的代码 ...\n\nfunc main() {\n\trouter := gin.Default()\n\n\t// 注册一个路由，使用了 middleware1，middleware2 两个中间件\n\trouter.GET(\"/someGet\", middleware1, middleware2, handler)\n  \n\t// 默认绑定 :8080\n\trouter.Run()\n}\n\nfunc handler(c *gin.Context) {\n\tlog.Println(\"exec handler\")\n}\n\n// 省略的代码 ...\n```\n\n### 执行流程控制\n\n用上面的实例代码，我们来看一下中间件是怎么执行的。\n\n```go\n// 省略的代码 ...\n\nfunc middleware1(c *gin.Context) {\n\tlog.Println(\"exec middleware1\")\n  \n\t//你可以写一些逻辑代码\n  \n\t// 执行该中间件之后的逻辑\n\tc.Next()\n}\n\n// 省略的代码 ...\n```\n\n可以看出，中间件的写法和路由的 Handler 几乎是一样的，只是多调用 `c.Next()`。\n\n正是有个`c.Next()`，我们可以在中间件中控制调用逻辑的变化，看下面的 `middleware2` 代码。\n\n```go\n// 省略的代码 ...\n\nfunc middleware2(c *gin.Context) {\n\tlog.Println(\"arrive at middleware2\")\n\t// 执行该中间件之前，先跳到流程的下一个方法\n\tc.Next()\n\t// 流程中的其他逻辑已经执行完了\n\tlog.Println(\"exec middleware2\")\n  \n\t//你可以写一些逻辑代码\n}\n\n// 省略的代码 ...\n```\n\n在 `middleware2`中，执行到 `c.Next()`时，Gin 会直接跳到流程的下一个方法中，等到这个方法执行完后，才会回来接着执行 `middleware2` 剩下的代码。\n\n所以请求上面注册的路由 url `/someGet` ，请求先到达`middleware1`，然后到达 `middleware2`，但此时 `middleware2`调用了 `c.Next()`，所以 `middleware2`的代码并没有执行，而是跳到了 `handler`，等 `handler`执行完成后，跳回到 `middleware2`，执行 `middleware2`剩下的代码。\n\n所以我们可以在控制台上看到以下日志输出:\n\n```bash\nexec middleware1\narrive at middleware2\nexec handler\nexec middleware2\n```\n\n### 路由组使用中间件\n\n路由组使用中间件和单个路由类似，只不过是要把中间件放到 `Group` 上.\n\n```go\n// 省略的代码 ...\n\nfunc main() {\n\trouter := gin.Default()\n\n\t// 定义一个组前缀, 并使用 middleware1 中间件\n  \t// 访问 /v2/login 就会执行 middleware1 函数\n\tv2 := router.Group(\"/v2\", middleware1)\n\tv2.POST(\"/login\", loginEndpoint)\n\tv2.POST(\"/submit\", submitEndpoint)\n\tv2.POST(\"/read\", readEndpoint)\n\n\trouter.Run(\":8080\")\n}\n\n// 省略的代码 ...\n```","tags":["Go"],"categories":["技术加油站"]},{"title":"Docker 常用命令记录","path":"/2018/docker-common-command .html","content":"## Docker 是什么\n\nDocker 是一个改进的容器技术。具体的 “改进” 体现在，Docker 为容器引入了镜像，使得容器可以从预先定义好的模版（images）创建出来，并且这个模版还是分层的。\n\n### Docker 经常被提起的特点：\n\n- 轻量，体现在内存占用小，高密度\n- 快速，毫秒启动\n- 隔离，沙盒技术更像虚拟机\n\n### Docker 技术的基础：\n\n- namespace，容器隔离的基础，保证 A 容器看不到 B 容器. 6 个名空间：User,Mnt,Network,UTS,IPC,Pid\n- cgroups，容器资源统计和隔离。主要用到的 cgroups 子系统：cpu,blkio,device,freezer,memory\n- unionfs，典型：aufs/overlayfs，分层镜像实现的基础\n\n### Docker 组件：\n\n- **docker Client** 客户端————> 向 docker 服务器进程发起请求，如: 创建、停止、销毁容器等操作\n- **docker Server** 服务器进程—–> 处理所有 docker 的请求，管理所有容器\n- **docker Registry** 镜像仓库——> 镜像存放的中央仓库，可看作是存放二进制的 scm\n\n## Docker 安装\n\nDocker 的安装非常简单，支持目前所有主流操作系统，从 Mac 到 Windows 到各种 Linux 发行版\n具体参考： [docker 安装](https://docs.docker.com/installation/)\n\n## Docker 常见命令\n\n#### 容器相关操作\n\n```\ndocker create # 创建一个容器但是不启动它\ndocker run # 创建并启动一个容器\ndocker stop # 停止容器运行，发送信号 SIGTERM\ndocker start # 启动一个停止状态的容器\ndocker restart # 重启一个容器\ndocker rm # 删除一个容器\ndocker kill # 发送信号给容器，默认 SIGKILL\ndocker attach # 连接 (进入) 到一个正在运行的容器\ndocker wait # 阻塞到一个容器，直到容器停止运行\n```\n\n\n\n#### 获取容器相关信息\n\n```\ndocker ps # 显示状态为运行（Up）的容器\ndocker ps -a # 显示所有容器, 包括运行中（Up）的和退出的 (Exited)\ndocker inspect # 深入容器内部获取容器所有信息\ndocker logs # 查看容器的日志 (stdout/stderr)\ndocker events # 得到 docker 服务器的实时的事件\ndocker port # 显示容器的端口映射\ndocker top # 显示容器的进程信息\ndocker diff # 显示容器文件系统的前后变化\n```\n\n\n\n#### 导出容器\n\n```\ndocker cp # 从容器里向外拷贝文件或目录\ndocker export # 将容器整个文件系统导出为一个 tar 包，不带 layers、tag 等信息\n```\n\n\n\n#### 执行\n\n```\ndocker exec # 在容器里执行一个命令，可以执行 bash 进入交互式\n```\n\n\n\n#### 镜像操作\n\n```\ndocker images # 显示本地所有的镜像列表\ndocker import # 从一个 tar 包创建一个镜像，往往和 export 结合使用\ndocker build # 使用 Dockerfile 创建镜像（推荐）\ndocker commit # 从容器创建镜像\ndocker rmi # 删除一个镜像\ndocker load # 从一个 tar 包创建一个镜像，和 save 配合使用\ndocker save # 将一个镜像保存为一个 tar 包，带 layers 和 tag 信息\ndocker history # 显示生成一个镜像的历史命令\ndocker tag # 为镜像起一个别名\n```\n\n\n\n#### 镜像仓库 (registry) 操作\n\n```\ndocker login # 登录到一个 registry\ndocker search # 从 registry 仓库搜索镜像\ndocker pull # 从仓库下载镜像到本地\ndocker push # 将一个镜像 push 到 registry 仓库中\n```\n\n\n\n#### 获取 Container IP 地址（Container 状态必须是 Up）\n\n```\ndocker inspect id | grep IPAddress | cut -d '\"' -f 4\n```\n\n#### 获取端口映射\n\n```\ndocker inspect -f '{{range $p, $conf := .NetworkSettings.Ports}} {{$p}} -> {{(index $conf 0).HostPort}} {{end}}' id\n```\n\n#### 获取环境变量\n\n```\ndocker exec container_id env\n```\n\n#### 杀掉所有正在运行的容器\n\n```\ndocker kill $(docker ps -q)\n```\n\n#### 删除老的 (一周前创建) 容器\n\n```\ndocker ps -a | grep 'weeks ago' | awk '{print $1}' | xargs docker rm\n```\n\n#### 删除已经停止的容器\n\n```\ndocker rm `docker ps -a -q`\n```\n\n#### 删除所有镜像，小心\n\n```\ndocker rmi $(docker images -q)\n```\n\n## Dockerfile\n\nDockerfile 是 docker 构建镜像的基础，也是 docker 区别于其他容器的重要特征，正是有了 Dockerfile，docker 的自动化和可移植性才成为可能。\n\n不论是开发还是运维，学会编写 Dockerfile 几乎是必备的，这有助于你理解整个容器的运行。\n\n#### FROM , 从一个基础镜像构建新的镜像\n\n```\nFROM ubuntu \n```\n\n#### MAINTAINER , 维护者信息\n\n```\nMAINTAINER William <wlj@nicescale.com>\n```\n\n#### ENV , 设置环境变量\n\n```\nENV TEST 1\n```\n\n#### RUN , 非交互式运行 shell 命令\n\n```\nRUN apt-get -y update \nRUN apt-get -y install nginx\n```\n\n#### ADD , 将外部文件拷贝到镜像里, src 可以为 url\n\n```\nADD http://nicescale.com/  /data/nicescale.tgz\n```\n\n#### WORKDIR /path/to/workdir, 设置工作目录\n\n```\nWORKDIR /var/www\n```\n\n#### USER , 设置用户 ID\n\n```\nUSER nginx\n```\n\n#### VULUME <#dir>, 设置 volume\n\n```\nVOLUME [‘/data’]\n```\n\n#### EXPOSE , 暴露哪些端口\n\n```\nEXPOSE 80 443 \n```\n\n#### ENTRYPOINT [‘executable’, ‘param1’,’param2’] 执行命令\n\n```\nENTRYPOINT [\"/usr/sbin/nginx\"]\n```\n\n#### CMD [“param1”,”param2”]\n\n```\nCMD [\"start\"]\n```\n\ndocker 创建、启动 container 时执行的命令，如果设置了 ENTRYPOINT，则 CMD 将作为参数\n\n#### Dockerfile 最佳实践\n\n- 尽量将一些常用不变的指令放到前面\n- CMD 和 ENTRYPOINT 尽量使用 json 数组方式\n\n#### 通过 Dockerfile 构建 image\n\n```\ndocker build csphere/nginx:1.7 .\n```\n\n## 镜像仓库 Registry\n\n镜像从 Dockerfile build 生成后，需要将镜像推送 (push) 到镜像仓库。企业内部都需要构建一个私有 docker registry，这个 registry 可以看作二进制的 scm，CI/CD 也需要围绕 registry 进行。\n\n#### 部署 registry\n\n```\nmkdir /registry\ndocker run  -p 80:5000  -e STORAGE_PATH=/registry  -v /registry:/registry  registry:2.0\n```\n\n#### 推送镜像保存到仓库\n\n假设 192.168.1.2 是 registry 仓库的地址：\n\n```\ndocker tag  csphere/nginx:1.7 192.168.1.2/csphere/nginx:1.7\ndocker push 192.168.1.2/csphere/nginx:1.7\n```\n\n## 几个简单小例子\n\n### 容器操作\n\n#### 1. 创建并拉取 busybox\n\n```\n# docker run -it --name con01 busybox:latest\n/ # ip addr    #容器里执行\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default \nlink/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\ninet 127.0.0.1/8 scope host lo\n   valid_lft forever preferred_lft forever\nSegmentation fault (core dumped)\n/ # ping www.csphere.cn\nPING www.csphere.cn (117.121.26.243): 56 data bytes\n64 bytes from 117.121.26.243: seq=0 ttl=48 time=3.139 ms\n64 bytes from 117.121.26.243: seq=1 ttl=48 time=3.027 ms\n^C\n--- www.csphere.cn ping statistics ---\n2 packets transmitted, 2 packets received, 0% packet loss\nround-trip min/avg/max = 3.027/3.083/3.139 ms\nexit    #退出容器\n```\n\n#### 2. 创建测试容器\n\n```\ndocker run -d --name con03 csphere/test:0.1\nefc9bda4a2ff2f479b18e0fc4698e42c47c9583a24c93f5ce6b28a828a172709\n```\n\n#### 3. 登陆到 con03 中\n\n```\n# docker exec -it con03 /bin/bash\n[root@efc9bda4a2ff /]# exit\n```\n\n#### 4. 停止 con03\n\n```\n# docker stop con03\ncon03\n```\n\n#### 5. 开启 con03\n\n```\n# docker start con03\ncon03\n```\n\n#### 6. 删除 con03\n\n```\n# docker ps -a\nCONTAINER ID        IMAGE                    COMMAND                CREATED             STATUS                      PORTS                                             NAMES\nefc9bda4a2ff        csphere/test:0.1         \"/usr/local/bin/run    4 minutes ago       Up 17 seconds                                                                 con03               \n99aa6ee25adc        busybox:latest           \"/bin/sh\"              14 minutes ago      Exited (0) 12 minutes ago                                                     con02               \n831c93de9b9f        busybox:latest           \"/bin/sh\"              2 hours ago         Up 27 minutes                                                                 con01\n# docker rm con02     #容器停止的状态\n# docker rm -f con03  #容器开启的状态\n```\n\n### 镜像操作\n\n#### 1. 从 docker hub 官方镜像仓库拉取镜像\n\n```\n# docker pull busybox:latest\natest: Pulling from busybox\ncf2616975b4a: Pull complete \n6ce2e90b0bc7: Pull complete \n8c2e06607696: Already exists \nbusybox:latest: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.\nDigest: sha256:38a203e1986cf79639cfb9b2e1d6e773de84002feea2d4eb006b52004ee8502d\nStatus: Downloaded newer image for busybox:latest\n```\n\n#### 2. 从本地上传镜像到镜像仓库\n\n```\ndocker push 192.168.1.2/csphere/nginx:1.7\n```\n\n#### 3. 查找镜像仓库的某个镜像\n\n```\n# docker search centos/nginx\nNAME                                     DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\njohnnyzheng/centos-nginx-php-wordpress                                                   1                    [OK]\nsergeyzh/centos6-nginx                                                                   1                    [OK]\nhzhang/centos-nginx                                                                      1                    [OK]\n```\n\n#### 4. 查看本地镜像列表\n\n```\n# docker images\nTAG                 IMAGE ID            CREATED             VIRTUAL SIZE\ndocker.io/csphere/csphere   0.10.3              604c03bf0c9e        3 days ago          62.72 MB\ndocker.io/csphere/csphere   latest              604c03bf0c9e        3 days ago          62.72 MB\ncsphere/csphere             0.10.3              604c03bf0c9e        3 days ago          62.72 MB\nregistry                    2.0                 2971b6ce766c        7 days ago          548.1 MB\nbusybox                     latest              8c2e06607696        3 weeks ago         2.43 MB\n```\n\n#### 5. 删除镜像\n\n```\ndocker rmi busybox:latest        #没有容器使用此镜像创建，如果有容器在使用此镜像会报错：Error response from daemon: Conflict, cannot delete 8c2e06607696 because the running container 831c93de9b9f is using it, stop it and use -f to force\nFATA[0000] Error: failed to remove one or more images\ndocker rmi -f busybox:latest     #容器使用此镜像创建，此容器状态为Exited\n```\n\n#### 6. 查看构建镜像所用过的命令\n\n```\n# docker history busybox:latest\nIMAGE               CREATED             CREATED BY                                      SIZE\n8c2e06607696        3 weeks ago         /bin/sh -c #(nop) CMD [\"/bin/sh\"]               0 B\n6ce2e90b0bc7        3 weeks ago         /bin/sh -c #(nop) ADD file:8cf517d90fe79547c4   2.43 MB\ncf2616975b4a        3 weeks ago         /bin/sh -c #(nop) MAINTAINER Jérôme Petazzo     0 B\n```","tags":["Docker","Cloud Navite"],"categories":["技术加油站"]},{"title":"初学 Redis 作缓存层","path":"/2018/redis-for-mysql-cache.html","content":"> 项目需求：数据库用的是MySQL，考虑用Redis/memcached做数据库的缓存层。在读DB前，先读缓存层，如果有直接返回，如果没有再读DB，然后写入缓存层并返回。\n\n\n## 思路：\n###缓存读取流程\n1. 先到缓存中查数据                         \n2. 缓存中不存在则到实际数据源中取，取出来后放入缓存                     \n3. 下次再来取同样信息时则可直接从缓存中获取\n\n###缓存更新流程\n1. 更新数据库                         \n2. 使缓存过期或失效，这样会促使下次查询数据时在缓存中查不到而重新从数据库去一次。\n\n###通用缓存机制\n1. 用查询的方法名 + 参数作为查询时的 key value 对中的 key 值\n2. 向 memcache 或 redis 之类的 nosql 数据库（或者内存 hashmap）插入数据3、取数据时也用方法名 + 参数作为 key 向缓存数据源获取信息。\n\n## 应用场景\n### 判断缓存是否存在\n\n```go\ndataList, err := dataRedis.Get(CacheKey).Result()\nif err == redis.Nil {\n\t// 不存在redis key\n\treturn \"\", false\n} else if err != nil {\n\tlog.Errorf(\"Get cache err, cache_key: %s, error: %s\", CacheKey, err)\n\treturn \"\", false\n} else {\n\t// 缓存值为空\n\tif dataList == \"\" {\n\t\treturn \"\", false\n\t}\n}\n\nreturn dataList, true\n```\n\n### 对数据做处理\n\n```go\nCacheKey := \"key\"\nData, isTrue := isGetDataCache(CacheKey)\n\nif isTrue {\n\t// 从`redis`中获取数据直接返回\n\terr := json.Unmarshal([]byte(Data), &dataList)\n\tif err != nil {\n\t\tlog.Errorf(\"Json unmarshal datalist err:%s\", err)\n\t\treturn dataList\n\t}\n} else {\n\t// 从db中获取数据\n\tdataList = GetDataWhere(\"`deleted`=0 order by sort limit ? offset ?\", limit, offset)\n\n\t// 更新redis缓存\n\terr := dataRedis.Set(CacheKey, xutil.ToJSONString(dataList), 1*time.Minute).Err()\n\tif err != nil {\n\t\tlog.Errorf(\"Set rediscache error:%s\", err)\n\t\treturn dataList\n\t}\n\n}\nreturn dataList\n```\n\n## 思考\n\n### 写入数据是否立刻更新缓存\n\n如果需要立刻更新缓存的话，使用 findAndModify 获取最新结果并设置进缓存中，但这带来了一个弊端，有些并不是热数据，这时候放进了 redis 会导致占用内存，如果设置过快，redis 内存的使用量增长得非常快；好处需要与另一种方式对比才明显，另一种方式是写入数据后立刻删掉该缓存，等待有需要才再加载缓存，这样的好处是 redis 占用缓存不会过高，总是保留着热数据，弊端就是加载缓存读取从库的数据还是未同步的，这样导致脏数据，所以前者的直接更新保证了不会是脏数据。至于采取那种方式，要看使用场景，如果不需要最新的数据，最方便是删除掉该缓存就可以了，否则就需要立刻更新缓存数据，如果键数量特别多的情况下，可以设置过期时间短一些，尽快释放 redis 的内存占用。\n\n### 读取 Set 和 SortedSet 数据缓存失效问题\n\n这种大数据集合，无法单个操作就可以判断其 key 存在还是该 key 是否有值。通常需要两个操作：加载和获取需要的数据。问题就出现在加载和获取的间隙中，这个间隙缓存刚好过期，就会出现数据错误的后果，我觉得最佳实践是这样: 保证在服务运行过程中，这些数据集合不会缓存过期。像我们使用排行榜的时候用到大量了 SortedSet，当时设置了 1 天就过期，这样导致出现排行榜数据出现不全的问题。又如 Set 保存着比赛名单的数据，发现 key 是存在，不再加载数据，准备判断某个项是否存在该 set 的时候，这个 set 就过期了，用sismember就会返回False，就无法判断这个 False 的意思是该数据项不存在该 set 里面还是该 set 的 key 已经过期了。\n\n### 在项目中 Redis 做缓存\n- 首先，对于数据缓存不是所有东西都缓存到 redis 就是好的，而是要针对一些改动不大或者访问率大的数据进行缓存来减少关系型数据库的压力。\n- redis 作为缓存使用，不作数据库用途，遵循以下规则：如果缓存没有数据，即加载数据到缓存，并会设置过期时间。\n- 凡是可以用 String 保存的，尽量将数据用json.dumps之后再放进 String，如果需要 Set 和 SortedSet 就需要警惕缓存 key 刚好过期时候，会有一定读取错误的问题，这个无法避免。\n- 对于一些不分页，不需要实时（需要多表查询）的列表，我们可以将列表结果缓存到 redis 中，设定一定缓存时间作为该数据的存活时间。用获取该列表的方法名作为 key，列表结果为 value；这种情况只试用于不经常更新且不需要实时的情况下。\n- 不需要实时的，需要分页的列表：可以把分页的结果列表放到一个 map（key 为分页标识，value 为分页结果）中，然后将该 map 存到 redis 的 list 中（用该方法名为 key）。然后给该 list 设置一个缓存存活时间（用 expire）。这样通过方法名 lrange 出来就能获取存有分页列表的数据，遍历该 list，通过遍历 list 中 map 的 key 判断该分页数据是否在缓存内，是则返回，不存在则 rpush 进去。这种做法能解决比如 1-5 页的数据已经重新加载，而 6-10 页的数据依然是缓存的数据而导致脏数据的情况。","tags":["Go","Redis"],"categories":["技术加油站"]},{"title":"Windows 利器 - babun","path":"/2018/babun-windows-tool.html","content":"## 什么是 babun\n\nbabun 是 windows 上的一个第三方 shell，在这个 shell 上面你可以使用几乎所有 linux，unix 上面的命令，他几乎可以取代 windows 的 shell。用官方的题目说就是 A Windows shell you will love!\n\n> ### babun 的几个特点\n>\n> 使用 babun 无需管理员权限\n> 先进的安装包管理器 (类似于 linux 上面的 apt-get 或 yum)\n> 预先配置了 Cygwin 和很多插件\n> 拥有 256 色的兼容控制台\n> HTTP(S) 的代理支持\n> 面向插件的体系结构\n> 可以使用它来配置你的 git\n> 集成了 oh-my-zsh\n> 自动升级\n> 支持 shell 编程，内置 VIM 等\n>\n> babun 官网链接：<<http://babun.github.io/>>\n\n## 什么是 cmder\n\ncmder 是 window 下的多标签命令行工具，可以方便的新建 cmd、cmd admin、powershell、powershell admin 多种命令行，设置很多，功能强大。\n\n## 安装\n\n### cmder 安装\n\n下载：<http://cmder.net/>\n\ncmder 是开箱即用的软件就不在详述了，具体使用可参考官网说明。\n\n### babun 安装\n\n下载：<http://babun.github.io/>\n\n##### 默认安装\n\n下载完成之后解压 babun，直接双击目录中 install.bat 脚本 (需管理员权限) 进行安装。几分钟之后自动安装完成，默认会被安装在`%userprofile%\\.babun`目录下。\n\n##### 自定义安装位置\n\n通过 cmd 命令行在执行 install.bat 时指定参数 / t 或 / target 指定安装的目录。\n\n执行：`babun.bat /t c:\\babun`\n\n安装好之后会在 c:\\babun 目录下生成一个. babun 的目录，babun 所有文件都在这个目录中。注意安装目录最好不要有空格，这是 cygwin 要求的。\n\n##### 测试安装成功\n\n安装完毕后，一般需要以下两个命令检查\n\n```\nbabun check(用于判断环境是否正确)\nbabun update(用于判断是否有新的更新包)\n```\n\n## babun 主要配置\n\n### 主题配置\n\n- 字体下载（不安装会乱码）\n\n  ```shell\n  # clone(克隆git)\n  git clone https://github.com/powerline/fonts.git --depth=1\n  # install(运行安装脚本)\n  cd fonts\n  ./install.sh\n  # clean-up a bit(清楚克隆git文件)_\n  cd ..\n  rm -rf fonts\n  ```\n\n  安装  [在`~\\.local\\share\\fonts`目录下找到`DejaVu Sans Mono for Powerline`字体]\n\n- 把`ZSH_THEME=”babun”`设置为`ZSH_THEME=”agnoster”`（详情参考`.zshrc`配置）\n\n- 修改`~/.minttyrc`\n\n  ```shell\n  # open ~/.minttyrc\n  vi ~/.minttyrc\n\n  # 把下面这段复制粘贴进去\n  BoldAsFont=no\n  Columns=90\n  Rows=55\n  Font=DejaVu Sans Mono for Powerline\n  FontHeight=10\n  Transparency=low\n\n  ForegroundColour=248,248,242\n  BackgroundColour=27,29,30\n  CursorColour=160,160,160\n  Black=249,38,114\n  Red=249,38,114\n  Green=130,180,20\n  Yellow=253,151,31\n  Blue=38,139,210\n  Magenta=140,84,254\n  Cyan=86,194,214\n  White=204,204,198\n  BoldRed=255,89,149\n  BoldBlack=80,83,84\n  BoldGreen=183,235,70\n  BoldYellow=254,237,108\n  BoldBlue=98,173,227\n  BoldMagenta=191,160,254\n  BoldCyan=148,216,229\n  BoldWhite=248,248,242\n  Scrollbar=none\n  ```\n\n### babun 插件安装\n\n#### [zsh-syntax-highlighting](https://github.com/zsh-users/zsh-syntax-highlighting) && [zsh-autosuggestions](https://github.com/zsh-users/zsh-autosuggestions)\n\n```shell\ncd ~/.oh-my-zsh/custom/plugins\ngit clone git://github.com/zsh-users/zsh-syntax-highlighting.git\ngit clone git://github.com/zsh-users/zsh-autosuggestions\nvi ~/.zshrc\n```\n\n```shell\n# add below to ~/.zshrc\nplugins=(zsh-syntax-highlighting zsh-autosuggestions)\n```\n\n```shell\nsource ~/.zshrc or src\n```\n\n[![zsh-syntax-highlighting](https://raw.githubusercontent.com/zsh-users/zsh-syntax-highlighting/master/images/preview.png)](https://raw.githubusercontent.com/zsh-users/zsh-syntax-highlighting/master/images/preview.png)\n\n#### [autojump](https://github.com/wting/autojump)\n\n```shell\ncd ~/.oh-my-zsh/custom/plugins\ngit clone git://github.com/joelthelion/autojump.git\ncd autojump\n./install.py\nvi ~/.zshrc\n```\n\n``` shell\n# add below to ~/.zshrc\n[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] && . ~/.autojump/etc/profile.d/autojump.sh\nautoload -U compinit && compinit -u\n```\n\n然后定位到 plugins=(git) 的位置，将其修改成：\n\n```shell\nplugins=(git autojump)\n```\n\n### .zshrc配置\n\n```shell\n# Path to your oh-my-zsh installation.\nexport ZSH=$HOME/.oh-my-zsh\n\n# Set name of the theme to load.\n# Look in ~/.oh-my-zsh/themes/\nZSH_THEME=\"agnoster\"\n\n# DEFAULT_USER=\"$USER\"\n\n# Uncomment the following line if you want to disable marking untracked files\n# under VCS as dirty. This makes repository status check for large repositories\n# much, much faster.\n# DISABLE_UNTRACKED_FILES_DIRTY=\"true\"\n\n# The optional three formats: \"mm/dd/yyyy\"|\"dd.mm.yyyy\"|\"yyyy-mm-dd\"\nHIST_STAMPS=\"yyyy-mm-dd\"\n\n# Would you like to use another custom folder than $ZSH/custom?\n# ZSH_CUSTOM=/path/to/new-custom-folder\n\n# Which plugins would you like to load? (plugins can be found in ~/.oh-my-zsh/plugins/*)\n# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/\n# Example format: plugins=(rails git textmate ruby lighthouse)\n# Add wisely, as too many plugins slow down shell startup.\nplugins=(git autojump sh-autosuggestions zsh-syntax-highlighting wd web-search history history-substring-search)\n\n[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] && . ~/.autojump/etc/profile.d/autojump.sh\nautoload -U compinit && compinit -u\n\nsource ~/.bash_profile\n# Load zsh-syntax-highlighting.\nsource ~/.oh-my-zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\n#\n# Load zsh-autosuggestions.\nsource ~/.oh-my-zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh\n\n# User configuration\nexport PATH=$HOME/bin:/usr/local/bin:$PATH\n# export MANPATH=\"/usr/local/man:$MANPATH\"\n\nsource $ZSH/oh-my-zsh.sh\n\n# Compilation flags\n# export ARCHFLAGS=\"-arch x86_64\"\n\n# ssh\n# export SSH_KEY_PATH=\"~/.ssh/dsa_id\"\n\n# Example aliases\nalias zshconfig=\"mate ~/.zshrc\"\nalias ohmyzsh=\"mate ~/.oh-my-zsh\"\nalias cls='clear'\nalias mysql='/usr/local/opt/mysql/bin/mysql'\nalias mysqladmin='/usr/local/opt/mysql/bin/mysqladmin'\nalias rake='noglob rake'\n\nalias code=\"/Applications/Visual\\ Studio\\ Code.app/Contents/Resources/app/bin/code\"\nalias vi=\"vim\"\nalias vim=\"vim\"\nalias tmux=\"tmux -2\"\nalias ssh=\"ssh -X\"\nalias s=\"ssh -X\"\nalias md=\"mkdir -p\"\nalias rd=\"rmdir\"\nalias df=\"df -h\"\nalias mv=\"mv -i\"\nalias slink=\"link -s\"\nalias sed=\"sed -E\"\nalias l=\"ls -l\"\nalias la=\"ls -a\"\nalias ll=\"ls -la\"\nalias lt=\"ls -lhtrF\"\nalias l.=\"ls -lhtrdF .*\"\nalias grep=\"grep --color=auto\"\nalias cd..=\"cd ..\"\nalias cd...=\"cd ../..\"\nalias cd....=\"cd ../../..\"\nalias ..=\"cd ..\"\nalias ...=\"cd ../..\"\nalias ....=\"cd ../../..\"\nalias zb=\"cat /dev/urandom | hexdump -C | grep --color=auto \\\"ca fe\\\"\"\nalias mtr=\"/usr/local/sbin/mtr\"\nalias gs=\"git status\"\nalias gsm=\"git summary\"\nalias ga='git add'\nalias gd='git diff'\nalias gf='git fetch'\nalias grv='git remote -v'\nalias grb='git rebase'\nalias gbr='git branch'\nalias gpl=\"git pull\"\nalias gps=\"git push\"\nalias gco=\"git checkout\"\nalias gl=\"git log\"\nalias gc=\"git commit -m\"\nalias gm=\"git merge\"\nalias pro=\"proxychains4\"\nalias gb=\"go build\"\n\nalias -s go=vi\nalias -s html=vi\nalias -s rb=vi\nalias -s py=vi\nalias -s txt=vi\nalias -s ex=vi\nalias -s exs=vi\nalias -s js=vi\nalias -s json=vi\n\n\nalias qas01='ssh root@123.59.56.118 -p38390'\nalias rdp01='ssh lei.li@rdp01.xiaoenai.net -p38390'\nalias rdp='ssh lei.li@rdp01.xiaoenai.net -p38390'\n\n_COLUMNS=$(tput cols)\n_MESSAGE=\" FBI Warining \"\ny=$(( ( $_COLUMNS - ${#_MESSAGE} )  / 2 ))\nspaces=$(printf \"%-${y}s\" \" \")\n\necho \" \"\necho -e \"${spaces}\\033[41;37;5m FBI WARNING \\033[0m\"\necho \" \"\n_COLUMNS=$(tput cols)\n_MESSAGE=\"Ferderal Law provides severe civil and criminal penalties for\"\ny=$(( ( $_COLUMNS - ${#_MESSAGE} )  / 2 ))\nspaces=$(printf \"%-${y}s\" \" \")\necho -e \"${spaces}${_MESSAGE}\"\n\n_COLUMNS=$(tput cols)\n_MESSAGE=\"the unauthorized reproduction, distribution, or exhibition of\"\ny=$(( ( $_COLUMNS - ${#_MESSAGE} )  / 2 ))\nspaces=$(printf \"%-${y}s\" \" \")\necho -e \"${spaces}${_MESSAGE}\"\n\n_COLUMNS=$(tput cols)\n_MESSAGE=\"copyrighted motion pictures (Title 17, United States Code,\"\ny=$(( ( $_COLUMNS - ${#_MESSAGE} )  / 2 ))\nspaces=$(printf \"%-${y}s\" \" \")\necho -e \"${spaces}${_MESSAGE}\"\n\n_COLUMNS=$(tput cols)\n_MESSAGE=\"Sections 501 and 508). The Federal Bureau of Investigation\"\ny=$(( ( $_COLUMNS - ${#_MESSAGE} )  / 2 ))\nspaces=$(printf \"%-${y}s\" \" \")\necho -e \"${spaces}${_MESSAGE}\"\n\n_COLUMNS=$(tput cols)\n_MESSAGE=\"investigates allegations of criminal copyright infringement\"\ny=$(( ( $_COLUMNS - ${#_MESSAGE} )  / 2 ))\nspaces=$(printf \"%-${y}s\" \" \")\necho -e \"${spaces}${_MESSAGE}\"\n\n_COLUMNS=$(tput cols)\n_MESSAGE=\"(Title 17, United States Code, Section 506).\"\ny=$(( ( $_COLUMNS - ${#_MESSAGE} )  / 2 ))\nspaces=$(printf \"%-${y}s\" \" \")\necho -e \"${spaces}${_MESSAGE}\"\n\necho \" \"\n```","tags":["Windows","Shell"],"categories":["安利系列"]},{"title":"Python 之正则表达式","path":"/2018/python-regular-expression.html","content":"### 1. 什么是正则表达式\n\n正则表达式：也成为规则表达式，英文名称 Regular Expression，我们在程序中经常会缩写为 regex 或者 regexp，专门用于进行文本检索、匹配、替换等操作的一种技术。\n*注意：正则表达式是一种独立的技术，并不是某编程语言独有的*\n\n正则表达式，是一种特殊的符号，这样的符号是需要解释才能使用的，也就是需要正则表达式引擎来进行解释，目前正则表达式的引擎主要分三种：DFA，NFA、POSIX NFA，*有兴趣了正则表达式引擎的童鞋，可以自己查看资料*\n\n### 2. 正则表达式语法结构\n\n接下来，我们开始了解这样一个神秘的可以类似人类神经网络一样思考问题的技术的语法结构。\n*注意：我们通过 python 程序进行测试，但是正则表达式的语法结构在各种语言环境中都是通用的。*\n\n###### 2.1. 入门案例：了解正则表达式\n\n我们通过一个简单的案例入手：通常情况下，我们会验证用户输入的手机号码是否合法，是否 156/186/188 开头的手机号码，如果按照常规验证手段，就需要对字符串进行拆分处理，然后逐步匹配\n\n> 重要提示：python 中提供了`re`模块，包含了正则表达式的所有功能，专门用于进行正则表达式的处理；\n\n我们首先看一下，常规的手机号码验证过程\n\n```python\nuserphone = input(\"请输入手机号码：\")\n\n# 验证用户手机号码是否合法的函数\ndef validatePhone(phone):\n    msg = \"提示信息：请输入手机号码\"\n    # 判断输入的字符的长度是否合法\n    if len(phone) == 11:\n        # 判断是否156/186/188开头\n        if phone.startswith(\"156\") or phone.startswith(\"186\") or phone.startswith(\"188\"):\n            # 判断每一个字符都是数字\n            for num in phone:\n                # isdigit()函数用于判断调用者是否数字\n                if not num.isdigit():\n                    msg = \"不能包含非法字符\"\n                    return msg\n            msg = \"手机号码合法\"\n        else:\n            msg = \"开头数字不合法\"\n    else:\n        msg = \"长度不合法\"\n    return msg\n\n# 开始测试\nprint(validatePhone(userphone))\n```\n\n执行上面的代码，分别输入不同的手机号码，结果如下\n\n> 请输入手机号码：188\n> 长度不合法\n>\n> 请输入手机号码：15568686868\n> 开头数字不合法\n>\n> 请输入手机号码：1566868686a\n> 不能包含非法字符\n>\n> 请输入手机号码：15688888888\n> 手机号码合法\n\n我们再次使用正则表达式来改造这段程序\n*注意：如果下面的程序中出现了一些语法不是很明白，没关系，后面会详细讲解*\n\n```python\nimport re\n\n# 接收用户输入\nuserphone = input(\"请输入手机号码\")\n\n# 定义验证手机号码的函数\ndef validatePhone(phone):\n    # 定义正则表达式，Python中的正则表达式还是一个字符串，是以r开头的字符串\n    regexp = r\"^(156|186|188)\\d{8}$\"\n    # 开始验证\n    if re.match(regexp, phone):\n        return \"手机号码合法\"\n    else:\n        return \"手机号码只能156/186/188开头，并且每一个字符都是数字，请检查\"\n\n# 开始验证\nprint(validatePhone(userphone))\n```\n\n执行上面的代码，我们得到正常验证的结果，大家可以自己试一试。\n我们从这两套代码中，可以看出来，使用了正则表达式之后的程序变得非常简洁了，那保持好你的冲动和热情，让正则表达式来搞事吧\n\n###### 2.3. python 中的正则表达式模块 re\n\npython 提供的正则表达式处理模块 re，提供了各种正则表达式的处理函数\n\n**2.3.1 字符串查询匹配的函数：**\n\n| 函数                      | 描述                                       |\n| ----------------------- | ---------------------------------------- |\n| re.match(reg, info)     | 用于在**开始位置**匹配目标字符串 info 中符合正则表达式 reg 的字符，匹配成功会返回一个 match 对象，匹配不成功返回 None |\n| re.search(reg, info)    | 扫描**整个字符串 info**，使用正则表达式 reg 进行匹配，匹配成功返回匹配的第一个 match 对象，匹配不成功返回 None |\n| re.findall(reg, info)   | 扫描**整个字符串 info**，将符合正则表达式 reg 的字符全部提取出来存放在列表中返回 |\n| re.fullmatch(reg, info) | 扫描整个字符串，如果整个字符串都包含在正则表达式表示的范围中，返回整个字符串，否则返回 None |\n| re.finditer(reg, info)  | 扫描整个字符串，将匹配到的字符保存在一个可以遍历的列表中             |\n\n参考官方 re.py 源代码如下：\n\n```python\ndef match(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern at the start of the string, returning\n    a match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).match(string)\n\ndef fullmatch(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern to all of the string, returning\n    a match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).fullmatch(string)\n\ndef search(pattern, string, flags=0):\n    \"\"\"Scan through string looking for a match to the pattern, returning\n    a match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).search(string)\n\ndef findall(pattern, string, flags=0):\n    \"\"\"Return a list of all non-overlapping matches in the string.\n\n    If one or more capturing groups are present in the pattern, return\n    a list of groups; this will be a list of tuples if the pattern\n    has more than one group.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).findall(string)\n\ndef finditer(pattern, string, flags=0):\n    \"\"\"Return an iterator over all non-overlapping matches in the\n    string.  For each match, the iterator returns a match object.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).finditer(string)\n```\n\n**2.3.2 字符串拆分替换的函数：**\n\n| 函数                        | 描述                                       |\n| ------------------------- | ---------------------------------------- |\n| re.split(reg, string)     | 使用指定的正则表达式 reg 匹配的字符，将字符串 string 拆分成一个字符串列表，如：re.split(r\"\\s+\", info)，表示使用一个或者多个空白字符对**字符串 info** 进行拆分，并返回一个拆分后的字符串列表 |\n| re.sub(reg, repl, string) | 使用**指定的字符串 repl** 来**替换目标字符串 string** 中**匹配正则表达式 reg** 的字符 |\n\n参考官方源代码如下：\n\n```python\ndef split(pattern, string, maxsplit=0, flags=0):\n    \"\"\"Split the source string by the occurrences of the pattern,\n    returning a list containing the resulting substrings.  If\n    capturing parentheses are used in pattern, then the text of all\n    groups in the pattern are also returned as part of the resulting\n    list.  If maxsplit is nonzero, at most maxsplit splits occur,\n    and the remainder of the string is returned as the final element\n    of the list.\"\"\"\n    return _compile(pattern, flags).split(string, maxsplit)\n\ndef sub(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in string by the\n    replacement repl.  repl can be either a string or a callable;\n    if a string, backslash escapes in it are processed.  If it is\n    a callable, it's passed the match object and must return\n    a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).sub(repl, string, count)\n```\n\n接下来，我们进入正则表达式干货部分\n\n###### 2.4. 正则表达式中的元字符\n\n在使用正则表达式的过程中，一些包含特殊含义的字符，用于表示字符串中一些特殊的位置，非常重要，我们先简单了解一下一些常用的元字符\n\n| 元字符  | 描述                       |\n| ---- | ------------------------ |\n| ^    | 表示匹配字符串的开头位置的字符          |\n| $    | 表示匹配字符串的结束位置的字符          |\n| .    | 表示匹配任意一个字符               |\n| \\d   | 匹配一个数字字符                 |\n| \\D   | 匹配一个非数字字符                |\n| \\s   | 匹配一个空白字符                 |\n| \\S   | 匹配一个非空白字符                |\n| \\w   | 匹配一个数字 / 字母 / 下划线中任意一个字符 |\n| \\W   | 匹配一个非数字字母下划线的任意一个字符      |\n| \\b   | 匹配一个单词的边界                |\n| \\B   | 匹配不是单词的开头或者结束位置          |\n\n上干货：代码案例\n\n```python\n# 导入正则表达式模块\nimport re\n\n# 定义测试文本字符串，我们后续在这段文本中查询数据\nmsg1 = \"\"\"Python is an easy to learn, powerful programming language.\nIt has efficient high-level data structures and a simple but effective approach to object-oriented programming.\nPython’s elegant syntax and dynamic typing, together with its interpreted nature, \nmake it an ideal language for scripting and rapid application development in many areas on most platforms.\n\"\"\"\nmsg2 = \"hello\"\nmsg3 = \"hello%\"\n\n# 定义正则表达式，匹配字符串开头是否为python\nregStart = r\"efficient\"\n\n# 从字符串开始位置匹配，是否包含符合正则表达式的内容，返回匹配到的字符串的Match对象\nprint(re.match(regStart, msg1))\n# 扫描整个字符串，是否包含符合正则表达式的内容，返回匹配到的第一个字符串的Match对象\nprint(re.search(regStart, msg1))\n# 扫描整个字符串，是否包含符合正则表达式的内容，返回匹配到的所有字符串列表\nprint(re.findall(regStart, msg1))\n# 扫描整个字符串，是否包含符合正则表达式的内容，返回匹配到的字符串的迭代对象\nfor r in re.finditer(regStart, msg1):\n    print(\"->\"+ r.group())\n# 扫描整个字符串，是否包含在正则表达式匹配的内容中，是则返回整个字符串，否则返回None\nprint(re.fullmatch(r\"\\w*\", msg2))\nprint(re.fullmatch(r\"\\w*\", msg3))\n```\n\n上述代码执行结果如下：\n\n> ~ None\n> ~<sre.SRE_Match object; span=(66, 75), match='efficient'>\n> ~['efficient']\n> ~->efficient\n> ~<sre.SRE_Match object; span=(0, 5), match='hello'>\n> ~None\n\n###### 2.5. 正则表达式中的量词\n\n正则表达式中的量词，是用于限定数量的特殊字符\n\n| 量词     | 描述                                |\n| ------ | --------------------------------- |\n| x*     | 用于匹配符号 * 前面的字符出现 0 次或者多次          |\n| x+     | 用于匹配符号 + 前面的字符出现 1 次或者多次          |\n| x？     | 用于匹配符号？前面的字符出现 0 次或者 1 次          |\n| x{n}   | 用于匹配符号 {n} 前面的字符出现 n 次            |\n| x{m,n} | 用于匹配符号 {m,n} 前面的字符出现至少 m 次，最多 n 次 |\n| x{n,}  | 用于匹配符号 {n,} 前面的字符出现至少 n 次         |\n\n接上代码干货：\n\n```python\n# 导入正则表达式模块\nimport re\n\n# 定义测试文本字符串，我们后续在这段文本中查询数据\nmsg1 = \"\"\"goodgoodstudy!,dooodooooup\"\"\"\n\n# 匹配一段字符串中出现单词o字符0次或者多次的情况\nprint(re.findall(r\"o*\", msg1))\n# 匹配一段字符串中出现单词o字符1次或者多次的情况\nprint(re.findall(r\"o+\", msg1))\n# 匹配一段字符串中出现单词o字符0次或者1次的情况\nprint(re.findall(r\"o?\", msg1))\n# 匹配字符串中连续出现2次字符o的情况\nprint(re.findall(r\"o{2}\", msg1))\n# 匹配字符串中连续出现2次以上字符o的情况\nprint(re.findall(r\"o{2,}\", msg1))\n# 匹配字符串中连续出现2次以上3次以内字符o的情况\nprint(re.findall(r\"o{2,3}\", msg1))\n```\n\n上述代码大家可以自行尝试并分析结果。执行结果如下：\n\n###### 2.6. 正则表达式中的范围匹配\n\n在正则表达式中，针对字符的匹配，除了快捷的元字符的匹配，还有另一种使用方括号进行的范围匹配方式，具体如下：\n\n| 范围            | 描述                               |\n| ------------- | -------------------------------- |\n| [0-9]         | 用于匹配一个 0~9 之间的数字，等价于 \\ d         |\n| [^0-9]        | 用于匹配一个非数字字符，等价于 \\ D              |\n| [3-6]         | 用于匹配一个 3~6 之间的数字                 |\n| [a-z]         | 用于匹配一个 a~z 之间的字母                 |\n| [A-Z]         | 用于匹配一个 A~Z 之间的字母                 |\n| [a-f]         | 用于匹配一个 a~f 之间的字母                 |\n| [a-zA-Z]      | 用于匹配一个 a~z 或者 A-Z 之间的字母，匹配任意一个字母 |\n| [a-zA-Z0-9]   | 用于匹配一个字母或者数字                     |\n| [a-zA-Z0-9_]  | 用于匹配一个字母或者数字或者下划线，等价于 \\ w        |\n| [^a-zA-Z0-9_] | 用于匹配一个非字母或者数字或者下划线，等价于 \\ W       |\n\n*注意：不要使用 [0-120] 来表示 0~120 之间的数字，这是错误的*\n\n整理测试代码如下：\n\n```python\n# 引入正则表达式模块\nimport re\n\nmsg = \"Hello, The count of Today is 800\"\n# 匹配字符串msg中所有的数字\nprint(re.findall(r\"[0-9]+\", msg))\n# 匹配字符串msg中所有的小写字母\nprint(re.findall(r\"[a-z]+\", msg))\n# 匹配字符串msg中所有的大写字母\nprint(re.findall(r\"[A-Z]+\", msg))\n# 匹配字符串msg中所有的字母\nprint(re.findall(r\"[A-Za-z]+\", msg))\n```\n\n上述代码执行结果如下：\n\n> ['800']\n> ['ello', 'he', 'count', 'of', 'oday', 'is']\n> ['H', 'T', 'T']\n> ['Hello', 'The', 'count', 'of', 'Today', 'is']\n\n###### 2.7. 正则表达式中的分组\n\n正则表达式主要是用于进行字符串检索匹配操作的利器\n在一次完整的匹配过程中，可以将匹配到的结果进行分组，这样就更加的细化了我们对匹配结果的操作\n正则表达式通过圆括号 () 进行分组，以提取匹配结果的部分结果\n\n常用的两种分组：\n\n| 分组                   | 描述                                       |\n| -------------------- | ---------------------------------------- |\n| (expression)         | 使用圆括号直接分组；正则表达式本身匹配的结果就是一个组，可以通过 group() 或者 group(0) 获取；然后正则表达式中包含的圆括号就是按照顺序从 1 开始编号的小组 |\n| (?P<name>expression) | 使用圆括号分组，然后给当前的圆括号表示的小组命名为 name，可以通过 group(name) 进行数据的获取 |\n\n废话少说，上干货：\n\n```python\n# 引入正则表达式模块\nimport re\n\n# 用户输入座机号码，如\"010-6688465\"\nphone = input(\"请输入座机号码：\")\n# 1.进行正则匹配,得到Match对象，对象中就包含了分组信息\nres1 = re.search(r\"^(\\d{3,4})-(\\d{4,8})$\", phone)\n# 查看匹配结果\nprint(res1)\n# 匹配结果为默认的组，可以通过group()或者group(0)获取\nprint(res1.group())\n# 获取结果中第一个括号对应的组数据：处理区号\nprint(res1.group(1))\n# 获取结果中第二个括号对应的组数据：处理号码\nprint(res1.group(2))\n\n# 2.进行正则匹配,得到Match对象，对象中就包含了命名分组信息\nres2 = re.search(r\"^(?P<nstart>\\d{3,4})-(?P<nend>\\d{4,8})$\", phone)\n# 查看匹配结果\nprint(res2)\n# 匹配结果为默认的组，可以通过group()或者group(0)获取\nprint(res2.group(0))\n# 通过名称获取指定的分组信息：处理区号\nprint(res2.group(\"nstart\"))\n# 通过名称获取指定分组的信息：处理号码\nprint(res2.group(\"nend\"))\n```\n\n上述代码就是从原始字符串中，通过正则表达式匹配得到一个结果，但是使用了分组之后，就可以将结果数据通过分组进行细化处理，执行结果如下：\n\n> 请输入座机号码：021-6565789\n> <_sre.SRE_Match object; span=(0, 11), match='021-6565789'>\n> 021-6565789\n> 021\n> 6565789\n> <_sre.SRE_Match object; span=(0, 11), match='021-6565789'>\n> 021-6565789\n> 021\n> 6565789\n\n###### 2.8. 正则表达式中的特殊用法\n\n使用分组的同时，会有一些特殊的使用方式如下：\n\n| 表达式             | 描述                                       |\n| --------------- | ---------------------------------------- |\n| (?:expression)  | 作为正则表达式的一部分，但是匹配结果丢弃                     |\n| (?=expression)  | 匹配 expression 表达式前面的字符，如 \"How are you doing\" , 正则 \"(?<txt>.+(?=ing))\" 这里取 ing 前所有的字符，并定义了一个捕获分组名字为 \"txt\" 而 \"txt\" 这个组里的值为 \"How are you do\" |\n| (?<=expression) | 匹配 expression 表达式后面的字符，如 \"How are you doing\" 正则 \"(?<txt>(?<=How).+)\"这里取\"How\"之后所有的字符，并定义了一个捕获分组名字为\"txt\"而\"txt\"这个组里的值为\" are you doing\"; |\n| (?!expression)  | 匹配字符串后面不是 expression 表达式字符，如 \"123abc\" 正则 \"\\d{3}(?!\\d)\" 匹配 3 位数字后非数字的结果 |\n| (?<!expression) | 匹配字符串前面不是 expression 表达式字符，如 \"abc123\" 正则 \"(?<![0-9])123\"匹配\"123\"前面是非数字的结果也可写成\"(?!<\\d)123\" |\n\n### 2.9 正则表达式的贪婪模式和懒惰模式\n\n在某些情况下，我们匹配的字符串出现一些特殊的规律时，就会出现匹配结果不尽如人意的意外情况\n如：在下面的字符串中，将 div 标签中的所有内容获取出来\n\n```\n<div>内容1</div><p>这本来是不需要的内容</p><div>内容2</div>\n```\n\n此时，我们想到的是，使用 <div> 作为关键信息进行正则表达式的定义，如下\n\n```\nregexp = r\"<div>.*</div>\"\n```\n\n本意是使用上述代码来完成 div 开始标签和结束标签之间的内容匹配，但是，匹配的结果如下\n\n```\n<div> [内容1</div><p>这本来是不需要的内容</p><div>内容2] </div>\n```\n\n我们可以看到，上面匹配的结果，是将字符串开头的 <div> 标签和字符串结束的 </div> 当成了匹配元素，对包含在中间的内容直接进行了匹配，也就得到了我们期望之外的结果：\n\n```\n内容1</div><p>这本来是不需要的内容</p><div>内容2\n```\n\n上述就是我们要说的正则表达式的第一种模式：贪婪模式\n**贪婪模式**：正则表达式匹配的一种模式，速度快，但是匹配的内容会从字符串两头向中间搜索匹配（比较贪婪~），一旦匹配选中，就不继续向字符串中间搜索了，过程如下：\n\n```html\n开始：<div>内容1</div><p>这本来是不需要的内容</p><div>内容2</div>\n\n第一次匹配：【<div>内容1</div><p>这本来是不需要的内容</p><div>内容2</div>】\n\n第二次匹配<div>【内容1</div><p>这本来是不需要的内容</p><div>内容2】</div>\n\n匹配到正则中需要的结果，不再继续匹配，直接返回匹配结果如下：\n内容1</div><p>这本来是不需要的内容</p><div>内容2\n```\n\n明显贪婪模式某些情况下，不是我们想要的，所以出现了另一种模式：懒惰模式\n**懒惰模式**：正则表达式匹配的另一种模式，会首先搜索匹配正则表达式开始位置的字符，然后逐步向字符串的结束位置查找，一旦找到匹配的就返回，然后接着查找\n\n```\nregexp = r\"<div>.*?</div>\"\n```\n\n```html\n开始：<div>内容1</div><p>这本来是不需要的内容</p><div>内容2</div>\n\n第一次匹配：【<div>】内容1</div><p>这本来是不需要的内容</p><div>内容2</div>\n\n第二次匹配【<div>内容1</div>】<p>这本来是不需要的内容</p><div>内容2</div>\n\n匹配到正则中需要的结果：内容1\n\n继续向后查找\n\n第三次匹配<div>内容1</div>【<p>这本来是不需要的内容</p>】<div>内容2</div>\n\n第四次匹配<div>内容1</div><p>这本来是不需要的内容</p>【<div>内容2</div>】\n\n匹配到正则中需要的结果：内容2\n\n查找字符串结束！\n```\n\n> 正则表达式匹配的两种模式：贪婪模式、懒惰模式\n> **贪婪模式**：从目标字符串的两头开始搜索，一次尽可能多的匹配符合条件的字符串，但是有可能会匹配到不需要的内容，正则表达式中的元字符、量词、范围等都模式是贪婪匹配模式，使用的时候一定要注意分析结果，如：`<div>.*</div>`就是一个贪婪模式，用于匹配 <div> 和 </div> 之间所有的字符\n> **懒惰模式**：从目标字符串按照顺序从头到位进行检索匹配，尽可能的检索到最小范围的匹配结果，语法结构是在贪婪模式的表达式后面加上一个符号? 即可，如`<div>.*?</div>`就是一个懒惰模式的正则，用于仅仅匹配最小范围的 <div> 和 </div> 之间的内容\n>\n> 不论贪婪模式还是懒惰模式，都有适合自己使用的地方，大家一定要根据实际需求进行解决方案的确定\n\n \n\n**转载: https://www.imooc.com/article/22158**","tags":["Python"],"categories":["技术加油站"]},{"path":"/about/index.html","content":"读一些无用的书，做一些无用的事，花一些无用的时间，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。 🎵 音乐的素食主义，🎦 电影的杂食主义者🎧 戴上耳机的聋子，🤓 摘掉眼镜的瞎子💔 午夜网抑云会员，🔭 人间美好事物观察者🏆 职业熬夜选手，😐 发呆业务爱好者"},{"path":"/friends/index.html","content":"读一些无用的书，做一些无用的事，花一些无用的时间，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。 先友后链，在我们有一定了解了之后才可以交换友链，除此之外，您的网站还应满足以下全部条件： 1. 合法的、非营利性、无商业广告、无木马植入。 2. 有实质性原创内容的 HTTPS 站点，发布过至少 5 篇原创文章，内容题材不限。 3. 有独立域名，非免费域名。 4. 博客已运行至少半年，非刚搭建好。"},{"path":"/more/index.html","content":"读一些无用的书，做一些无用的事，花一些无用的时间，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。 平时的所见所闻或是接触到的知识点，不系统，比较凌乱，只做记录或是分享详情见：#issues"},{"path":"/notes/index.html","content":"color:error 前言 日常接触到的知识点，不系统，比较凌乱，只作记录，整理后转至 WIKI (专栏)"},{"title":"数据库","path":"/notes/database/index.html","content":"trdsqlcolor:yellow codeblock:true open:false trdsql 使用示例```sh./trdsql -oat -config config.json \"select * from table_example where id=1\"```color:blue codeblock:true open:false config.json 配置示例```json{ \"db\": \"mdb\", \"database\": { \"sdb\": { \"driver\": \"sqlite3\", \"dsn\": \"\" }, \"pdb\": { \"driver\": \"postgres\", \"dsn\": \"user=test dbname=test\" }, \"mdb\": { \"driver\": \"mysql\", \"dsn\": \"test:test@tcp(ubuntu.wsl:4000)/example?charset=utf8mb4\" } }}```"},{"title":"Docker","path":"/notes/docker/index.html","content":"## 容器技术\n**四个组成部分**\n- `镜像` 包含虚拟运行环境的文件包，是一堆文件的合集，服务在该系统之上能够运行起来。docker 镜像采用了分层架构。\n- `容器` 镜像的运行状态，用来隔离虚拟环境的基础设施。主要包含：镜像、运行环境、指令集\n- `网络` 网络是应用之间通讯的媒介。\n- `数据卷` 应用肯定会涉及到数据持久化操作，数据卷就是用于宿主机和容器之间共享或者持久化。\n**三点技术**\n- `Namespace 命名空间` 作用是隔离\n- `Control Groups 控制组` 作用是限制计算机资源的使用\n- `Union File System 联合文件系统` 作用是实现不同目录挂载到同一目录\n\n## docker logs－查看 docker 容器日志\n**命令格式：**\n```sh\ndocker logs [OPTIONS] CONTAINER\n  Options:\n        --details        显示更多的信息\n    -f, --follow         跟踪实时日志\n        --since string   显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟）\n        --tail string    从日志末尾显示多少行日志， 默认是all\n    -t, --timestamps     显示时间戳\n        --until string   显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟）\n```\n\n**例子：**\n查看指定时间后的日志，只显示最后 100 行：\n```sh\ndocker logs -f -t --since=\"2018-02-08\" --tail=100 CONTAINER_ID\n```\n\n查看最近 30 分钟的日志:\n```sh\ndocker logs --since 30m CONTAINER_ID\n```\n\n查看某时间之后的日志：\n```sh\ndocker logs -t --since=\"2018-02-08T13:23:37\" CONTAINER_ID\n```\n\n查看某时间段日志：\n```sh\ndocker logs -t --since=\"2018-02-08T13:23:37\" --until \"2018-02-09T12:23:37\" CONTAINER_ID\n```"},{"title":"Git","path":"/notes/git/index.html","content":"git commit emoji 使用指南目录* commit 格式* emoji 指南* 如何在命令行中显示 emoji执行 `git commit` 时使用 emoji 为本次提交打上一个 \"标签\", 使得此次 commit 的主要工作得以凸现，也能够使得其在整个提交历史中易于区分与查找。例如，gitmojicommit 格式`git commit` 时，提交信息遵循以下格式：```sh:emoji1: :emoji2: 不超过 50 个字的摘要，首字母大写，使用祈使语气，句末不要加句号提交信息主体引用相关 issue 或 PR 编号 <#110>```初次提交示例：```shgit commit -m \":tada: Initialize Repo\"```emoji 指南emoji   emoji 代码   commit 说明:--------   :--------   :--------🎉 (庆祝)   `:tada:`    初次提交🆕 (全新)✨ (火花)   `:new:` `:sparkles:`   引入新功能 feature🔖 (书签)   `:bookmark:`    发行/版本标签🐛 (bug)  `:bug:`   修复 bug🚑 (急救车)  `:ambulance:`   重要补丁🌐 (地球)   `:globe_with_meridians:`    国际化与本地化💄 (口红)   `:lipstick:`   更新 UI 和样式文件🎬 (场记板)  `:clapper:`  更新演示/示例🚨 (警车灯)  `:rotating_light:`   移除 linter 警告🔧 (扳手)   `:wrench:`   修改配置文件➕ (加号)   `:heavy_plus_sign:`  增加一个依赖➖ (减号)   `:heavy_minus_sign:`   减少一个依赖⬆️ (上升箭头)  `:arrow_up:`   升级依赖⬇️ (下降箭头)  `:arrow_down:`   降级依赖⚡ (闪电)🐎 (赛马)   `:zap:`  `:racehorse:`  提升性能📈 (上升趋势图)  `:chart_with_upwards_trend:`   添加分析或跟踪代码🚀 (火箭)   `:rocket:`   部署功能✅ (白色复选框)  `:white_check_mark:`   增加测试📝 (备忘录)📖 (书)  `:memo:``:book:`   撰写文档🔨 (锤子)   `:hammer:`   重大重构🎨 (调色板)  `:art:`  改进代码结构/代码格式🔥 (火焰)   `:fire:`   移除代码或文件✏️ (铅笔)  `:pencil2:`  修复 typo🚧 (施工)   `:construction:`   工作进行中🗑️ (垃圾桶)   `:wastebasket:`  废弃或删除♿ (轮椅)   `:wheelchair:`   可访问性👷 (工人)   `:construction_worker:`  添加 CI 构建系统💚 (绿心)   `:green_heart:`  修复 CI 构建问题🔒 (锁)  `:lock:`   修复安全问题🐳 (鲸鱼)   `:whale:`  Docker 相关工作🍎 (苹果)   `:apple:`  修复 macOS 下的问题🐧 (企鹅)   `:penguin:`  修复 Linux 下的问题🏁 (旗帜)   `:checkered_flag:`   修复 Windows 下的问题🔀 (交叉箭头)   `:twisted_rightwards_arrows:`  分支合并🤖 (机器人)  `:robot:`  修复 Android 下的问题🍏 (苹果)   `:green_apple:`  修复 IOS下的问题📌 (图钉)   `:pushpin:`  依赖固定到特定版本♻️ (回收)  `:recycle:`  添加 CI 构建系统📦(包裹)  `:package:`  更新编译文件或Package👽 (外星人)  `:alien:`  由于外部API的更改而更新了代码🚚 (卡车)   `:truck:`  移动或重命名文件📄(文件)  `:page_facing_up:`   添加或更新 Licence💥 (隆隆声)  `:boom:`   引入重大变化🍱 (便当)   `:bento:`  添加或更新 Assets👌(OK)  `:ok_hand:`  由于代码评审更改而更新代码♿ (轮椅)   `:wheelchair:`   提高可访问性💡 (电灯泡)  `:bulb:`   记录源代码🍻 (啤酒)   `:beers:`  醉醺醺地编写代码💬 (发言)   `:speech_balloon:`   更新文本和文字🗃️ (文件盒)   `:card_file_box:`  执行与数据库相关的更改🔊 (巨大声响)   `:loud_sound:`   添加日志🔇 (静音)   `:mute:`   移除日志👥 (轮廓半身像)  `:busts_in_silhouette:`  添加贡献者🚸 (儿童通过)   `:children_crossing:`  提高用户体验/可用性🏗️ (房屋)  `:building_construction:`  使建筑变化📱 (苹果手机)   `:iphone:`   致力于响应式设计🤡 (小丑)   `:clown_face:`   Mock 相关🥚(彩蛋)  `:egg:`  加入一个复活节彩蛋🙈(非礼勿视)  `:see_no_evil:`  添加或更新 .gitignore 文件📸 (相机)   `:camera_flash:`   添加或更新快照⚗️ (蒸馏器)   `:alembic:`  尝试新事物🔍 (放大镜)  `:mag:`  SEO 提升☸️ (达摩车轮)  `:wheel_of_dharma:`  Kubernetes 相关工作🏷️ (标签)  `:label:`  添加或更新 types (Flow, TypeScript)🌱 (种子)   `:seedling:`   添加或更新种子文件🚩 (旗帜)   `:triangular_flag_on_post:`  添加、更新或删除功能标志💫 (头昏眼花)   `:dizzy:`  添加或更新动画和转换如何在命令行中显示 emoji默认情况下，在命令行中并不会显示出 emoji, 仅显示 emoji 代码。不过可以使用 emojify 使得在命令行也可显示 emoji, 它是一个 shell 脚本，安装与使用都很简单，在 这里 查看如何安装与使用。"},{"title":"Kubernetes","path":"/notes/kubernetes/index.html","content":"K8S 的架构open:true 像大多数的分布式系统，K8S 集群至少需要一个主节点 Master 和多个计算节点 Nodecolor:blue Master（控制节点）**由三个紧密协作的独立组件组合而成**- 负责 API 服务的 `kube-apiserver`- 负责调度的 `kube-scheduler`- 负责容器编排的 `kube-controller-manager`整个集群的持久化数据，则由 kube-apiserver 处理后保存在 `Etcd` 中color:green Node（计算节点）最核心的是 `kubelet` 的组件，具备以下功能- **负责同容器运行时（比如 Docker 项目）打交道**。而这个交互所依赖的，是一个称作 `CRI（Container Runtime Interface）`的远程调用接口，这个接口定义了容器运行时的各项核心操作- **通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互**。这个插件，是 K8S 项目用来管理 GPU 等宿主机物理设备的主要组件- **调用网络插件和存储插件为容器配置网络和持久化存储**。这两个插件与 kubelet 进行交互的接口，分别是 `CNI（Container Networking Interface）`和 `CSI（Container Storage Interface）`**补充：**K8S 项目并不关心你部署的是什么容器运行时、使用的什么技术实现，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 `CRI` 接入到 K8S 项目当中；而具体的容器运行时，比如 `Docker` 项目，则一般通过 `OCI` 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 `CRI` 请求翻译成对 Linux 操作系统的调用（操作 Linux Namespace 和 Cgroups 等）Prometheus、Metrics Server 与 K8S 监控体系Prometheus 项目工作的核心，是使用 **Pull** （抓取）的方式去搜集被监控对象的 Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，以便后续可以按照时间进行检索；其主要的特点如下：- **多维度的数据模型**：由指标名称和键 / 值对标签标识的时间序列数据来组成多维的数据模型。- **灵活的查询语言**：在 Prometheus 中使用强大的查询语言 PromSQL 来进行查询。- **不依赖分布式存储**，Prometheus 单个节点也可以直接工作，支持本地存储（TSDB）和远程存储的模式。- **服务端采集数据**：Prometheus 基于 HTTP pull 方式去对不同的端采集时间序列数据。- **客户端主动推送**：支持通过 PushGateway 组件主动推送时间序列数据。Prometheus 作用和工作方式，如下图Prometheus 剩下的组件就是用来配合这套机制的运行- **Prometheus Serve**r：Prometheus 服务端，用于收集指标和存储时间序列数据，并提供一系列的查询和设置接口。- **Client Libraries**：客户端库，用于帮助需要监控采集的服务暴露 metrics handler 给 Prometheus server，直接调用 promhttp 暴露了一个 metrics 接口。- **Push Gateway**：推送网关，Prometheus 服务端仅支持 HTTP pull 的采集方式，而有一些指存在的时间短，Prometheus 来 pull 前就结束了。又或是该类指标，就是要客户端自行上报的，这时候就可以采用 Push Gateway 的方式，客户端将指标 push 到 Push Gateway，再由 Prometheus Server 从 Pushgateway 上 pull- **Exporters**：用于暴露已有的第三方服务的 metrics 给 Prometheus Server- **Alertmanager**：可以根据 Metrics 信息灵活地设置报警，从 Prometheus server 端接收到 alerts 后，会进行去重，分组，然后路由到对应的 Receiver，发出报警- **Grafana**：对外暴露出的、可以灵活配置的监控数据可视化界面按照 Metrics 数据的来源，来对 K8S 的监控体系做一个汇总：- **第一种 Metrics，是宿主机的监控数据。**这部分数据的提供，需要借助一个由 Prometheus 维护的Node Exporter 工具- **第二种 Metrics，是来自于 Kubernetes 的 API Server、kubelet 等组件的 /metrics API**。除了常规的 CPU、内存的信息外，这部分信息还主要包括了各个组件的核心监控指标。比如，对于 API Server 来说，它就会在 /metrics API 里，暴露出各个 Controller 的工作队列- **第三种 Metrics，是 Kubernetes 相关的监控数据。**这部分数据，一般叫作 Kubernetes 核心监控数据（core metrics）。这其中包括了 Pod、Node、容器、Service 等主要 Kubernetes 核心概念的 Metrics。其中，容器相关的 Metrics 主要来自于 kubelet 内置的 `cAdvisor` 服务。在 kubelet 启动后，cAdvisor 服务也随之启动，而它能够提供的信息，可以细化到每一个容器的 CPU 、文件系统、内存、网络等资源的使用情况。需要注意的是，这里提到的 Kubernetes 核心监控数据，其实使用的是 Kubernetes 的一个非常重要的扩展能力，叫作 `Metrics Server`。声明式 API 和 K8S 控制器> 声明式 API**是 Kubernetes 项目编排能力“赖以生存”的核心所在**- 首先，所谓“声明式”，指的就是我只需要提交一个定义好的 API 对象来“声明”，我所期望的状态是什么样子- 其次，“声明式 API”允许有多个 API 写端，以 PATCH 的方式对 API 对象进行修改，而无需关心本地原始 YAML 文件的内容- 最后，也是最重要的，有了上述两个能力，Kubernetes 项目才可以基于对 API 对象的增、删、改、查，在完全无需外界干预的情况下，完成对“实际状态”和“期望状态”的调谐（Reconcile）过程实际运用项目：**Istio 项目使用的，是 K8S 中的一个非常重要的功能，叫作 Dynamic Admission Control（动态入场控制），也叫作：Initializer（初始化器）。提供了一种“热插拔”式的 Admission 机制**> Kubernetes 控制器GPU 在容器云中的方案及使用核心功能模块:- `GPU Share Scheduler Extender`: 利用 Kubernetes 的调度器扩展机制，负责在全局调度器 Filter 和 Bind 的时候判断节点上单个 GPU 卡是否能够提供足够的 GPU Mem，并且在 Bind 的时刻将 GPU 的分配结果通过 annotation 记录到 Pod Spec 以供后续 Filter 检查分配结果。- `GPU Share Device Plugin`: 利用 `Device Plugin` 机制，在节点上被 Kubelet 调用负责 GPU 卡的分配，依赖 scheduler Extender 分配结果执行。具体流程：1. 资源上报 GPU Share Device Plugin利用nvml库查询到GPU卡的数量和每张GPU卡的显存， 通过 `ListAndWatch()` 将节点的GPU总显存（数量 *显存）作为另外 Extended Resource 汇报给 Kubelet； Kubelet 进一步汇报给 Kubernetes API Server*2. 扩展调度 GPU Share Scheduler Extender 可以在分配 gpu-mem 给 Pod 的同时将分配信息以 annotation 的形式保留在 Pod spec 中，并且在过滤时刻根据此信息判断每张卡是否包含足够可用的 gpu-mem 分配。3. 节点上运行 当Pod和节点绑定的事件被Kubelet接收到后，Kubelet就会在节点上创建真正的Pod实体，在这个过程中, Kubelet会调用GPU Share Device Plugin的 `Allocate` 方法, `Allocate` 方法的参数是Pod申请的gpu-mem。而在 `Allocate` 方法中，会根据GPU Share Scheduler Extender的调度决策运行对应的Pod"},{"title":"Linux","path":"/notes/linux/index.html","content":"Systemctl 守护进程Unit 介绍> **Systemd** 可以管理所有系统资源。不同的资源统称为 `Unit（单位）`。**`systemctl list-units` 命令可以查看当前系统的所有 Unit**```sh# 列出正在运行的 Unitsystemctl list-units# 列出所有Unit，包括没有找到配置文件的或者启动失败的systemctl list-units --all# 列出所有没有运行的 Unitsystemctl list-units --all --state=inactive# 列出所有加载失败的 Unitsystemctl list-units --failed# 列出所有正在运行的、类型为 service 的 Unitsystemctl list-units --type=service```**`systemctl status` 命令用于查看系统状态和单个 Unit 的状态**```sh# 显示系统状态systemctl status# 显示单个 Unit 的状态sysystemctl status bluetooth.service# 显示远程主机的某个 Unit 的状态systemctl -H root@rhel7.example.com status httpd.service除了 status 命令，systemctl 还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。# 显示某个 Unit 是否正在运行systemctl is-active application.service# 显示某个 Unit 是否处于启动失败状态systemctl is-failed application.service# 显示某个 Unit 服务是否建立了启动链接systemctl is-enabled application.service```**最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）**```sh# 立即启动一个服务sudo systemctl start apache.service# 立即停止一个服务sudo systemctl stop apache.service# 重启一个服务sudo systemctl restart apache.service# 杀死一个服务的所有子进程sudo systemctl kill apache.service# 重新加载一个服务的配置文件sudo systemctl reload apache.service# 重载所有修改过的配置文件sudo systemctl daemon-reload# 显示某个 Unit 的所有底层参数systemctl show httpd.service# 显示某个 Unit 的指定属性的值systemctl show -p CPUShares httpd.service# 设置某个 Unit 的指定属性sudo systemctl set-property httpd.service CPUShares=500```Unit 的配置文件> Systemd 默认从目录 `/etc/systemd/system/` 读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录 `/usr/lib/systemd/system/`，真正的配置文件存放在那个目录- `systemctl daemon-reload` 重新加载配置文件- `systemctl enable` 激活开机启动- `systemctl disable` 撤销开机启动color:blue codeblock:true open:false Unit 配置文件示例```sh# vi /lib/systemd/system/example.service[Unit]Description=exampleAfter=network.target[Install]WantedBy=multi-user.target[Service]Type=simpleUser=rootGroup=rootRestart=always# Prevent writes to /usr, /boot, and /etcProtectSystem=full# Doesn't yet work properly with SELinux enabled# NoNewPrivileges=truePrivateDevices=trueWorkingDirectory=/optExecStart=/opt/example --http-port=:8080 --env=pro --apollo-appid=example --apollo-url=http://apollo.example.com:80 --apollo-cluster=exampleKillMode=processKillSignal=SIGTERM# Don't want to see an automated SIGKILL everSendSIGKILL=noRestartSec=1sUMask=007-------------------------```守护进程日志管理color:green codeblock:true open:false Unit 日志常用操作```sh# 查看所有日志（默认情况下 ，只保存本次启动的日志）sudo journalctl# 查看内核日志（不显示应用日志）sudo journalctl -k# 查看系统本次启动的日志sudo journalctl -bsudo journalctl -b -0# 查看上一次启动的日志（需更改设置）sudo journalctl -b -1# 查看指定时间的日志sudo journalctl --since=\"2012-10-30 18:17:16\"sudo journalctl --since \"20 min ago\"sudo journalctl --since yesterdaysudo journalctl --since \"2015-01-10\" --until \"2015-01-11 03:00\"sudo journalctl --since 09:00 --until \"1 hour ago\"# 显示尾部的最新10行日志sudo journalctl -n# 显示尾部指定行数的日志sudo journalctl -n 20# 实时滚动显示最新日志sudo journalctl -f# 查看指定服务的日志sudo journalctl /usr/lib/systemd/systemd# 查看指定进程的日志sudo journalctl _PID=1# 查看某个路径的脚本的日志sudo journalctl /usr/bin/bash# 查看指定用户的日志sudo journalctl _UID=33 --since today# 查看某个 Unit 的日志sudo journalctl -u nginx.servicesudo journalctl -u nginx.service --since today# 实时滚动显示某个 Unit 的最新日志sudo journalctl -u nginx.service -f# 合并显示多个 Unit 的日志journalctl -u nginx.service -u php-fpm.service --since today# 查看指定优先级（及其以上级别）的日志，共有8级# 0: emerg# 1: alert# 2: crit# 3: err# 4: warning# 5: notice# 6: info# 7: debugsudo journalctl -p err -b# 以 JSON 格式（单行）输出sudo journalctl -b -u nginx.service -o json# 以 JSON 格式（多行）输出，可读性更好sudo journalctl -b -u nginx.serviceqq -o json-pretty# 显示日志占据的硬盘空间sudo journalctl --disk-usage# 指定日志文件占据的最大空间sudo journalctl --vacuum-size=1G# 指定日志文件保存多久sudo journalctl --vacuum-time=1years```日志切割转存```shsudo du -ahgrep messages sudo rm messages-202101*sudo vim /etc/logrotate.d/messagelog // 新建messagelog配置/var/log/messages{\tsize 2000000 // 2G\trotate 4 // 保存4份\tcopytruncate\tcompress}sudo vim /etc/logrotate.d/syslog // 注释引用/var/log/messagessudo crontab -e // 新增crontab*/30 * * * * sudo /usr/sbin/logrotate /etc/logrotate.conf sudo crontab -l // 参看crontab```"},{"title":"临时记录","path":"/notes/record/index.html","content":"color:green 每日接触到的知识点，不系统，比较凌乱，只是记录 2020-08-13Uber 的分布式追踪系统 Jaeger 2019-09-19nohup。使用 nohup 命令让程序在关闭窗口（切换 SSH 连接）的时候程序还能继续在后台运行。如：`nohup ./caster &` or `nohup ./caster >/dev/null 2>&1 &  ` 2019-08-29DSL（`Domain Specific Language` 领域特定语言） & GPL（`General Purpose Language` 通用编程语言） 2019-08-28缓存优化，常见缓存算法 & 快照与备份的区别，常见快照机制 `cow` 和 `row` 2019-08-27状态机，有助于编码实现，有限状态机 FSM 的原理与 Go 的实现"},{"title":"常用 Shell","path":"/notes/shell/index.html","content":"## docker cli\n```bash\nkill -9 $(ps -ef|grep caster|awk 'NR==1 {print $3}')\ndocker rmi $(docker images | grep '<none>'| awk '{print $3}')\ndocker rmi $(docker images | grep '<none>'| awk '{next}{print $3}') \numount $(df -h|grep danaos|awk '{print $6}')\n\nshuf -n 1000000 alluser_id | awk '{print $2}' > test_random_1000000\nawk 'END{print NR}' test_random_1000000\n\ndocker inspect --format '{{ .NetworkSettings.IPAddress }}' centos\n\ndocker run -itd --name=centos --privileged=true -v /sys/fs/cgroup:/sys/fs/cgroup -p 8888:8888 centos:centos7 /usr/sbin/init\n```\n\n## 开通防火墙端口\n```bash\niptables -I INPUT -p tcp --dport 8888 -j ACCEPT\n```\n\n## 允许远程主机访问本机的 80 端口\n```bash\niptables -F\niptables -X\niptables -A INPUT -p tcp --dport 80 -j accept\niptables -A INPUT -p tcp -j REJECT\n\n# 或者\niptables -A INPUT -m state --state NEW-m tcp -p tcp --dport 80 -j ACCEPT\n```\n## 查看最大空间占用目录\n```bash\nsudo du -h --exclude=\"mnt*\" --exclude=\"proc*\" -d 1 /\n```\n\n## 监控 linux 磁盘根分区\n- 打印根分区大小\n```bash\n# 注解：awk ‘{print $5}’意思是打印第 5 个域，-F 的意思为分隔，例如以 % 分隔，简单意思就是去掉百分号，awk –F. ‘{print $1}’分隔点. 号\ndf -h |sed -n '//$/p'|awk '{print $5}'|awk –F ”%” '{print $1}'\n```\n\n- if 条件判断该大小是否大于 90，如果大于 90 则发送邮件报警\n```bash\nwhile sleep 5m\ndo\n    for i in `df -h |sed -n '//$/p' |awk '{print $5}' |sed 's/%//g'`\n        do\n            echo $i\n            if [$i -ge 90];then\n            echo “More than 90% Linux of disk space ,Please LinuxSA Check Linux Disk !” |mail -s “Warn Linux / Parts is $i%” \n            XXX@XXX.XX\n            fi\n        done\ndone\n```\n\n## 网络抓包 `tcpdump`\n```bash\n# 抓取 56.7 通过 80 请求的数据包。\ntcpdump -nn host 192.168.56.7 and port 80  \n\n# 80 排除 0.22 80 端口！\ntcpdump -nn host 192.168.56.7 or ! host 192.168.0.22 and port  \n\n# tcp/ip 7 层协议物理层–数据链路层 - 网络层 - 传输层 - 会话层 - 表示层 - 应用层。\n```\n\n## 使用 snmpd 抓取版本为 v2 的 `cacti` 数据方式\n```bash\nsnmpwalk -v2c -c public 192.168.0.241\n```\n\n## CPU 满载测试用例\n```bash\n# 由于连续执行Ｎ个 (Ｎ是CPU个数) 的 dd 命令, 且使用率为100%,　这时调度器会调度每个 dd 命令在不同的 CPU 上处理；最终就实现所有 CPU 占用率 100%\n\nfor i in `seq 1 $(cat /proc/cpuinfo |grep \"physical id\" |wc -l)`; do dd if=/dev/zero of=/dev/null & done\n```\n\n说明:\n- `cat /proc/cpuinfo |grep \"physical id\" | wc -l ` 可以获得 CPU 的个数,　我们将其表示为 N.\n- `seq 1 N ` 用来生成１到Ｎ之间的数字\n- `for i in seq 1 N`;  就是循环执行命令, 从１到Ｎ\n- `dd if=/dev/zero of=/dev/null` 执行 dd 命令,　输出到 `/dev/null`, 实际上只占用 CPU,　没有 IO 操作.\n\n另外，上述程序的结束可以使用：\n1. fg 后按 ctrl + C (因为该命令是放在后台执行)\n2. pkill -9 dd\n\n\n## 查找当前目录下以 `.tar` 的文件移动到指定目录\n```bash\nfind . -name “*.tar” -exec mv {} ./backup/ \n\n# 注解：find –name 主要用于查找某个文件名字，-exec 、xargs 可以用来承接前面的结果，然后将要执行的动作，一般跟 find 在一起用的很多，find 使用我们可以延伸 - mtime 查找修改时间、-type 是指定对象类型（常见包括 f 代表文件、d 代表目录），-size 指定大小，例如经常用到的：查找当前目录 30 天以前大于 100M 的 LOG 文件并删除\nfind . -name \"*.log\" –mtime +30 –typef –size +100M |xargs rm –rf {}\n```\n\n## 批量解压当前目录下 `.zip` 的所有文件到指定目录\n```bash\n# 注解：forI in （command）;do … done 为 for 循环的一个常用格式，其中 I 为变量，可以自己指定\nfor i  in  `find . –name “*.zip”–type f `\ndo\n   unzip –d $i /data/www/img/\ndone\n```\n\n## 判断目录是否存在\n```bash\n# 注解：if…;then …else ..fi：为 if 条件语句,! 叹号表示反义 “不存在 “，-d 代表目录。\nif\n\t[! –d /data/backup/];then\n\tMkdir–p /data/backup/\nelse\n\techo  \"The Directory alreadyexists,please exit\"\nfi\n```\n\n## nginx 日志统计前10个 IP\n```bash\ncd /home/logs/nginx/default\n\n# 注解：sort 排序、uniq（检查及删除文本文件中重复出现的行列 ）\nsort -m -k 4 -o access.logok access.1 access.2 access.3 ..... \n\ncat access.log |awk '{print $1}'|sort -n|uniq -c|sort -nr |head -10\n```\n\n## 打印出一个文件里面最大和最小值\n```bash\ncat a.txt |sort -nr|awk ‘{}END{print} NR==1′\n\ncat a.txt |sort -nr |awk ‘END{print} NR==1′\n\n# 这个才是真正的打印最大最小值：\nsed ‘s/ / /g’ a.txt |sort -nr|sed -n ’1p;$p’\n```\n\n## 查找3天前创建且后缀是 `\\*.log` 的文件并删除\n```bash\nfind . -mtime +3  -name \"*.log\" |xargs rm -rf {} ;\n```\n\n## 将某目录下大于 100k 的文件移动至 `/tmp` 下\n```bash\nfind . -size +100k -exec mv {} /tmp ;\n```\n\n## sed 常用命令\n```bash\n# 如何去掉行首的. 字符: \nsed -i 's/^.//g' test.txt\n\n# 在行首添加一个 a 字符: \nsed 's/^/a/g' test.txt\n\n# 在行尾添加一个 a 字符: \nsed 's/$/a/' tets.txt\n\n# 在特定行后添加一个 c 字符: \nsed '/wuguangke/ac' test.txt\n\n#在行前加入一个 c 字符: \nsed '/wuguangke/ic' test.txt\n\n# 修改文本中以 jk 结尾的替换成 yz\nsed -e ‘s/jk$/yz/g’ b.txt\n\n# sed 冒号方式 \nsed -i ‘s:/tmp:/tmp/abc/:g’test.txt  # 意思是将 /tmp 改成 /tmp/abc/\n```"},{"title":"Windows","path":"/notes/windows/index.html","content":"color:blue 📢&nbsp;公告通知 已整理迁移至 专栏/时间胶囊/Windows 常见问题"},{"title":"前言","path":"/wiki/capsules/index.html","content":"color:error 危险，请不要打开这个color:warning 警告，真的很危险color:error 最后一次警告，千万不要打开这个不要说我没有警告过你"},{"title":"安装与配置","path":"/wiki/git/index.html","content":"git Install Linux安装指定系统的依赖包：$ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev解压安装下载的源码包：$ tar -zxf git-1.7.2.2.tar.gz$ cd git-1.7.2.2$ make prefix=/usr/local all$ sudo make prefix=/usr/local install使用终端指令安装 color:purple$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev$ apt-get install git$ git --versiongit version 1.8.1.2$ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel$ yum -y install git-core$ git --versiongit version 1.7.1 Windows完成安装之后，就可以使用命令行的 git 工具（已经自带了 ssh 客户端）了，另外还有一个图形界面的 Git 项目管理工具。在开始菜单里找到 <kbd>Git</kbd> -> <kbd>Git Bash</kbd>，会弹出 Git 命令窗口，你可以在该窗口进行 Git 操作。 MacMac 自带 git 并且随着系统版本的更新，自带的 git 也会升级到最新，一般无需手动安装。配置Git 提供了一个叫做 `git config` 的工具，专门用来配置或读取相应的工作环境变量。这些环境变量，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下三个不同的地方：- `/etc/gitconfig` 文件：系统中对所有用户都普遍适用的配置。若使用 `git config` 时用 `--system` 选项，读写的就是这个文件。- `~/.gitconfig` 文件：用户目录下的配置文件只适用于该用户。若使用 `git config` 时用 `--global` 选项，读写的就是这个文件。- 当前项目的 Git 目录中的配置文件（也就是工作目录中的 `.git/config` 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 `.git/config` 里的配置会覆盖 `/etc/gitconfig` 中的同名变量。用户信息```bash$ git config --global user.name xaoxuu$ git config --global user.email git@xaoxuu.com```- 如果用了 `--global` 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。- 如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 `--global` 选项重新配置即可，新的设定保存在当前项目的 `.git/config` 文件里。查看配置信息```bash$ git config --listhttp.postbuffer=2Muser.name=xaoxuuuser.email=git@xaoxuu.com```windows下 git-bash 美化> 尽管现在 `wsl+linux` 能玩出花来，但是以前都是 babun+git-bash 为主力的，那不美化下，windows 下的终端都没法看，就算现在要是不小心切到 git-bash ，而不想出现恶心的割裂感~open:true 具体配置color:blue .minttyrc 字体和配色方案再账户目录下新建 `~/.minttyrc` 文件```shColumns=106Rows=58Font=ConsolasFontHeight=13CursorType=blockCursorBlinks=noTransparency=offBoldAsFont=yesAllowBlinking=yesScrollbar=noneScrollbackLines=200ClickTargetMod=offComposeKey=shiftForegroundColour=119,80,103BackgroundColour=249,241,233CursorColour=0,184,174Black=194,168,144BoldBlack=194,168,144Red=255,43,89BoldRed=255,43,89Green=0,127,192BoldGreen=0,127,192Yellow=151,185,1BoldYellow=151,185,1Blue=248,130,20BoldBlue=248,130,20Magenta=177,54,91BoldMagenta=177,54,91Cyan=20,77,121BoldCyan=20,77,121White=0,184,174BoldWhite=0,184,174ClipShortcuts=noFontWeight=700FontIsBold=yesLanguage=zh_CNPrinter=Generic 36C-9SeriesPCLZoomShortcuts=noAltFnShortcuts=noBellType=0OpaqueWhenFocused=no```color:green git-prompt.sh 状态提示脚本.替换安装目录下的 `/etc/profile` 同名脚本即可```shif test -f /etc/profile.d/git-sdk.shthen TITLEPREFIX=SDK-${MSYSTEM#MINGW}else TITLEPREFIX=$MSYSTEMfiif test -f ~/.config/git/git-prompt.shthen . ~/.config/git/git-prompt.shelse PS1='\\[\\033]0;$TITLEPREFIX:$PWD\\007\\]' # set window title PS1=\"$PS1\"'\\n' # new line PS1=\"$PS1\"'\\[\\033[1;32m\\]' # change to green # PS1=\"$PS1\"'\\u@\\h ' # user@host<space> PS1=\"$PS1\"'\\u ' # user@host<space> PS1=\"$PS1\"'\\[\\033[1;31m\\]' # PS1=\"$PS1\"'{@v@/~} ' PS1=\"$PS1\"'\\[\\033[1;35m\\]' # change to purple # PS1=\"$PS1\"'$MSYSTEM ' # show MSYSTEM PS1=\"$PS1\"'\"\\t\" ' # show TIME PS1=\"$PS1\"'\\[\\033[1;33m\\]' # change to brownish yellow PS1=\"$PS1\"'\\W' # current working directory if test -z \"$WINELOADERNOEXEC\" then GIT_EXEC_PATH=\"$(git --exec-path 2>/dev/null)\" COMPLETION_PATH=\"${GIT_EXEC_PATH%/libexec/git-core}\" COMPLETION_PATH=\"${COMPLETION_PATH%/lib/git-core}\" COMPLETION_PATH=\"$COMPLETION_PATH/share/git/completion\" if test -f \"$COMPLETION_PATH/git-prompt.sh\" then . \"$COMPLETION_PATH/git-completion.bash\" . \"$COMPLETION_PATH/git-prompt.sh\" PS1=\"$PS1\"'\\[\\033[36m\\]'  # change color to cyan PS1=\"$PS1\"'`__git_ps1`' # bash function fi fi PS1=\"$PS1\"'\\[\\033[37m\\]' # change color # PS1=\"$PS1\"'\\n' # new line PS1=\"$PS1\"' >>> ' # prompt: always $fiMSYS2_PS1=\"$PS1\" # for detection by MSYS2 SDK's bash.basrc```完成上述两步后，重启即可，效果如下，可根据自己口味进行调节使用 SSH 连接到 GitHub生成新 SSH 密钥```ssh-keygen -t rsa -C user@example.com```其中 `user@example.com` 对应 Git 的邮箱地址`ssh-agent` 是一种控制用来保存公钥身份验证所使用的私钥的程序，其实 ssh-agent 就是一个密钥管理器，运行 ssh-agent 以后，使用 ssh-add 将私钥交给 ssh-agent 保管，其他程序需要身份验证的时候可以将验证申请交给 ssh-agent 来完成整个认证过程。```eval \"$(ssh-agent -s)\"```添加生成的 SSH key 到 ssh-agent：```ssh-add ~/.ssh/id_rsa```要配置 GitHub 帐户使用新的（或现有）SSH 密钥，您还需要将其添加到 GitHub 帐户。这个网上有大量的教程这里就不赘述了，后续也会讲到多 git 账户管理。"},{"title":"pacman","path":"/wiki/capsules/commands/pacman.html","content":"color:blue pacman `arclinux` 中的软件管理工具，可以直接从网络上的软件仓库下载安装及删除软件，自动处理依赖关系，类似ubuntu中的apt-get安装软件```pacman -S 软件名: 安装软件也可以同时安装多个包，只需以空格分隔包名即可pacman -S --needed 软件名1 软件名2: 安装软件，但不重新安装已经是最新的软件pacman -Sy 软件名：安装软件前，先从远程仓库下载软件包数据库(数据库即所有软件列表)pacman -Sv 软件名：在显示一些操作信息后执行安装pacman -Sw 软件名: 只下载软件包，不安装pacman -U 软件名.pkg.tar.gz：安装本地软件包pacman -U http://www.example.com/repo/example.pkg.tar.xz : 安装一个远程包（不在 pacman 配置的源里面）```更新系统```pacman -Sy: 从服务器下载新的软件包数据库（实际上就是下载远程仓库最新软件列表到本地）pacman -Su: 升级所有已安装的软件包````pacman` 可以用一个命令就可以升级整个系统，花费的时间取决于系统有多老这个命令会同步非本地(local)软件仓库并升级系统的软件包：```pacman -Syu```在 `Arch linux` 中，只支持系统完整升级，不支持部分升级。`pacman -Syu` 也会升级整个系统，安装完成目录占用空间立马变大很多；如果升级时，网络比较慢，觉得既浪费时间又浪费硬盘，实在不想升级那么多东西，可以逐个软件包升级，用下面命令可以升级核心包：```pacman -S --needed filesystem msys2-runtime bash libreadline libiconv libarchive libgpgme libcurl pacman ncurses libintl```卸载软件```pacman -R 软件名: 该命令将只删除包，保留其全部已经安装的依赖关系pacman -Rv 软件名: 删除软件，并显示详细的信息pacman -Rs 软件名: 删除软件，同时删除本机上只有该软件依赖的软件pacman -Rsc 软件名: 删除软件，并删除所有依赖这个软件的程序，慎用pacman -Ru 软件名: 删除软件,同时删除不再被任何软件所需要的依赖```搜索软件```pacman -Ss 关键字: 在仓库中搜索含关键字的软件包（本地已安装的会标记）pacman -Sl <repo>: - 显示软件仓库中所有软件的列表 - 可以省略，通常这样用:`pacman -Sl  关键字`pacman -Qs 关键字: 搜索已安装的软件包pacman -Qu: 列出所有可升级的软件包pacman -Qt: 列出不被任何软件要求的软件包```**参数加q** 可以简洁方式显示结果，比如 `pacman -Ssq gcc` 会比 `pacman -Ss gcc` 显示的好看一些`pacman -Sl  gcc` 跟 `pacman -Ssq gcc` 很接近，但是会少一些和gcc有关但软件名不包含gcc的包查询软件信息```pacman -Q 软件名: 查看软件包是否已安装，已安装则显示软件包名称和版本pacman -Qi 软件名: 查看某个软件包信息，显示较为详细的信息，包括描述、构架、依赖、大小等等pacman -Ql 软件名: 列出软件包内所有文件，包括软件安装的每个文件、文件夹的名称和路径```软件包组```pacman -Sg: 列出软件仓库上所有的软件包组pacman -Qg: 列出本地已经安装的软件包组和子包pacman -Sg 软件包组: 查看某软件包组所包含的所有软件包pacman -Qg 软件包组: 和pacman -Sg 软件包组完全一样```很多人建议通过安装软件组来安装工具链，例如：```pacman -S mingw-w64-x86_64-toolchainpacman -S mingw-w64-i686-toolchainpacman -S mingw-w64-x86_64-qt5pacman -S base-devel```但是这样比较浪费空间实际上如果把 `gcc, qt, clang` 等安装上，`msys2` 就要占掉超过10G的硬盘空间，所以个人很少直接安装软件组清理缓存```pacman -Sc：清理未安装的包文件，包文件位于 /var/cache/pacman/pkg/ 目录pacman -Scc：清理所有的缓存文件```最常用的pacman命令```pacman -Syu: 升级系统及所有已经安装的软件pacman -S 软件名: 安装软件也可以同时安装多个包，只需以空格分隔包名即可pacman -Rs 软件名: 删除软件，同时删除本机上只有该软件依赖的软件pacman -Ru 软件名: 删除软件，同时删除不再被任何软件所需要的依赖pacman -Ssq 关键字: 在仓库中搜索含关键字的软件包，并用简洁方式显示pacman -Qs 关键字: 搜索已安装的软件包pacman -Qi 软件名: 查看某个软件包信息，显示软件简介,构架,依赖,大小等详细信息pacman -Sg: 列出软件仓库上所有的软件包组pacman -Sg 软件包组: 查看某软件包组所包含的所有软件包pacman -Sc：清理未安装的包文件，包文件位于 /var/cache/pacman/pkg/ 目录pacman -Scc：清理所有的缓存文件```"},{"title":"Capslock+","path":"/wiki/capsules/keys/capslock+.html","content":"https://capslox.com/capslock-plus/"},{"title":"linux shell(bash)","path":"/wiki/capsules/keys/shell.html","content":"color:blue Linux的缺省Shell是Bash 熟练运用下面的快捷键将对提高Bash的操作有很多好处。如果你用过Emacs的话，你会发现它们的很多操作都是相同的，因为Bash默认使用的是Emacs按键绑定，当然你也可以修改为其他的方式，比如vi绑定。本文总结了shell在Emacs按键绑定下的快捷键使用方式，也就是shell默认快捷键。入门用户可以参考本文，也可以把本文作为一个参考备忘文档> Bash 默认为 emacs 编辑模式。如果你的 Bash 不在 emacs 编辑模式，可通过 `set -o emacs` 设置控制命令```Ctrl + l：清屏（与clear命令效果相同）Ctrl + o：执行当前命令，并选择上一条命令Ctrl + s：阻止屏幕输出(当前正在执行的命令不在打印信息)Ctrl + q：允许屏幕输出(使用Ctrl+s命令后，可以用Ctrl+q恢复)Ctrl + c：终止当前正在执行的命令Ctrl + z：挂起命令，把当前进程转到后台运行，使用fg命令恢复。Ctrl + d : 退出当前 Shell````^S、^Q、^C、^Z` 是由终端设备处理的，可用 stty 命令设置。编辑命令光标移动```Ctrl + a ：移到命令行首Ctrl + e ：移到命令行尾Ctrl + f ：前移（向右移动）一个字符Ctrl + b ：后退（向左移动）一个字符Alt + f ：前移（向右移动）一个单词Alt + b ：后退（向左移动）一个单词Ctrl + xx：在命令行首和光标之间移动```文本修改补全、删除、粘贴```tab : 自动补全命令Ctrl + u ：从光标处删除至命令行首Ctrl + k ：从光标处删除至命令行尾Ctrl + w ：从光标处删除至字首Alt + d ：从光标处删除至字尾Ctrl + d ：删除光标处（或光标后）的字符（如果光标前后都没有字符，即命令行为空的时候，则会退出shell）Ctrl + h ：删除光标前的字符(与backspace键相同)Alt + Backspace：与 Ctrl + w 类似，分隔符有些差别Ctrl + y ：粘贴至光标后```改变大小写```Alt + c ：从光标处更改为首字母大写的单词Alt + u ：从光标处更改为全部大写的单词Alt + l ：从光标处更改为全部小写的单词```交换字符、单词位置```Ctrl + t ：交换光标处和之前的字符（ESC+t相同）Alt + t ：交换光标处和之前的单词```重新执行命令```Ctrl + p：历史中的上一条命令Ctrl + n：历史中的下一条命令Alt + .：使用上一条命令的最后一个参数（会直接在当前光标位置显示）Ctrl + r：搜索之前使用过的命令Ctrl + g：从历史搜索模式退出```Bang (!) 命令`Bang` 命令算不上快捷键键，但是使用可以快捷的进行一些操作，比如重新执行之前命令、修改上一条命令并执行等等。```!!：执行上一条命令!cc：执行最近的以cc开头的命令，如!l会执行ls命令!$：打印上一条命令的最后一个参数，并回车执行。与Alt + .相似，但是会自动执行!*：上一条命令的所有参数!cc:p：仅打印以!cc的输出，但不执行，如!l:p会显示ls!$:p：打印输出!$的输出!*:p：打印输出!*的输出^blah：删除上一条命令中第一个blah，然后执行^blah^foo：将上一条命令中的 blah 替换为 foo，然后执行^blah^foo^：将上一条命令中所有的 blah 都替换为 foo，然后执行```"},{"title":"Visual Studio Code","path":"/wiki/capsules/keys/vscode.html","content":"| 按 Press             | 功能 Function                     |\n| ------------------- | ------------------------------- |\n| Ctrl + Shift + P，F1 | 显示命令面板 Show Command Palette     |\n| Ctrl + P            | 快速打开 Quick Open                 |\n| Ctrl + Shift + N    | 新窗口 / 实例 New window/instance    |\n| Ctrl + Shift + W    | 关闭窗口 / 实例 Close window/instance |\n\n## 基础编辑 Basic editing\n\n| 按 Press           | 功能 Function                              |\n| ----------------- | ---------------------------------------- |\n| Ctrl+X            | 剪切行（空选定） Cut line (empty selection)      |\n| Ctrl+C            | 复制行（空选定）Copy line (empty selection)      |\n| Alt+ ↑ / ↓        | 向上 / 向下移动行 Move line up/down             |\n| Shift+Alt + ↓ / ↑ | 向上 / 向下复制行 Copy line up/down             |\n| Ctrl+Shift+K      | 删除行 Delete line                          |\n| Ctrl+Enter        | 在下面插入行 Insert line below                 |\n| Ctrl+Shift+Enter  | 在上面插入行 Insert line above                 |\n| Ctrl+Shift+\\      | 跳到匹配的括号 Jump to matching bracket         |\n| Ctrl+] / [        | 缩进 / 缩进行 Indent/outdent line             |\n| Home              | 转到行首 Go to beginning of line             |\n| End               | 转到行尾 Go to end of line                   |\n| Ctrl+Home         | 转到文件开头 Go to beginning of file           |\n| Ctrl+End          | 转到文件末尾 Go to end of file                 |\n| Ctrl+↑ / ↓        | 向上 / 向下滚动行 Scroll line up/down           |\n| Alt+PgUp / PgDown | 向上 / 向下滚动页面 Scroll page up/down          |\n| Ctrl+Shift+[      | 折叠（折叠）区域 Fold (collapse) region          |\n| Ctrl+Shift+]      | 展开（未折叠）区域 Unfold (uncollapse) region     |\n| Ctrl+K Ctrl+[     | 折叠（未折叠）所有子区域 Fold (collapse) all subregions |\n| Ctrl+K Ctrl+]     | 展开（未折叠）所有子区域 Unfold (uncollapse) all subregions |\n| Ctrl+K Ctrl+0     | 折叠（折叠）所有区域 Fold (collapse) all regions   |\n| Ctrl+K Ctrl+J     | 展开（未折叠）所有区域 Unfold (uncollapse) all regions |\n| Ctrl+K Ctrl+C     | 添加行注释 Add line comment                   |\n| Ctrl+K Ctrl+U     | 删除行注释 Remove line comment                |\n| Ctrl+/            | 切换行注释 Toggle line comment                |\n| Shift+Alt+A       | 切换块注释 Toggle block comment               |\n| Alt+Z             | 切换换行 Toggle word wrap                    |\n\n## 导航 Navigation\n\n| 按 Press            | 功能 Function                              |\n| ------------------ | ---------------------------------------- |\n| Ctrl + T           | 显示所有符号 Show all Symbols                  |\n| Ctrl + G           | 转到行... Go to Line...                     |\n| Ctrl + P           | 转到文件... Go to File...                    |\n| Ctrl + Shift + O   | 转到符号... Go to Symbol...                  |\n| Ctrl + Shift + M   | 显示问题面板 Show Problems panel               |\n| F8                 | 转到下一个错误或警告 Go to next error or warning   |\n| Shift + F8         | 转到上一个错误或警告 Go to previous error or warning |\n| Ctrl + Shift + Tab | 导航编辑器组历史记录 Navigate editor group history |\n| Alt + ←/→          | 返回 / 前进 Go back / forward                |\n| Ctrl + M           | 切换选项卡移动焦点 Toggle Tab moves focus         |\n\n## 搜索和替换 Search and replace\n\n| 按 Press           | 功能 Function                              |\n| ----------------- | ---------------------------------------- |\n| Ctrl + F          | 查找 Find                                  |\n| Ctrl + H          | 替换 Replace                               |\n| F3 / Shift + F3   | 查找下一个 / 上一个 Find next/previous           |\n| Alt + Enter       | 选择查找匹配的所有出现 Select all occurences of Find match |\n| Ctrl + D          | 将选择添加到下一个查找匹配 Add selection to next Find match |\n| Ctrl + K Ctrl + D | 将最后一个选择移至下一个查找匹配项 Move last selection to next Find match |\n| Alt + C / R / W   | 切换区分大小写 / 正则表达式 / 整个词 Toggle case-sensitive / regex / whole word |\n\n## 多光标和选择 Multi-cursor and selection\n\n| 按 Press                            | 功能 Function                              |\n| ---------------------------------- | ---------------------------------------- |\n| Alt + 单击                           | 插入光标 Insert cursor                       |\n| Ctrl + Alt +↑/↓                    | 在上 / 下插入光标 Insert cursor above / below   |\n| Ctrl + U                           | 撤消上一个光标操作 Undo last cursor operation     |\n| Shift + Alt + I                    | 在选定的每一行的末尾插入光标 Insert cursor at end of each line selected |\n| Ctrl + I                           | 选择当前行 Select current line                |\n| Ctrl + Shift + L                   | 选择当前选择的所有出现 Select all occurrences of current selection |\n| Ctrl + F2                          | 选择当前字的所有出现 Select all occurrences of current word |\n| Shift + Alt + →                    | 展开选择 Expand selection                    |\n| Shift + Alt + ←                    | 缩小选择 Shrink selection                    |\n| Shift + Alt + （拖动鼠标）               | 列（框）选择 Column (box) selection            |\n| Ctrl + Shift + Alt +（箭头键）          | 列（框）选择 Column (box) selection            |\n| Ctrl + Shift + Alt + PgUp / PgDown | 列（框）选择页上 / 下 Column (box) selection page up/down |\n\n## 丰富的语言编辑 Rich languages editing\n\n| 按 Press              | 功能 Function                              |\n| -------------------- | ---------------------------------------- |\n| Ctrl + 空格            | 触发建议 Trigger suggestion                  |\n| Ctrl + Shift + Space | 触发器参数提示 Trigger parameter hints          |\n| Tab                  | Emmet 展开缩写 Emmet expand abbreviation     |\n| Shift + Alt + F      | 格式化文档 Format document                    |\n| Ctrl + K Ctrl + F    | 格式选定区域 Format selection                  |\n| F12                  | 转到定义 Go to Definition                    |\n| Alt + F12            | Peek 定义 Peek Definition                  |\n| Ctrl + K F12         | 打开定义到边 Open Definition to the side       |\n| Ctrl + .             | 快速解决 Quick Fix                           |\n| Shift + F12          | 显示引用 Show References                     |\n| F2                   | 重命名符号 Rename Symbol                      |\n| Ctrl + Shift + . /，  | 替换为下一个 / 上一个值 Replace with next/previous value |\n| Ctrl + K Ctrl + X    | 修剪尾随空格 Trim trailing whitespace          |\n| Ctrl + K M           | 更改文件语言 Change file language              |\n\n## 编辑器管理 Editor management\n\n| 按 Press                  | 功能 Function                              |\n| ------------------------ | ---------------------------------------- |\n| Ctrl+F4, Ctrl+W          | 关闭编辑器 Close editor                       |\n| Ctrl+K F                 | 关闭文件夹 Close folder                       |\n| Ctrl+\\                   | 拆分编辑器 Split editor                       |\n| Ctrl+ 1 / 2 / 3          | 聚焦到第 1，第 2 或第 3 编辑器组 Focus into 1st, 2nd or 3rd editor group |\n| Ctrl+K Ctrl+ ←/→         | 聚焦到上一个 / 下一个编辑器组 Focus into previous/next editor group |\n| Ctrl+Shift+PgUp / PgDown | 向左 / 向右移动编辑器 Move editor left/right      |\n| Ctrl+K ← / →             | 移动活动编辑器组 Move active editor group        |\n\n## 文件管理 File management\n\n| 按 Press        | 功能 Function                              |\n| -------------- | ---------------------------------------- |\n| Ctrl+N         | 新文件 New File                             |\n| Ctrl+O         | 打开文件... Open File...                     |\n| Ctrl+S         | 保存 Save                                  |\n| Ctrl+Shift+S   | 另存为... Save As...                        |\n| Ctrl+K S       | 全部保存 Save All                            |\n| Ctrl+F4        | 关闭 Close                                 |\n| Ctrl+K Ctrl+W  | 关闭所有 Close All                           |\n| Ctrl+Shift+T   | 重新打开关闭的编辑器 Reopen closed editor          |\n| Ctrl+K         | 输入保持打开 Enter Keep Open                   |\n| Ctrl+Tab       | 打开下一个 Open next                          |\n| Ctrl+Shift+Tab | 打开上一个 Open previous                      |\n| Ctrl+K P       | 复制活动文件的路径 Copy path of active file       |\n| Ctrl+K R       | 显示资源管理器中的活动文件 Reveal active file in Explorer |\n| Ctrl+K O       | 显示新窗口 / 实例中的活动文件 Show active file in new window/instance |\n\n## 显示 Display\n\n| 按 Press      | 功能 Function                              |\n| ------------ | ---------------------------------------- |\n| F11          | 切换全屏 Toggle full screen                  |\n| Shift+Alt+1  | 切换编辑器布局 Toggle editor layout             |\n| Ctrl+ = / -  | 放大 / 缩小 Zoom in/out                      |\n| Ctrl+B       | 切换侧栏可见性 Toggle Sidebar visibility        |\n| Ctrl+Shift+E | 显示浏览器 / 切换焦点 Show Explorer / Toggle focus |\n| Ctrl+Shift+F | 显示搜索 Show Search                         |\n| Ctrl+Shift+G | 显示 Git Show Git                          |\n| Ctrl+Shift+D | 显示调试 Show Debug                          |\n| Ctrl+Shift+X | 显示扩展 Show Extensions                     |\n| Ctrl+Shift+H | 替换文件 Replace in files                    |\n| Ctrl+Shift+J | 切换搜索详细信息 Toggle Search details           |\n| Ctrl+Shift+C | 打开新命令提示符 / 终端 Open new command prompt/terminal |\n| Ctrl+Shift+U | 显示输出面板 Show Output panel                 |\n| Ctrl+Shift+V | 切换 Markdown 预览 Toggle Markdown preview   |\n| Ctrl+K V     | 从旁边打开 Markdown 预览 Open Markdown preview to the side |\n\n## 调试 Debug\n\n| 按 Press         | 功能 Function             |\n| --------------- | ----------------------- |\n| F9              | 切换断点 Toggle breakpoint  |\n| F5              | 开始 / 继续 Start/Continue  |\n| Shift+F5        | 停止 Stop                 |\n| F11 / Shift+F11 | 下一步 / 上一步 Step into/out |\n| F10             | 跳过 Step over            |\n| Ctrl+K Ctrl+I   | 显示悬停 Show hover         |\n\n## 集成终端 Integrated terminal\n\n| 按 Press             | 功能 Function                        |\n| ------------------- | ---------------------------------- |\n| Ctrl+`              | 显示集成终端 Show integrated terminal    |\n| Ctrl+Shift+`        | 创建新终端 Create new terminal          |\n| Ctrl+Shift+C        | 复制选定 Copy selection                |\n| Ctrl+Shift+V        | 粘贴到活动端子 Paste into active terminal |\n| Ctrl+↑ / ↓          | 向上 / 向下滚动 Scroll up/down           |\n| Shift+PgUp / PgDown | 向上 / 向下滚动页面 Scroll page up/down    |\n| Ctrl+Home / End     | 滚动到顶部 / 底部 Scroll to top/bottom    |"},{"title":"WSL2 & Arch","path":"/wiki/capsules/list/archwsl.html","content":"安装 Arch> 进入 ArchWSL 仓库下载最新 release 中的 zip 包>> 建议选择无 `online` 后缀的包1. 在 release 下载最新版的 Arch.zip2. 解压到 C 盘根目录，(一定要在 C 盘，其他位置也可以)，但是你要有该目录的读写权限，所以不能放到 `Program Files` 等目录中3. 双击解压好的 `Arch.exe` 进行安装，这个 .exe 的名字 就是要创建的 WSL 实例的名字，改不同的名字就能创建多个 Arch WSLArchWSL 常用命令在终端中进入 Arch.exe 所在的目录，运行 `.\\Arch.exe help` 可查看详细命令说明;> 备份```bash# 备份格式参数可选：tar tgz vhdx vhdxgz reg.\\Arch.exe backup --tar```> 恢复```bash.\\Arch.exe install /to/file/path/backup.tar```> 卸载```bash.\\Arch.exe clean```配置 Arch经过上面的安装后，现在到 terminal 中输入 wsl 运行即可;如果已经在使用其他的wsl系统了，那么此时直接输入wsl 并不能启动刚刚新安装的Arch，需要在终端中打开上面安装（含有 Arch.exe）时的目录，输入 .\\Arch.exe 进行运行；或者修改默认的 WSL 为刚刚安装的 Arch ，可参考：设置默认 Linux 发行版  WSL 的基本命令  Microsoft Docs创建用户默认使用 root 用户 ，跳过导入密钥(重要)```bash# 初始化密钥环 && 验证主密钥 && 更新密钥sudo pacman-key --init sudo pacman-key --populate archlinux sudo pacman-key --refresh-keys```配置软件仓库Arch Linux 软件仓库国内镜像编辑 `/etc/pacman.d/mirrorlist`，里面有注释了的 `China` 的镜像(选择 `https`)，选一个你喜欢的取消注释就可以了。```bashvim /etc/pacman.d/mirrorlist```color:blue 其他跟镜像有关的可以看这里： https://wiki.archlinux.org/index.php/Mirrors_(简体中文)添加 ArchlinuxCN 源> Arch Linux 中文社区仓库 是由 Arch Linux 中文社区驱动的非官方用户仓库。包含中文用户常用软件、工具、字体 / 美化包等。> > 官方仓库地址：http://repo.archlinuxcn.org```bashecho \"[archlinuxcn]Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/x86_64\" >> /etc/pacman.conf```基础环境更新```bash# 安装archlinuxcn证书sudo pacman -Syy archlinuxcn-keyring# 更新软件源# sudo pacman -Syyu --noconfirm 不提示确认对话sudo pacman -Syyu```其它配置下载镜像（推荐）利用 Reflector，自动生成，生成时可设置过滤条件```bashsudo pacman -S reflector```安装成功后，执行下面这条命令；意思是地址为中国、最近12小时活跃、https协议、速度排序、生成镜像文件```bashsudo reflector --country China --age 12 --protocol https --sort rate --save /etc/pacman.d/mirrorlist```完成后可以输入下面的命令查看生成的镜像列表 `cat /etc/pacman.d/mirrorlist`安装常用工具```bashpacman -S which openssh git zsh tree wget unzip```安装 AUR```bashpacman -S paru```zsh 配置安装前置工具```bashpacman -S lua exa fzf```zsh会自动下载zinit以及zsh插件,由于速度较慢，推荐使用代理：```bashproxychains zsh```child:codeblock open:false color:blue .zshrc 配置```bash# 修复emacs中不能输入中文# LC_CTYPE=\"zh_CN.utf8\"#  移除重复的命令历史setopt HIST_IGNORE_ALL_DUPS# 取消zsh在输出不以换行符结尾的内容是在其后添加百分号并另其一行的特性# unsetopt prompt_cr prompt_sp# 设置可以使用通配符setopt nonomatch# 免输入cd进入目录setopt auto_cd###################### ZINIT ######################Added by Zinit's installerif [[ ! -f $HOME/.local/share/zinit/zinit.git/zinit.zsh ]]; then print -P \"%F{33} %F{220}Installing %F{33}ZDHARMA-CONTINUUM%F{220} Initiative Plugin Manager (%F{33}zdharma-continuum/zinit%F{220})…%f\" command mkdir -p \"$HOME/.local/share/zinit\" && command chmod g-rwX \"$HOME/.local/share/zinit\" command git clone https://github.com/zdharma-continuum/zinit \"$HOME/.local/share/zinit/zinit.git\" && \\ print -P \"%F{33} %F{34}Installation successful.%f%b\"  \\ print -P \"%F{160} The clone has failed.%f%b\"fisource \"$HOME/.local/share/zinit/zinit.git/zinit.zsh\"autoload -Uz _zinit(( ${+_comps} )) && _comps[zinit]=_zinitEnd of Zinit's installer chunk# Load a few important annexes, without Turbozinit light-mode for \\ zdharma-continuum/zinit-annex-as-monitor \\ zdharma-continuum/zinit-annex-bin-gem-node \\ zdharma-continuum/zinit-annex-patch-dl \\ zdharma-continuum/zinit-annex-rustautosuggestionszinit ice wait\"0a\" lucid atload\"_zsh_autosuggest_start\"zinit light zsh-users/zsh-autosuggestionscompletionszinit ice wait\"0b\" lucid blockf atpull'zinit creinstall -q .'zinit light zsh-users/zsh-completionssyntax highlightingzinit ice wait\"0c\" lucid atinit\"zicompinit; zicdreplay\"zinit light zdharma-continuum/fast-syntax-highlightingz.luazinit ice lucid wait='0d'zinit light skywind3000/z.luafzf-tabzinit ice wait\"0f\" lucid atinit\"zicompinit; zicdreplay\"zinit light Aloxaf/fzf-tab# colorzstyle ':fzf-tab:*' default-color $'\\033[38;5;79m'# disable sort when completing `git checkout`zstyle ':completion:*:git-checkout:*' sort false# set descriptions format to enable group supportzstyle ':completion:*:descriptions' format '[%d]'# set list-colors to enable filename colorizingzstyle ':completion:*' list-colors ${(s.:.)LS_COLORS}# preview directory's content with exa when completingzstyle ':fzf-tab:complete:*' fzf-preview 'exa -1 --color=always $realpath'# switch group using `,` and `.`zstyle ':fzf-tab:*' switch-group ',' '.'history searchzinit ice wait\"0b\" lucid atload'bindkey \"$terminfo[kcuu1]\" history-substring-search-up; bindkey \"$terminfo[kcud1]\" history-substring-search-down'zinit light zsh-users/zsh-history-substring-searchbindkey '^A' history-substring-search-upbindkey '^Z' history-substring-search-downLoad Oh MY Zsh Pluginszinit snippet OMZ::plugins/git/git.plugin.zshzinit snippet OMZ::lib/history.zsh###################### STARSHIP ######################eval \"$(starship init zsh)\"# The environment for GOLANGexport GOROOT=/usr/lib/goexport GOPATH=/home/goexport PATH=$PATH:$GOROOT/bin:$GOPATH/binexport GOPROXY=https://goproxy.cn,directexport GOPRIVATE=git.ztosys.com# The environment for RUSTexport RUSTUP_DIST_SERVER=https://mirrors.sjtug.sjtu.edu.cn/rust-staticexport RUSTUP_UPDATE_ROOT=https://mirrors.sjtug.sjtu.edu.cn/rust-static/rustup# Aliasalias l=\"ls -alh --color\"alias ls=\"ls --color\"alias ll=\"ls -lh --color\"alias c='clear'alias cda='cd /mnt/c/Users/Administrator/'alias cdg='cd /home/go/src/'alias cdr='cd /home/rust'alias cdt='cd /home/ts'alias ex='explorer.exe .'alias tailf='tail -f'alias gcn='git config user.name \"lliei\"'alias gce='git config user.email \"i@liei.cc\"'alias gczn='git config user.name \"lilei1215\"'alias gcze='git config user.email \"lilei1215@zto.ldap\"'source /usr/share/nvm/init-nvm.sh```插件更新```bashzinit update --all```zinit框架升级```bashzinit slef-update```"},{"title":"Windows 常见问题","path":"/wiki/capsules/list/windows.html","content":"释放 WSL 占用的硬盘空间`WSL` 使用虚拟硬盘(VHD)存储 linux 下的文件，随着Linux下文件越来越多，占用空间也会不断增长，不过有个最大限制 256G。但是，在 Linux 中减少文件占用，WSL 却没有相应的减少硬盘空间的占用。所以为了避免碰到 256G 的限制，或者硬盘空间告警，在删除掉 linux 下的文件后，我们需要手动释放这部分空间；<br/> 1. 要找到使用的的vhd文件路径 2. 打开 `PowerShell`, 执行以下命令：```PowerShellwsl --shutdowndiskpart# open window Diskpartselect vdisk file=\"C:\\Users\\Administrator\\Data\\Arch\\ext4.vhdx\"attach vdisk readonlycompact vdiskdetach vdiskexit``` WSL2 Input/output error解决方案 1： `重启 wsl````shwsl --shutdownwsl```解决方案 2： `重新挂载 C 盘````shsudo umount /mnt/csudo mount -t drvfs C:\\\\ /mnt/c``` 禁止指定程序联网使用命令行建立防火墙规则，以禁止 STC-ISP 联网为例：```shnetsh advfirewall firewall add rule name=\"stc-isp-15xx-v6.86_NewLogo\" dir=out program=\"C:\\Users\\Administrator\\Desktop\\stc-isp-15xx-v6.86_NewLogo.exe\" action=block ```恢复允许联网：```shnetsh advfirewall firewall set rule name=\"stc-isp-15xx-v6.86_NewLogo\" new enable=no```回车确定后立即生效；`在控制面板 -> windows 防火墙 -> 高级设置 -> 出站设置` 里就出现了这条新增项目 Chrome（CentBrowser）平滑滚动设置一直以来对 Microsoft EDGE 的平滑滚动的效果很羡慕，而 Chrome 的 Smooth Scrolling 太糟糕，研究了几天，经过摸索终于发现了其实 Chrome（CentBrowser）也有这个设置，只是默认没有开启罢了。在 `chrome://flags` 中将 - Impulse-style scroll animations color:blue- Percent-based Scrolling  color:blue这两个设置成 `Enable` 就行了，比任何插件都要好用，原生支持！color:red 注意 `Smooth Scrolling` 还是 Default 就行，不需要修改 开启浏览器多线程下载选项尽管没有 `IDM` 等专门的下载软件那么专业强大，但在开启多线程下载选项之后，只要服务器支持多线程，那么直接使用浏览器下载文件就能获得比原先更快的速度 Chrome地址栏输入并回车：```yamlchrome://flags/#enable-parallel-downloading```然后你就能看到如下图所示，只需将默认的 Default color:blue 改成 Enabled color:blue 即可！然后点击 Relaunch 重启浏览器，多线程下载的选项就生效了，这时就可以找个文件去试试速度了 Edge (Chromium 内核)地址栏输入并回车：```yamledge://flags/#enable-parallel-downloading```然后你就能看到如下图所示，只需将默认的 Default color:blue 改成 Enabled color:blue 即可！然后点击 Relaunch 重启浏览器，多线程下载的选项就生效了，这时就可以找个文件去试试速度了 浏览器开启终极黑暗模式 使用扩展- Dark Reader- Midnight Lizard 不使用扩展（推荐）1. 浏览器地址栏输入 `edge://flags` or `chrome://flags`2. 使用最上方的搜索关键字 `dark`，将 Auto Dark Mode for Web Contents color:warning 选项设置为 `Enabled with selective inversion of non-image elements`，也可以尝试其他选项3. 重启浏览器，即可。 配置 WSL2 使用代理上网将宿主机的代理共享给这个局域网下的其他设备，以 Clash 为例，打开 `Allow LAN` 选项WSL2 下操作：```sh获取主机 IP主机 IP 保存在 /etc/resolv.conf 中export hostip=$(cat /etc/resolv.conf grep -oP '(?<=nameserver\\ ).*')设置代理export all_proxy=\"socks5://${hostip}:7890\"验证curl google.com```简化上述设置，在 ~/.zshrc color:warning 中添加的以下配置```shexport hostip=$(cat /etc/resolv.conf grep -oP '(?<=nameserver\\ ).*')alias setss='export ALL_PROXY=\"socks5://${hostip}:7890\"'alias unsetss='unset ALL_PROXY'```如果wsl连接不到主机（ping不通的话），直接放开 `vEthernet (WSL)` 这张网卡的防火墙，在 powershell color:warning 上执行：```powershellNew-NetFirewallRule -DisplayName \"WSL\" -Direction Inbound -InterfaceAlias \"vEthernet (WSL)\" -Action Allow```"},{"title":"搭建免费 CDN","path":"/wiki/git/cdn/index.html","content":"CDN 的全称是 Content Delivery Network，即内容分发网络。CDN 是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN 的关键技术主要有内容存储和分发技术。新建 Github Repository> 就常规的新建 Github 仓库，作为内容存储；最好都使用命令行操作，不熟悉的自己去查，这是最基础的，乖哦！我就不说了通过 jsDelivr 引用资源`jsDelivr` 由 ProspectOne 维护的公共库，使用的融合 CDN 技术，由 Cloudflare、Fastly、StackPath、QUANTIL 等 CDN 供应商提供了全球超过 750 个 CDN 节点。最重要的是，jsDelivr 在中国大陆也拥有超过数百个节点，因为 jsDelivr 拥有正规的 ICP 备案，解决了中国大陆的访问速度优化，实现真正的全球极速低延迟体验。jsDelivr 是免费的、不限制带宽的，可以加速 NPM、Github 内的文件。使用方法- 根据版本号https://cdn.jsdelivr.net/gh/Username/YourRepoName@Version/FilePath- 根据 Commit Hash 提交记录https://cdn.jsdelivr.net/gh/Username/YourRepoName@CommitHash/FilePath- 获取最新提交https://cdn.jsdelivr.net/gh/Username/YourRepoName/FilePathcolor:green codeblock:true 举个例子 🍌```https://cdn.jsdelivr.net/gh/leeifme/oss-aliyun-cli@0.1.0/README.mdhttps://cdn.jsdelivr.net/gh/leeifme/oss-aliyun-cli@1d86a902394f556f954142125746f5b7c014c6bd/README.mdhttps://cdn.jsdelivr.net/gh/leeifme/oss-aliyun-cli/README.m```代码压缩> jsDelivr 还提供了代码压缩服务，比如将 JS/CSS 的代码压缩，优化访问速度。只是前几次访问会执行压缩操作，速度比较慢。后面就会将文件缓存，速度不会再慢了。直接将访问链接的文件后缀改成 `.min.js` 即可。例如： `https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/src/example.min.js`"},{"title":"git-flow 的工作流程","path":"/wiki/git/git-flow/index.html","content":"## 前言\n\n> 当在团队开发中使用版本控制系统时，商定一个统一的工作流程是至关重要的。 `Git` 的确可以在各个方面做很多事情，然而，如果在你的团队中还没有能形成一个特定有效的工作流程，那么混乱就将是不可避免的。\n>\n> `git-flow` 就是当前非常流行且行之有效的工作流程， 是一个 `Git` 扩展集，按 Vincent Driessen 的分支模型提供高层次的库操作，并且提供了极其出色的命令帮忙以及输出提示，本文中有演示操作，可以仔细阅读并观察发生了什么事情\n\n## git-flow 安装\n\n**安装指南：**https://github.com/petervanderdoes/gitflow-avh/wiki/Installation\n\n### 准备工作（Windows）\n\n按照官方给出的安装方法，依次点击三个链接：\n\n- [util-linux package](http://gnuwin32.sourceforge.net/packages/util-linux-ng.htm)\n- [libintl](http://gnuwin32.sourceforge.net/packages/libintl.htm)  \n- [libiconv](http://gnuwin32.sourceforge.net/packages/libiconv.htm)\n\n三个要下载的都是 `Binaries` 的 zip 格式文件，下载完后只需要把各自 bin 目录下的对应文 (`getopt.exe，libintl3.dll，libiconv2.dll` ) 件复制到 git 安装目录的 bin 目录下即可, 其他的都不需要，版本和路径根据自己的情况而定\n\n### Clone the git-flow \n\n打开 `Git Bash` 执行：\n\n```sh\n$ git config --global url.\"https://github\".insteadOf git://github\n```\n\n如果不执行这条命令，直接执行下面命令的话，clone 会出现卡住现象\n\n```sh\n$ git clone --recursive git://github.com/nvie/gitflow.git\n```\n\n打开`powershell`（以管理员身份运行）， cd 到下载 `gitflow` 的目录下\n\n```powershell\nPS C:\\Users\\Administrator> cd .\\gitflow\\\nPS C:\\Users\\Administrator\\gitflow> .\\contrib\\msysgit-install.cmd \"C:\\Program Files\\Software\\Git\"\n\n# \"C:\\Program Files\\Software\\Git\" 根据安装 git 的安装目录进行调整\n```\n\n测试是否安装成功，打开 `Git Bash`\n\n```sh\nAdministrator at 14:56:56 / $ git flow help\nusage: git flow <subcommand>\n\nAvailable subcommands are:\n   init      Initialize a new git repo with support for the branching model.\n   feature   Manage your feature branches.\n   bugfix    Manage your bugfix branches.\n   release   Manage your release branches.\n   hotfix    Manage your hotfix branches.\n   support   Manage your support branches.\n   version   Shows version information.\n   config    Manage your git-flow configuration.\n   log       Show log deviating from base branch.\n\nTry 'git flow <subcommand> help' for details.\n```\n\n## git-flow 使用\n\n### 开发新功能 ( **Feature** )\n\n**需求：**添加一个 `README.md` 文件，并添加内容\n\n**创建 `my-feature` 分支**\n\n```sh\nAdministrator at 16:04:03 Go-fun (develop) $ git flow feature start my-feature\nSwitched to a new branch 'feature/my-feature'\n\nSummary of actions:\n- A new branch 'feature/my-feature' was created, based on 'develop'\n- You are now on branch 'feature/my-feature'\n\nNow, start committing on your feature. When done, use:\n\n     git flow feature finish my-feature\n     \nAdministrator at 16:04:51 Go-fun (feature/my-feature) $\n```\n\n根据提示，我们知道一个新的分支 `feature／my-feature` 基于 `develop` 分支创建好了, 并且目前我们所在的分支为 `feature／my-feature`，可以查看下分支情况\n\n```sh\n $ git branch\n  develop\n* feature/my-feature\n  master\n```\n\n**在 `feature/my-feature` 分支新建一个 README.md 并提交**\n\n```sh\n$ vi README.md\n$ git add README.md\n$ git commit -m \"create README.md\"\n[feature/my-feature e783fdf] create README.md\n1 file changed, 1 insertion(+)\ncreate mode 100644 README.md\n```\n\n**完成 `feature` 分支合并**\n\n根据之前创建分支的提示可知，在完成新功能的开发后，可使用 ` git flow feature finish <name> ` 提交合并\n\n```sh\n$ git flow feature finish my-feature\nSwitched to branch 'develop'\nUpdating bde3a64..e783fdf\nFast-forward\n README.md | 1 +\n 1 file changed, 1 insertion(+)\n create mode 100644 README.md\nDeleted branch feature/my-feature (was e783fdf).\n\nSummary of actions:\n- The feature branch 'feature/my-feature' was merged into 'develop'\n- Feature branch 'feature/my-feature' has been locally deleted\n- You are now on branch 'develop'\n```\n\n根据提示，我们看到了 git flow feature finish my-feature 这条语句的作用。\n\n1. `feature/my-feature` 分支被 merge 到了 `develop` 分支\n2. 本地 `feature/my-feature` 分支被删除，现在我们处于 `develop` 分支\n\n参看分支情况：\n\n```sh\n$ git branch\n* develop\n  master\n```\n\n**不使用 `git-flow`**\n\n在不使用 `git-flow` 工具的情况下，怎么实现 \n\n1. 新建一个分支\n\n   ```sh\n    $ git checkout -b my-feature develop\n   ```\n\n2. 当开发完成后，合并分支。\n\n   ```sh\n    $ git merge --no-ff my-feature\n    Already up-to-date.\n   ```\n\n3. 删除本地 my-feature 分支\n\n   ```sh\n    $ git branch -d my-feature\n   ```\n\n4. 提交更改到远程 develop 分支\n\n   ```sh\n    $ git push origin develop\n   ```\n\n比较两种方式就会发现，git flow 方便了分支的管理, 使用上更为简单\n\n### 发布版本 ( **Release** )\n\n**需求：**添加一个 `README.md` 文件，并添加版本号与日期\n\n**创建 `release 1.0` 分支**\n\n```sh\nAdministrator at 17:37:59 Go-fun (develop) $ git flow release start 1.0\nSwitched to a new branch 'release/1.0'\n\nSummary of actions:\n- A new branch 'release/1.0' was created, based on 'develop'\n- You are now on branch 'release/1.0'\n\nFollow-up actions:\n- Bump the version number now!\n- Start committing last-minute fixes in preparing your release\n- When done, run:\n\n     git flow release finish '1.0'\n\n\nAdministrator at 17:38:07 Go-fun (release/1.0) $\n```\n\n根据提示，流程和创建 `feature` 分支差不多，查看分支情况\n\n```sh\n$ git branch\n  develop\n  master\n* release/1.0\n```\n\n**添加修改文件到暂存区**\n\n```sh\n$ git add README.md\n$ git commit -m \"update version to 1.0\"\n```\n\n**完成 `release 1.0` 分支**\n\n```sh\nAdministrator at 19:00:28 Go-fun (release/1.0) $ git flow release finish 1.0\nSwitched to branch 'master'\nYour branch is up to date with 'origin/master'.\nMerge made by the 'recursive' strategy.\n README.md | 5 ++++-\n 1 file changed, 4 insertions(+), 1 deletion(-)\nAlready on 'master'\nYour branch is ahead of 'origin/master' by 2 commits.\n  (use \"git push\" to publish your local commits)\nSwitched to branch 'develop'\nMerge made by the 'recursive' strategy.\n README.md | 5 ++++-\n 1 file changed, 4 insertions(+), 1 deletion(-)\nDeleted branch release/1.0 (was 922692f).\n\nSummary of actions:\n- Release branch 'release/1.0' has been merged into 'master'\n- The release was tagged '1.0'\n- Release tag '1.0' has been back-merged into 'develop'\n- Release branch 'release/1.0' has been locally deleted\n- You are now on branch 'develop'\n```\n\n根据上图的提示，发现这一步做了如下的事情。\n\n1. `release/1.0` 分支已经被 merge 到了 master 分支\n2. 版本被打上 `tag 1.0` \n3. `elease/1.0` 被 merge 到了 `develop` 分支\n4. 本地 `release/1.0` 被删除\n5. 切换分支到 `develop`\n\n**更新远程分支**\n\n```sh\n$ git push origin master\n$ git push origin develop\n$ git push --tags\n```\n\n**不使用 `git-flow`**\n\n1. 创建 release-1.0 分支\n\n    ```sh\n    $ git checkout -b release-1.0 develop\n    Switched to a new branch 'release-1.0'\n    ```\n\n2. 提交到分支 release-1.0\n\n    ```sh\n    $ git commit -am \"Bumped version number to 1.0\"\n    ```\n\n3. 切换分支到 master\n\n    ```sh\n    $ git checkout master\n    ```\n\n4. 合并 release-1.0 到 develop 分支\n\n    ```sh\n    $ git merge --no-ff release-1.0\n    ```\n\n5. 打上标签 (tag)\n\n    ```sh\n    $ git tag -a 1.0 -am \"message\"\n    ```\n\n6. 切换到 develop 分支，并合并到 develop 分支。\n\n    ````sh\n    $ git checkout develop\n    $ git merge --no-ff release-1.0\n    ````\n\n7. 删除本地分支 realse-1.0\n\n    ```sh\n    $ git branch -d release-1.0\n    ```\n\n8. 更新远程分支\n\n   ```sh\n   $ git push origin master\n   $ git push origin develop\n   $ git push --tags\n   ```\n\n如果说在开发新功能的时候你没体会到 `git flow` 的优点，那么在 release 版本的时候，就能很明显地感受到 `git flow` 的优势\n\n### 紧急修复 ( **Hotfix** )\n\ngit flow 基于 master 分支，用于紧急修复，修改完成后要 merge 到 master，develop 分支\n\n**使用 `git-flow`**\n\n```sh\n$ git flow hotfix start 1.0.1\n```\n\n**不使用 `git-flow`**\n\n```sh\n$ git checkout -b hotfix-1.2.1 master\n```\n\n其他步骤与在 release 开发相同，同样不要忘了在 master 分支打上 tag"},{"title":"修改操作","path":"/wiki/git/modify/index.html","content":"## 工作区和版本库\n\n- **工作区：**\n\n  就是你电脑文件夹能看到的目录，就如我创建的test文件夹就是一个工作区\n\n  ```sh\n  leeif@leeif MINGW64 /e/git/test (master)\n  $ ls\n  git.txt  index.html  README.md\n  ```\n- **版本库(Repository)：**\n\n  工作区有一个隐藏的目录文件 `.git` ，这个虽然在工作区目录下，但不算在工作区，而是 `Git` 的版本库。\n  `Git` 的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支 `master`，以及指向 `master` 的一个指针叫 `HEAD` 。\n\n  <img src = \"http://orj2jcr7i.bkt.clouddn.com/%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%92%8C%E7%89%88%E6%9C%AC%E5%BA%93.png\" alt = \"flex-axis\"> \n\n\n上一篇讲了我们把文件往Git版本库里添加的时候，是分两步执行的：\n\n1. 用 `git add` 把文件添加进去，实际上就是把文件修改添加到暂存区；\n2. 用 `git commit` 提交更改，实际上就是把暂存区的所有内容提交到当前分支。\n\n因为我们创建Git版本库时，Git自动为我们创建了唯一一个 `master` 分支，所以，现在，`git commit` 就是往 `master` 分支上提交更改。\n\n你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。\n\n**ok，我们实践一下：**\n\n<!-- more -->\n\n- 首先新建一个文件 `test.txt` ，然后对 `git.exe` 进行修改，\n\n  ```sh\n  $ git diff git.txt\n  diff --git a/git.txt b/git.txt\n  index 97fe984..a537f08 100644\n  --- a/git.txt\n  +++ b/git.txt\n  @@ -2,4 +2,6 @@ Git is a version control system.\n   Git is free software.\n\n   Git is a distributed version control system.\n  -Git is free software.\n  \\ No newline at end of file\n  +Git is free software.\n  +\n  +add test add test\n  \\ No newline at end of file\n  ```\n\n- 然后我们用 `git status` 查看一下状态：\n\n  ```js\n  $ git status\n  On branch master\n  Your branch is ahead of 'origin/master' by 3 commits.\n    (use \"git push\" to publish your local commits)\n\n  Changes not staged for commit:\n    (use \"git add <file>...\" to update what will be committed)\n    (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n          modified:   git.txt\n\n  Untracked files:\n    (use \"git add <file>...\" to include in what will be committed)\n\n          test.txt\n  ```\n\n  Git非常清楚地告诉我们，`git.txt` 被修改了，而 `test.txt` 还从来没有被添加过，所以它的状态是 `Untracked`\n\n- 现在，使用两次命令 `git add` ，把 `git.txt` 和 `test.txt` 都添加后，用 `git status` 再查看一下：\n\n  ```sh\n  $ git status\n  On branch master\n  Your branch is ahead of 'origin/master' by 3 commits.\n    (use \"git push\" to publish your local commits)\n  Changes to be committed:\n    (use \"git reset HEAD <file>...\" to unstage)\n\n          modified:   git.txt\n          new file:   test.txt\n  ```\n\n  所以，暂存区的状态就变成这样了：\n\n  <img src = \"http://orj2jcr7i.bkt.clouddn.com/git%20add.png\" alt = \"flex-axis\">\n\n- `git add` 命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行 `git commit` 就可以一次性把暂存区的所有修改提交到分支。\n\n  ```sh\n  $ git commit -m \"updata&test \"\n  [master 0fbc057] updata&test\n   3 files changed, 5 insertions(+), 1 deletion(-)\n   create mode 100644 test.txt\n  ```\n\n  在检查下状态，如果你没在对工作区文件进行修改的话，工作区返回的状态就是 `clean`\n  ```sh\n  $ git status\n  On branch master\n  Your branch is ahead of 'origin/master' by 4 commits.\n    (use \"git push\" to publish your local commits)\n  nothing to commit, working tree clean\n  ```\n\n  现在版本库变成了这样，暂存区就没有任何内容了：\n\n  <img src = \"http://orj2jcr7i.bkt.clouddn.com/git%20commit.png\" alt = \"flex-axis\">\n\n<div class=\"tip\">\n\n**小结：**\n暂存区是Git非常重要的概念，弄明白了暂存区，就弄明白了Git的很多操作到底干了什么!\n\n</div>\n\n## 管理修改\n\n为什么Git比其他版本控制系统设计得优秀，因为Git跟踪并管理的是修改，而非文件。\n\n每次修改，如果不 `add` 到暂存区，那就不会加入到 `commit` 中。\n\n**例如：**\n\n- 我们对 `git.txt` 进行两次修改，并在修改之间进行如下指令操作：\n\n  第一次修改 -> `git add` -> 第二次修改 -> `git commit`；\n\n  没错，我们会发现第二次修改没有被提交。我们前面讲了，Git管理的是修改，当你用`git add`命令后，在工作区的第一次修改被放入暂存区，准备提交，但是，在工作区的第二次修改并没有放入暂存区，所以，`git commit`只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。\n\n- 那怎么提交第二次修改呢？你可以继续 `git add` 再 `git commit` ，也可以别着急提交第一次修改，先 `git add` 第二次修改，再 `git commit` ，就相当于把两次修改合并后一块提交了：\n\n  第一次修改 -> `git add` -> 第二次修改 -> `git add` -> `git commit`\n\n  <br />\n\n注：提交后，用 `git diff HEAD -- readme.txt` 命令可以查看工作区和版本库里面最新版本的区别\n\n## 撤销修改\n\n每个人都会犯错，但重点在于你能不能及时改正，Git当然也知道这一点，所以它给了我们撤销修改这个机会。\n\n- **第一种情况，在没 `git add` 提交到暂存区时，撤销修改**\n\n  我对 `git.txt` 增加了一条错误信息，使用 `git diff` 查看一下：\n\n  ```sh\n   $ git diff HEAD -- git.txt\n  diff --git a/git.txt b/git.txt\n  index a537f08..246dfe2 100644\n  --- a/git.txt\n  +++ b/git.txt\n  @@ -4,4 +4,6 @@ Git is free software.\n   Git is a distributed version control system.\n   Git is free software.\n   add test add test\n\n  +\n  +Add an error message\n  \\ No newline at end of file\n  ```\n\n  我们再用 `git status` 查看一下状态：\n\n  ```sh\n  $ git status\n  On branch master\n  Your branch is ahead of 'origin/master' by 4 commits.\n    (use \"git push\" to publish your local commits)\n  Changes not staged for commit:\n    (use \"git add <file>...\" to update what will be committed)\n    (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n          modified:   git.txt\n\n  no changes added to commit (use \"git add\" and/or \"git commit -a\")\n  ```\n\n  可以发现，Git会告诉你，`git checkout -- file` 可以丢弃工作区的修改\n\n  ok， 我们试一下，执行：\n\n  ```sh\n  $ git checkout -- git.txt\n  ```\n\n  然后，查看文件 `git.txt`:\n\n  ```sh\n  $ cat git.txt\n  Git is a version control system.\n  Git is free software.\n\n  Git is a distributed version control system.\n  Git is free software.\n\n  add test add test\n  ```\n\n  嗯，最后一行 `Add an error message` 果然撤销了\n\n- **第二种情况，你把修改文件提交到了暂存区，但在`git commit`之前**\n\n  我们给 `git.txt` 添加 `Add a second error message`，并执行 `git add` 提交到暂存区，用 `git staus` 参看以下状态：\n\n  ```sh\n  $ $ git status\n    (use \"git push\" to publish your local commits)\n  Changes to be committed:\n    (use \"git reset HEAD <file>...\" to unstage)\n\n          modified:   git.txt\n  bash: $: command not found\n  ```\n\n  可以看到，Git同样告诉我们，用命令 `git reset HEAD file` 可以把暂存区的修改撤销掉（unstage），重新放回工作区：\n\n  ```sh\n  $ git reset HEAD git.txt\n  Unstaged changes after reset:\n  M       git.txt\n  ```\n\n  `git reset` 命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用 `HEAD` 时，表示最新的版本。\n\n  现在，我们可以执行 `git status` 查看状态发现，暂存区是干净的，而工作区有修改，其实，现在就回到了我们上面第一种情况了，执行 `git checkout -- git.txt` 后，查看状态，发现工作区也干净了，也就达到撤销修改的目的了。\n\n  ```sh\n  $ cat git.txt\n  Git is a version control system.\n  Git is free software.\n\n  Git is a distributed version control system.\n  Git is free software.\n\n  add test add test\n  ```\n\n<div class = \"tip\">\n\n**小结:**\n\n- 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。\n- 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。\n- 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考上一篇，不过前提是没有推送到远程库。\n\n</div>\n\n## 删除文件\n\n在Git中，删除也是一个修改操作，我们实验一下，之前添加一个新文件test.txt到Git并且进行了 `git commit` 提交操作，可以看下 `log`：\n\n```sh\n$ git log --pretty=oneline\n0fbc057e11b4ba59f3700a79d760e5af927a6a65 updata&test  //添加text.txt文件\n9152d920e48515d79a32824efcbe14b3665a3e6d add distributed\nf78f60960e2d59bd6fdc1a069e840c6d1f1c2566 add txt\n01ce8dd6733f7f78e7611ef72f2a092417de0bca updata homepage\n4db229de25fb4d0c325c98df9263b2c3d4d4607f add homepage\n6010c7e80796b40d89e1135bc2c86ac217274015 initial commit\n```\n\n一般情况下，我们通常直接在文件管理器中把没用的文件删了，或者用 `rm` 命令删了：\n\n```java\n$ rm test.txt\n\n# 查看目录 已经没了test,txt文件\n$ ls\ngit.txt  index.html  README.md\n```\n\n习惯性查看下状态：\n\n```json\n$ git status\nOn branch master\nYour branch is ahead of 'origin/master' by 4 commits.\n  (use \"git push\" to publish your local commits)\nChanges not staged for commit:\n  (use \"git add/rm <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n        deleted:    test.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n```\n\n发现Git已经知道我们进行了删除操作。\n\n**现在会出现两种情况：**\n\n- 一种情况就是执行 `rm` 命令后，发现文件删除错误了，但好在版本库里还有，所以可以很轻松的把误删的文件恢复到最新版本：\n\n  ```json\n  $ git checkout -- test.txt\n  ```\n\n  `git checkout`其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。\n\n\n- 另一种情况确定进行删除操作，并需要从版本库中删除该文件。因此，需要使用 `git rm` 命令，并执行 `git commit` 提交操作：\n\n  ```sh\n  $ git rm test.txt\n  rm 'test.txt'\n\n  $ git commit -m \"deleted test\"\n  [master a15cd98] deleted test\n   1 file changed, 0 insertions(+), 0 deletions(-)\n   delete mode 100644 test.txt\n  ```\n\n  现在，文件就从版本库中也删除了，就此消失不见~~~\n\n<div class = \"tip\">\n\n命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。\n\n</div>"},{"title":"版本控制","path":"/wiki/git/version-control/index.html","content":"## 创建版本库\n**把文件添加到版本库：**\n- 通过 `git init` 命令把这个目录变成Git可以管理的仓库\n  ```json\n  $ git init\n  Initialized empty Git repository in E:/git/test/.git/\n  ```\n- 用命令 `git add` 告诉Git，把文件添加到仓库\n  ```sh\n  $ git add README.md\n  ```\n- 用命令 `git commit` 告诉Git，把文件提交到仓库\n  ```sh\n  $ git commit -m \"initial commit\"\n  [master (root-commit) 6010c7e] initial commit\n   1 file changed, 7 insertions(+)\n   create mode 100644 README.md\n  ```\n  **另外：**\n  初始创建一个 `github` 仓库时，`github` 会给一些命令你去创建git本地项目.\n\n```sh\ngit remote add origin https://github.com/leeifme/test.git\n```\n这里的origin仅仅是一个名字，你可以把 `origin` 命名为 `test` `git remote add test https://github.com/leeifme/test.git`, 以后就可以用 `git push text master` 了\n\n`git push -u origin master` , 这里就是把 master（默认 git 分支）推送到 origin， `-u`也就是`--set-upstream`, 代表的是更新默认推送的地方，这里就是默认以后`git pull`和`git push`时，都是推送和拉自 origin 。\n\n<!-- more -->\n\n## 版本回退\n\n- `git status` 命令可以让我们时刻掌握仓库当前的状态\n- `git diff` 顾名思义就是查看difference(修改内容)\n- 如果 `git status` 告诉你有文件被修改过，用 `git diff` 可以查看修改内容。\n\n**如何回退和撤回操作：**\n\n- 先用 `git log` 命令显示从最近到最远的 `git commit` 提交日志\n\n  ```sh\n  $ git log\n  commit f78f60960e2d59bd6fdc1a069e840c6d1f1c2566\n  Author: **********************\n  Date:   Thu Jun 15 01:24:55 2017 +0800\n\n      add txt\n\n  commit 01ce8dd6733f7f78e7611ef72f2a092417de0bca\n  Author: **********************\n  Date:   Thu Jun 15 01:23:51 2017 +0800\n\n      updata homepage\n\n  commit 4db229de25fb4d0c325c98df9263b2c3d4d4607f\n  Author: **********************\n  Date:   Thu Jun 15 01:14:33 2017 +0800\n\n      add homepage\n\n  commit 6010c7e80796b40d89e1135bc2c86ac217274015\n  Author: **********************\n  Date:   Thu Jun 15 01:03:15 2017 +0800\n\n      initial commit\n  ```\n\n  **注：** 这样输出信息太多，看得眼花缭乱的，可以试试加上 `--pretty=oneline` 参数\n  ```sh\n  $ git log --pretty=oneline\n  9152d920e48515d79a32824efcbe14b3665a3e6d add distributed\n  f78f60960e2d59bd6fdc1a069e840c6d1f1c2566 add txt\n  01ce8dd6733f7f78e7611ef72f2a092417de0bca updata homepage\n  4db229de25fb4d0c325c98df9263b2c3d4d4607f add homepage\n  6010c7e80796b40d89e1135bc2c86ac217274015 initial commit\n  ```\n\n\n\n- 回退版本，使用`git reset`命令。在Git中，用`HEAD`表示当前版本，也就是最新的提交`3628164...882e1e0`（注意我的提交ID和你的肯定不一样），上一个版本就是`HEAD^`，上上一个版本就是`HEAD^^`，当然往上100个版本写100个`^`比较容易数不过来，所以写成`HEAD~100`。\n\n  ```sh\n  $ git reset --hard HEAD^\n  HEAD is now at f78f609 add txt //注意看commitID\n  ```\n\n  ​\n\n- 后悔回退，想恢复版本，怎么办？只要知道`commitID`就好，怎么找？\n\n  Git很人性化的提供了一个命令`git reflog`用来记录你的每一次命令：\n\n  ```json\n  $ git reflog\n  f78f609 HEAD@{0}: reset: moving to HEAD^\n  9152d92 HEAD@{1}: commit: add distributed\n  f78f609 HEAD@{2}: commit: add txt\n  01ce8dd HEAD@{3}: commit: updata homepage\n  4db229d HEAD@{4}: commit: add homepage\n  6010c7e HEAD@{5}: commit (initial): initial commit\n  ```\n\n- 知道`commitID`后,由于`HEAD`指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令`git reset --hard commit_id`\n\n  ```sh\n  $ git reset --hard 9152d92\n  HEAD is now at 9152d92 add distributed\n  ```\n\n  我们可以再看下版本日志，查看是否回到`commitID = 9152d92`的版本：\n\n  ```json\n  $ git log --pretty=oneline\n  9152d920e48515d79a32824efcbe14b3665a3e6d add distributed\n  f78f60960e2d59bd6fdc1a069e840c6d1f1c2566 add txt\n  01ce8dd6733f7f78e7611ef72f2a092417de0bca updata homepage\n  4db229de25fb4d0c325c98df9263b2c3d4d4607f add homepage\n  6010c7e80796b40d89e1135bc2c86ac217274015 initial commit\n  ```"},{"title":"使用标签插件增强阅读体验","path":"/wiki/stellar/tag-plugins/index.html","content":"Stellar 的标签插件和 Hexo 官方的标签插件一样使用空格分隔多个参数，所以如果参数内容中需要出现的空格被意外分隔开了的时候，请使用 `&nbsp;` 代替。为了方便理解，本文档语法格式中的可选参数用方括号括起来，键值对参数用冒号分隔开，例如：``````就表明第一个参数是图片链接，第二个参数是图片描述，而 `download` 是可选参数，并且值是布尔或字符串类型，第二三个参数为可选参数。以图片标签为例，使用空格分隔开之后得到一个数组，如果图片描述文字中有空格，多分出来的这些「参数」被合并到最后一个「非键值对参数」中，什么是「非键值对参数」呢？举个例子您就明白了：``````这个例子中，`download:https://xxxx` 是有冒号分隔开的，`download` 为键，后面的网址为值，所以叫做「键值对参数」；与此相对的，没有冒号分隔的就叫做「非键值对参数」。键值对参数可以放在任何位置，我可以通过匹配键来解析，而非键值对参数则只能通过顺序解析，所以它们必须和文档中要求的前后顺序一致。一般核心的、重要的参数会设置成非键值对参数，而可选参数设置成键值对参数。"},{"title":"如何使用半自动化的文档系统","path":"/wiki/stellar/wiki-settings/index.html","content":"自动意味着 Stellar 可以自动找到一个项目的所有文档分页，生成一个目录树，半自动意味着您可以手动指定顺序、标题、分组，而非依赖文件路径、文件名来排序和显示。\n\n## 创建一个项目\n\n在 `blog/source/` 文件夹中创建一个 `wiki` 文件夹，在其中放入各个项目的文档。以 Stellar 项目为例：\n\n```\nblog/source/wiki/stellar/index.md\n```\n\n设置布局模板和项目名称：\n\n```yaml blog/source/wiki/stellar/index.md\n---\nlayout: wiki  # 使用wiki布局模板\nwiki: Stellar # 这是项目名\ntitle: 这是分页标题\n---\n```\n\n建议用这个文件作为项目的主页，并在文件夹内创建其它分页。Stellar 会把同一个项目的所有分页中 `order` 最小的一页作为项目的主页（其默认值为0）。\n\n## 完善项目信息\n\n在数据文件中创建项目文件，以 Stellar 为例：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  title: Stellar\n  subtitle: 每个人的独立博客\n  tags: 博客主题\n  cover: true\n  logo:\n    src: https://cdn.jsdelivr.net/gh/cdn-x/wiki@1.0.2/stellar/icon.svg\n    small: 112px\n    large: 240px\n  description: Stellar 是一个内置 wiki 系统的 hexo 主题，适合综合型站点使用。同时也拥有简约而精美的视觉设计和丰富的标签插件，帮助您简单从容地应对各种场合。\n  repo: xaoxuu/hexo-theme-stellar\n  comment_title: '评论区仅供交流，有问题请提 [issue](https://github.com/xaoxuu/hexo-theme-stellar/issues) 反馈。'\n  beaudar:\n    repo: xaoxuu/hexo-theme-stellar\n    'issue-term': 'Q & A'\n```\n\n\n### 是否显示封面\n\n项目可以显示一个全屏封面，封面占据一个屏幕的高度，会居中依次显示项目的 logo、标题、描述。开启项目封面方法如下：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  cover: true\n  logo:\n    src: https://cdn.jsdelivr.net/gh/cdn-x/wiki@1.0.2/stellar/icon.svg\n    small: 120px\n    large: 240px\n```\n\n如果 logo 中已经包含了项目标题，可以这样设置不显示项目标题：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  cover: [logo, description]\n```\n\n### 项目文档标签\n\n如果您有很多项目，有些项目是有相关性的，可以相同的 `tags` 值：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  tags: 博客主题\n```\n\n也可以设置多个 `tags` 值：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  tags: [博客主题, 开源项目]\n```\n\n\n### 项目的 GitHub 仓库信息\n\n设置了 `repo` 值就会在侧边栏显示项目仓库的相关链接：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  repo: xaoxuu/hexo-theme-stellar\n```\n\n### 项目评论设置\n\n如果希望项目的所有分页使用相同的评论数据，可以在这里覆盖评论配置：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  comment_title: '评论区仅供交流，有问题请提 [issue](https://github.com/xaoxuu/hexo-theme-stellar/issues) 反馈。'\n  beaudar:\n    repo: xaoxuu/hexo-theme-stellar\n    'issue-term': 'Q & A'\n```\n\n> 目前支持覆盖 beaudar/utterances，其它评论系统可以通过设置 `comment_id` 来实现。\n\n### 是否索引\n\n如果您有些项目希望在项目列表中隐藏，可以设置 `index` 值：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  index: false\n```\n\n## 文档排序\n\n一个项目文档的多个分页之间以 `order` 的值作为排序依据，数字越小越靠前，最小的是项目主页。\n\n## 侧边栏设置\n\n### 侧边栏组件\n\n如果您希望自定义某个项目的侧边栏组件，可以设置 `sidebar` 值：\n\n```yaml blog/source/_data/projects.yml\nNotes:\n  sidebar: [toc]\n```\n\n### 对目录树进行分组\n\n如果您的项目文档分页较多，可以对目录树进行分组：\n\n```yaml blog/source/_data/projects.yml\nStellar:\n  ...\n  sections:\n    '快速开始': [0, 99]\n    '基本使用': [100, 199]\n    '文档系统': [200, 299]\n    '进阶设定': [900, 999]\n```\n\n左边是显示的标题，右边是 `order` 的区间，例如某页文档的 `order` 是 `150`，那么这页文档将会显示在「日常问题解决方案」这个组中。\n\n\n\n## 修改 wiki 路径\n\n在根目录中添加 `wiki_dir` 指定 Wiki 主页的路径：\n\n```yaml blog/_config.yml\nwiki_dir: wiki\n```\n\n例如书籍类的“项目”可以改为：\n\n```yaml blog/_config.yml\nwiki_dir: books\n```\n\n例如商品/产品类的“项目”可以改为：\n\n```yaml blog/_config.yml\nwiki_dir: products\n```"},{"title":"容器类标签（7个）","path":"/wiki/stellar/tag-plugins/container/index.html","content":"ablock 普通块容器note 标签就是使用 ablock 容器实现的，它们样式是相同的：更名记录（Stellar 1.18.0） color:warning因为原 noteblock 标签在升级到 hexo 6.0 之后跟官方库冲突了，官方一直没有解释原因，后不得不改名：noteblock -> grid -> border -> ablock详情见：#172```md 语法格式...``````md 写法如下因为原 noteblock 标签在升级到 hexo 6.0 之后跟官方库冲突了，官方一直没有解释原因，后不得不改名：noteblock -> grid -> border详情见：#172```彩色代码块设置 `child:codeblock` 并设置 `color:颜色枚举` 可以实现 10 种不同颜色的代码块，彩色代码块一般可以用在代码正确与错误的示范对比场景。**推荐的写法**```swiftfunc test() { // ...}```**不推荐的写法**```swiftfunc test() -> () { // ...}```嵌套其它标签例如嵌套一个 `tabs` 标签： 图文混排公司一般都会强制安装安防软件，这些软件要求开机自启动，要求有屏幕录制权限、完全的磁盘访问权限包括相册图库。因此如果使用自己的 MacBook 作为办公设备，必须要把生活区和工作区完全独立开，安装在两个磁盘分区，并且对磁盘分区进行加密。 示例代码<script src=\"https://gist.github.xaox.cc/xaoxuu/c983c958ef0deab819376c231e977ba7.js\"></script>folding 折叠容器折叠块标签的语法格式为：```title [codeblock:bool] [open:bool] [color:color]content``````yaml 参数说明codeblock: true/falseopen: true/falsecolor: red/orange/yellow/green/cyan/blue/purple/light/dark```彩色可折叠代码块备注标签相较于旧版进行了增强，可以实现更多种颜色，还可以通过设置 `child:codeblock` 来实现可折叠的代码块。以下是一个默认打开的代码折叠框：child:codeblock open:true color:yellow 默认打开的代码折叠框```swiftfunc test() { print(\"hello world\")}```代码如下：```child:codeblock open:true color:yellow 默认打开的代码折叠框代码块```color:yellow 危险，请不要打开这个通过设置颜色，以实现更醒目的作用，但不要滥用色彩哦～color:orange 警告，真的很危险通过设置颜色，以实现更醒目的作用，但不要滥用色彩哦～color:red 最后一次警告，千万不要打开这个不要说我们没有警告过你，Windows 10 不是為所有人設計，而是為每個人設計。folders 多个折叠容器聚合样式相比 `folding` 简单一些，适用于多个折叠标签平铺显示的场景，例如题目列表： 题目1这是答案1 题目2这是答案2 题目3这是答案3代码如下：``` 题目1这是答案1 题目2这是答案2 题目3这是答案3```tabs 分栏容器这个标签移植自 NexT 主题，但做了以下修改：- 支持设置 `align:center` 来使内容居中- 设置默认激活的标签方式为 `active:1` 而非 `, 1`（使用默认格式降低学习成本，且显式声明可读性更强）- 不需要 `` 来作为结束标识（因为 Stellar 会自动判断）- 不需要 `tabs id` 来保证唯一性（因为 Stellar 会设置唯一标识）- 不支持 `@icon` 方式设置图标（因为 Stellar 不再内置 `fontawesome` 图标库）- 轮廓样式简化，可以搭配其它容器类标签嵌套使用。 演示效果 图片 代码块```swiftlet x = 123print(\"hello world\")``` 表格 a  b  c  ---  ---  ---  a1  b1  c1  a2  b2  c2  示例代码<script src=\"https://gist.github.xaox.cc/xaoxuu/cfd4e9645047115c6aa9b19cd9b28e97.js\"></script>grid 网格分区容器这个功能在 1.12.0 color:dark 版本后开始支持，目前只支持显示一行两列，且手机端因宽度较窄会恢复为单列显示。**Unsplash Photo**The Galactic Center is the rotational center of the Milky Way galaxy. Its central massive object is a supermassive black hole of about 4 million solar masses, which is called Sagittarius A*. Its mass is equal to four million suns. The center is located 25,800 light years away from Earth.> Ōwhiro Bay, Wellington, New Zealand> Published on May 31, 2022> SONY, ILCE-6000> Free to use under the Unsplash License普通块样式：<center>左侧内容</center><center>右侧内容</center>卡片样式：<center>左侧内容</center><center>右侧内容</center>示例代码：```<center>左侧内容</center><center>右侧内容</center>```> `bg` 为可选参数，默认没有背景，可设置为 `block/card` 两种样式about 关于块容器方便在关于页面显示一段图文信息，比普通块容器稍微有一点点不一样：```<img height=\"32px\" alt=\"XAOXUU\" src=\"/assets/xaoxuu/logo/180x30@2x.png\">**如果宇宙中真有什么终极的逻辑，那就是我们终有一天会在舰桥上重逢，直到生命终结。**XAOXUU 目前是一个 iOS 开发者，代表作品有：ProHUD、ValueX 等。在业余时间也开发了 Stellar 博客主题，更多的作品可以去项目主页查看，希望大家喜欢～```color:yellow 这个标签正在考虑重命名 请发表您的建议 #198swiper 轮播容器默认一张图片是 50% 宽度，通过设置 `width:min` 设置为 25% 宽度，`width:max` 设置为 100% 宽度。```md 写法如下``` 宽度```md 写法如下...``` 切换效果```...```color:warning 注意 一个页面只能设置一次，第一个 `swiper` 容器的效果全局生效。"},{"title":"数据集合类标签（5个）","path":"/wiki/stellar/tag-plugins/data/index.html","content":"timeline 时间线支持静态和动态时间线数据源，用法非常多，详见这篇文章：静态时间线静态数据是写死在 `md` 源文件中的，在 `deploy` 时就已经确定了。 2021 年 2 月 16 日主要部分功能已经开发的差不多了。 2021 年 2 月 11 日今天除夕，也是生日，一个人在外地过年+过生日，熬夜开发新主题，尽量在假期结束前放出公测版。```md 写法如下 2021 年 2 月 16 日主要部分功能已经开发的差不多了。 2021 年 2 月 11 日今天除夕，也是生日，一个人在外地过年+过生日，熬夜开发新主题，尽量在假期结束前放出公测版。```动态时间线 动态说说动态数据是从 GitHub Issues 中拉取的，使用方法为：1. 建一个仓库2. 创建一个 `issue` 并添加一个 `label` 进行测试3. 写 `timeline` 标签时加上 `api:https://api.github.com/repos/your-name/your-repo/issues`例如：```md _posts/xxx.md```效果如下： 朋友圈```md _posts/xxx.md``` 微博动态1. fork 爬虫 仓库 ，修改自己的仓库名2. 修改 `.github/workflows/main.yml` 中的微博ID为你想爬取的ID，修改完后每天会自动爬取你的微博，存储为 json 文件，输出文件在 output 分支```md _posts/xxx.md```静态 + 动态用法同静态和动态单独使用时一样，例如：``` 这条内容为静态数据这条内容为静态数据，静态数据在 `deploy` 时就已经确定了。```数据筛选 只显示某个人的数据 筛选最近3条todo 筛选评论最多的3条建议上述示例代码如下：``````更多用法详见：friends 友链您可以在任何位置插入友链组，支持静态数据和动态数据，静态数据需要写在数据文件中：```yaml blog/source/_data/links.yml'开源大佬': - title: 某某某 url: https:// screenshot: avatar: description:```在需要的位置这样写：```md```实现动态友链从 xaoxuu/issues-json-generator 作为模板克隆或者 fork 仓库修改 `config.yml` 并打开 github action 的运行权限```yaml config.yml# 要抓取的 issues 配置issues: repo: xaoxuu/friends # 仓库持有者/仓库名（改成自己的） label: active # 筛选具有 active 标签的 issue ，取消此项则会提取所有 open 状态的 issue sort: # updated-desc # 排序，按最近更新，取消此项则按创建时间排序```不出意外的话，仓库中已经配置好了 issue 模板，只需要在模板中指定的位置填写信息就可以了。然后在自己的仓库里提交一个 issue 并将 `Label` 设置为 `active` 进行测试。提交完 issue 一分钟左右，如果仓库中出现了 `output` 分支提交，可以点击查看一下文件内容是否已经包含了刚刚提交的 issue 中的数据，如果包含，那么前端页面就可以使用友链数据了：``````数据托管与加速特别感谢小冰博客的加速访问方案，解决了直接请求 GitHub API 速度过慢的问题，详见 小冰博客 的教程。支持把数据托管到任何其他地方来使用，例如：``````动态数据 API 升级至 v2 版本，原使用 issue-api 仓库的需要将友链仓库同步更新。v1 版本已经停止维护。> 你可以有 N 种办法加速访问 GitHub 仓库里的文件。sites 网站卡片您可以在任何位置插入网站卡片组，支持静态数据和动态数据，静态数据需要写在数据文件中：```yaml blog/source/_data/links.yml'分组名': - title: 某某某 url: https:// screenshot: avatar: description:```在需要的位置这样写：```md```原 friends 和 sites 标签数据合并至 `links.yml` 文件，动态数据使用方法同友链，数据源格式相同，与友链共享数据，仅样式不同，也可以用 `sites` 标签做友链。ghcard 卡片```md 写法如下```toc 文档目录树``````"},{"title":"表达类标签（14+个）","path":"/wiki/stellar/tag-plugins/express/index.html","content":"emoji 表情 效果演示内置了可配置的表情标签 使用方法如下：`````` 语法格式``````其中 `source` 可省略，默认为配置中的第一个 `source`（详见「引入表情包」部分）如果对高度有特别要求，可以指定高度，例如：``````> 表情速查表1：stellar表情标签索引> 表情速查表2：Stellar内嵌blobcat小表情 引入表情包```yaml blog/_config.stellar.ymltag_plugins: ... emoji: default: https://fastly.jsdelivr.net/gh/cdn-x/emoji/qq/%s.gif twemoji: https://fastly.jsdelivr.net/gh/twitter/twemoji/assets/svg/%s.svg qq: https://fastly.jsdelivr.net/gh/cdn-x/emoji/qq/%s.gif aru: https://fastly.jsdelivr.net/gh/cdn-x/emoji/aru-l/%s.gif tieba: https://fastly.jsdelivr.net/gh/cdn-x/emoji/tieba/%s.png```> 在配置文件中，文件名用 `%s` 代替。mark 行内文本标记支持多彩标记，包括：默认 红 color:red 橙 color:orange 黄 color:yellow 绿 color:green 青 color:cyan 蓝 color:blue 紫 color:purple 浅 color:light 深 color:dark 警告 color:warning 错误 color:error 一共 12 种颜色。```支持多彩标记，包括：默认 红 color:red 橙 color:orange 黄 color:yellow 绿 color:green 青 color:cyan 蓝 color:blue 紫 color:purple 浅 color:light 深 color:dark 警告 color:warning 错误 color:error 一共 12 种颜色。```tag 标签这个效果类似于 `mark` 标签，但是更适合一批标签独占一行来使用，支持链接：如果没有指定颜色，且没有设置默认颜色，则随机取一个颜色，快来试试吧～``````image 图片标签图片标签是一个精心设计的应对各种尺寸插图的标签，对于大图，可以放置一个「下载」按钮，语法格式如下：`````````yaml 参数说明src: 图片地址description: 图片描述download: href # 下载地址，设置此值后鼠标放在图片上会显示下载地址，如果下载地址为图片地址，可以设置为 truewidth: 200px # 图片宽度padding: 16px # 图片四周填充宽度bg: '#ffffff' # 图片区域背景颜色，16进制```大尺寸图片无论在什么宽度的设备上都希望横向铺满的图片，一般不需要额外操作。可以在链接后面写上图片描述，如有必要，可以通过设置 `download:true` 使其显示一个「下载」按钮链接指向图片地址，如果下载链接与显示的图片地址不同，可以 `download:下载链接` 来使其能够下载原图。```md 写法如下```小尺寸图片优化宽度较小而高度较大的图片，可以设置宽、高、填充间距、背景色等对其布局进行优化，使得它在不同宽度的屏幕下都能获得不错的视觉体验： 有底色的图片有底色的图片，可以填充图片底色：``````提示 鼠标拖拽一下图片可以看看原图如果不进行约束，在宽屏设备上阅读体验很糟糕 没有底色的图片没有底色的图片，可以填充 `bg:var(--card)` 动态颜色，能够适配暗黑模式：``````支持 Fancybox 插件点击放大由于 Stellar 主题的插件具有按需加载的特性，所以 Fancybox 插件默认也是已经配置好了的，在任意 `image` 标签中增加 `fancybox:true` 参数即可为特定图片开启缩放功能。如果一个页面没有任何地方使用，则不会加载 Fancybox 插件。如果您希望全站所有的 `image` 标签都开启此功能，可在主题配置文件中修改以下参数：```yamlTag Plugins ########tag_plugins: # image: fancybox: true```quot 引用适合居中且醒目的引用：支持自定义引号：其中自定义引号素材在主题配置文件的 `tag_plugins.quot` 中配置：```yamltag_plugins: ... # quot: default: # 可以自行配置多种图标方案 prefix: https://bu.dusays.com/2022/10/24/63567d3e092ff.png suffix: https://bu.dusays.com/2022/10/24/63567d3e0ab55.png hashtag: prefix: https://bu.dusays.com/2022/10/24/63567d3e07da3.png```child:codeblock 写法如下 open:true```适合居中且醒目的引用：支持自定义引号：```> 此外，加上 `el:h2/h3/h4/h5/h6` 可以作为标题使用poetry 诗词 示例莫笑农家腊酒浑，丰年留客足鸡豚。**山重水复疑无路，柳暗花明又一村。**箫鼓追随春社近，衣冠简朴古风存。从今若许闲乘月，拄杖无时夜叩门。 写法```莫笑农家腊酒浑，丰年留客足鸡豚。**山重水复疑无路，柳暗花明又一村。**箫鼓追随春社近，衣冠简朴古风存。从今若许闲乘月，拄杖无时夜叩门。```note 备注块 示例```md[title] content [color:color]``` 写法```yamltitle: 标题（可选）content: 内容color: red/orange/yellow/green/cyan/blue/purple/light/dark/warning/error```具有标题的备注块直接写备注内容，默认是和代码块一样的样式，第一个空格前面的是标题，后面的是正文，如果标题中需要显示空格，请使用 `&nbsp;` 代替。 示例这&nbsp;是标题 这是正文 哈哈。 写法```这&nbsp;是标题 这是正文 哈哈。```彩色备注块 示例一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:red 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:orange 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:yellow 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:green 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:cyan 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:blue 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:purple 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:light 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:dark 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:warning 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:error 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 写法```md一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。color:cyan 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。```link 链接卡片 效果演示 语法格式外链卡片标签的语法格式为：``````参数含义：```yamlhref: 链接title: 可选，手动设置标题（为空时会自动抓取页面标题）icon: 可选，手动设置图标（为空时会自动抓取页面图标）desc: 可选，是否显示摘要描述，为true时将会显示页面描述``` 写法示例```md不带摘要的样式：带摘要的样式：```copy 复制行 示例对于单行内容，可以使用 `copy` 标签来实现复制功能：curl -s https://sh.xaox.cc/install  sh您可以设置 `git:https` 或者 `git:ssh` 或者 `git:gh` 来快速放置一个 git 仓库链接：git:https xaoxuu.com/hexo-theme-stellar 写法```mdcurl -s https://sh.xaox.cc/install  shwidth:max curl -s https://sh.xaox.cc/install  shgit:https xaoxuu.com/hexo-theme-stellargit:ssh xaoxuu.com/hexo-theme-stellargit:gh xaoxuu.com/hexo-theme-stellar```radio 单选 示例 写法`````````yaml 支持的参数checked: true/falsecolor: red/orange/yellow/green/cyan/blue/purple```checkbox 复选 示例 写法```md``````yaml 支持的参数checked: true/falsecolor: red/orange/yellow/green/cyan/blue/purplesymbol: plus/minus/times```navbar 导航栏文章内也可以插入一个导航栏：```md```frame 设备框架 示例 写法```md```文本修饰标签集- 这是  标签- 这是  标签- 这是 着重号 标签- 这是 波浪线 标签- 这是  标签- 这是 上角标 color:red 标签- 这是 下角标 标签- 这是 键盘样式 标签，试一试：⌘ + D```md 写法如下- 这是  标签- 这是  标签- 这是 着重号 标签- 这是 波浪线 标签- 这是  标签- 这是 上角标 color:red 标签- 这是 下角标 标签- 这是 键盘样式 标签，试一试：⌘ + D```"}]