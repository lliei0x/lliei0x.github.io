[{"title":"OpenLDAP 快速落地实践-进阶","path":"/2020/openldap-high-ranking.html","content":"备份与恢复 主要介绍如何备份 OpenLDAP 的配置目录和数据目录，并将其恢复到另一个 OpenLDAP 服务中 OpenLDAP 的备份OpenLDAP 的备份可以通过服务端的 slapcat 命令或客户端的 ldapsearch 命令两种方式进行。下面展示了如何在 OpenLDAP 服务端使用 slapcat 对配置目录和数据目录进行导出。 slapcat -n 0 -l ./config.`date &#x27;+%Y-%m-%d&#x27;`.ldifslapcat -n 2 -l ./data.`date &#x27;+%Y-%m-%d&#x27;`.ldif 其中，-n 表示要导出的 OpenLDAP 数据库编号 OpenLDAP 的恢复在开始恢复之前，需要先暂停 OpenLDAP 服务systemctl stop slapdOpenLDAP 配置目录一般位于 /etc/openldap/slapd.d，我们需要先将原有配置删除，然后使用 slapadd 导入新的配置rm -rf &#x2F;etc&#x2F;openldap&#x2F;slapd.d&#x2F;*slapadd -n 0 -F &#x2F;etc&#x2F;openldap&#x2F;slapd.d -l .&#x2F;config.2019-01-04.ldifchown -R ldap:ldap &#x2F;etc&#x2F;openldap&#x2F;slapd.d2020-04-20 OpenLDAP 数据目录一般位于 /var/lib/ldap，同样的我们需要先将原有数据删除，然后使用 slapadd 导入新的数据rm -rf &#x2F;var&#x2F;lib&#x2F;ldap&#x2F;*slapadd -n 2 -F &#x2F;etc&#x2F;openldap&#x2F;slapd.d -l .&#x2F;data.2019-01-04.ldifchown -R ldap:ldap &#x2F;var&#x2F;lib&#x2F;ldap最后，重启 OpenLDAP 服务即可systemctl start slapd 添加 memberof 支持 如果使用 LDAP 仅仅作为用户统一登录中心，则参考安装文档即可；如果 ldap 要与第三方软件结合，例如 confluence、gitlab 等结合，则需要开启 memberof 支持 开启 memberof 支持。 vim 1-load-memberof.ldif内容如下：dn: cn=module,cn=configobjectClass: olcModuleListcn: module olcModuleLoad: memberof.laolcModulepath: /usr/lib64/openldap#ldap库路径与操作系统版本是相关的，此处是64位操作系统。 新增用户支持 memberof 配置。 vim 2-use-memberof.ldifdn: olcOverlay=memberof,olcDatabase=&#123;2&#125;hdb,cn=configobjectClass: olcConfigobjectClass: olcMemberOfobjectClass: olcOverlayConfigobjectClass: topolcOverlay: memberof 导入相关配置。 ldapadd -Y EXTERNAL -H ldapi:/// -f 1-chrootpw.ldifldapadd -Y EXTERNAL -H ldapi:/// -f 2-chdomain.ldifldapadd -Y EXTERNAL -H ldapi:/// -f 3-load-memberof.ldifldapadd -Y EXTERNAL -H ldapi:/// -f 4-use-memberof.ldif 查看当前 dn 下包含 cn&#x3D;config 配置列表。 ldapsearch -Q -LLL -Y EXTERNAL -H ldapi:/// -b cn=config dn 查看用户的 memberof 信息。 ldapsearch -LL -Y EXTERNAL -H ldapi:/// &quot;(uid=xxxxxx)&quot; -b dc=xxx,dc=com dn memberof 开启日志查看现在的日志配置[root@slave3] ~cat &#x2F;etc&#x2F;openldap&#x2F;slapd.d&#x2F;cn=config.ldif |grep olcLogLevelstate必须先创建日志文件，并调整权限，再修改 rsyslog.confmkdir -p &#x2F;var&#x2F;log&#x2F;slapdtouch &#x2F;var&#x2F;log&#x2F;slapd&#x2F;slapd.logchown ldap:ldap &#x2F;var&#x2F;log&#x2F;slapd&#x2F;echo “local4.* &#x2F;var&#x2F;log&#x2F;slapd&#x2F;slapd.log” &gt;&gt; &#x2F;etc&#x2F;rsyslog.conf重启使其生效systemctl restart rsyslog修改数数据库配置文件[root@test1] ~$ cat log.ldifdn: cn&#x3D;configchangetype: modifyadd: olcLogLevelolcLogLevel: 32[root@test1] ~$ ldapmodify -Y EXTERNAL -H ldapi:&#x2F;&#x2F;&#x2F; -f log.ldif最好进行日志切割配置，防止文件过大，不便排查故障vi /etc/logrotate.d/ldap&#x2F;var&#x2F;log&#x2F;slapd&#x2F;slapd.log{ daily # 每天轮询一次 rotate 5 # 保存5个历史日志文件，超过的删除 size 100M copytruncate # 复制源日志内容后，清空文件，而不是创建新文件 dateext # 切割文件时，文件名带有日期 missingok # 如果指定的目录不存在，会报错，此选项用来抑制报错} 如果你是使用旧版修改配置文件的方式，如下启用日志功能 修改 slapd.conf[root@backup2] &#x2F;etc&#x2F;openldap$ vim slapd.conf#末尾添加一行loglevel -1修改 rsyslog.conf，并重启[root@backup2] &#x2F;etc&#x2F;openldap$ vim &#x2F;etc&#x2F;rsyslog.conf#末尾添加如下一行：local4.* &#x2F;var&#x2F;log&#x2F;slapd.log[root@backup2] &#x2F;etc&#x2F;openldap$ systemctl restart rsyslog生成配置[root@backup2] &#x2F;etc&#x2F;openldap$ rm -rf &#x2F;etc&#x2F;openldap&#x2F;slapd.d&#x2F;*[root@backup2] &#x2F;etc&#x2F;openldap$ slaptest -f &#x2F;etc&#x2F;openldap&#x2F;slapd.conf -F &#x2F;etc&#x2F;openldap&#x2F;slapd.d&#x2F;[root@backup2] &#x2F;etc&#x2F;openldap$ systemctl start slapd.service123 来查看日志通过 tailf /var/log/slapd.log 来查看日志","tags":["OpenLDAP"],"categories":["折腾不止"]},{"title":"Kubernetes 控制器的进化之旅","path":"/2020/kubernetes-operator.html","content":"我是一堆 Kubernetes 控制器。 你可能会疑惑为什么是一堆，因为我不是一个人，我只是众多控制器中的一员，你也可以把我看成是众多控制器的集合。我的职责就是监控集群内资源的实际状态，一旦发现其与期望的状态不相符，就采取行动使其符合期望状态。 想当初，Kubernetes 老大哥创造我时，只是打算让我用控制循环简单维护下资源的状态。但我后来的发展，远远超出了他的想象。 1. 控制循环所谓控制循环就是一个用来调节系统状态的周期性操作，在 Kubernetes 中也叫调谐循环（Reconcile Loop）。我的手下控制着很多种不同类型的资源，比如 Pod，Deployment，Service 等等。就拿 Deployment 来说吧，我的控制循环主要分为三步： 从 API Server 中获取到所有属于该 Deployment 的 Pod，然后统计一下它们的数量，即它们的实际状态。 检查 Deployment 的 Replicas 字段，看看期望状态是多少个 Pod。 将这两个状态做比较，如果期望状态的 Pod 数量比实际状态多，就创建新 Pod，多几个就创建几个新的；如果期望状态的 Pod 数量比实际状态少，就删除旧 Pod，少几个就删除几个旧的。 然而好景不长，我收到了 Kubernetes 掌门人（看大门的） API Server 的抱怨：“你访问我的次数太频繁了，非常消耗我的资源，我连上厕所的时间都没有了！” 我仔细一想，当前的控制循环模式确实有这个缺陷 —— 访问 API Server 的次数太频繁了，容易被老大反感。 所以我决定，找一个小弟。 2. Informer这次我招的小弟叫 Informer，它分担一部分我的任务，具体的做法是这样的：由 Informer 代替我去访问 API Server，而我不管是查状态还是对资源进行伸缩都和 Informer 进行交接。而且 Informer 不需要每次都去访问 API Server，它只要在初始化的时候通过 LIST API 获取所有资源的最新状态，然后再通过 WATCH API 去监听这些资源状态的变化，整个过程被称作 ListAndWatch。 而 Informer 也不傻，它也有一个助手叫 Reflector，上面所说的 ListAndWatch 事实上是由 Reflector 一手操办的。 这一次，API Server 的压力大大减轻了，因为 Reflector 大部分时间都在 WATCH，并没有通过 LIST 获取所有状态，这使 API Server 的压力大大减少。我想这次掌门人应该不会再批评我了吧。 然而没过几天，掌门人又找我谈话了：“你的手下每次来 WATCH 我，都要 WATCH 所有兄弟的状态，依然很消耗我的资源啊！我就纳闷了，你一次搞这么多兄弟，你虎啊？” 我一想有道理啊，没必要每次都 WATCH 所有兄弟的状态，于是告诉 Informer：“以后再去 API Server 那里 WATCH 状态的时候，只查 WATCH 特定资源的状态，不要一股脑儿全 WATCH。“ Informer 再把这个决策告诉 Reflector，事情就这么愉快地决定了。 本以为这次我会得到掌门人的夸奖，可没过几天安稳日子，它又来找我诉苦了：“兄弟，虽然你减轻了我的精神压力，但我的财力有限啊，如果每个控制器都招一个小弟，那我得多发多少人的工资啊，你想想办法。” 3. SharedInformer经过和其他控制器的讨论，我们决定这么做：所有控制器联合起来作为一个整体来分配 Informer，针对每个（受多个控制器管理的）资源招一个 Informer 小弟，我们称之为 SharedInformer。你们可以理解为共享 Informer，因为有很多资源是受多个控制器管理的，比如 Pod 同时受 Deployment 和 StatefulSet 管理。这样当多个控制器同时想查 Pod 的状态时，只需要访问一个 Informer 就行了。 但这又引来了新的问题，SharedInformer 无法同时给多个控制器提供信息，这就需要每个控制器自己排队和重试。 为了配合控制器更好地实现排队和重试，SharedInformer 搞了一个 Delta FIFO Queue（增量先进先出队列），每当资源被修改时，它的助手 Reflector 就会收到事件通知，并将对应的事件放入 Delta FIFO Queue 中。与此同时，SharedInformer 会不断从 Delta FIFO Queue 中读取事件，然后更新本地缓存的状态。 这还不行，SharedInformer 除了更新本地缓存之外，还要想办法将数据同步给各个控制器，为了解决这个问题，它又搞了个工作队列（Workqueue），一旦有资源被添加、修改或删除，就会将相应的事件加入到工作队列中。所有的控制器排队进行读取，一旦某个控制器发现这个事件与自己相关，就执行相应的操作。如果操作失败，就将该事件放回队列，等下次排到自己再试一次。如果操作成功，就将该事件从队列中删除。 现在这个工作模式得到了大家的一致好评。虽然单个 SharedInformer 的工作量增加了，但 Informer 的数量大大减少了，老大可以把省下来的资金拿出一小部分给 SharedInformer 涨工资啊，这样大家都很开心。 4. CRD全民 Kubernetes 时代到了。 随着容器及其编排技术的普及，使用 Kubernetes 的用户大量增长，用户已经不满足 Kubernetes 自带的那些资源（Pod，Node，Service）了，大家都希望能根据具体的业务创建特定的资源，并且对这些资源的状态维护还要遵循上面所说的那一套控制循环机制。 幸好最近掌门人做了一次升级，新增了一个插件叫 CRD（Custom Resource Definition），创建一个全新的资源实例，只需要经过以下两步： 创建一个 CRD 资源（没错，CRD 也是一种资源类型），其中定义” 自定义资源 “的 API 组、API 版本和资源类型。这样就会向 API Server 注册该资源类型的 API。 指定上面定义的 API 组 和 API 版本，创建自定义资源。 当然，中间还要加入一些代码让 Kubernetes 认识自定义资源的各种参数。 到这一步就基本上完成了自定义资源的创建，但 Kubernetes 并不知道该资源所对应的业务逻辑，比如你的自定义资源是宿主机，那么对应的业务逻辑就是创建一台真正的宿主机出来。那么怎样实现它的业务逻辑呢？ 5. 自定义控制器Controller Manager 见多识广，说：” 这里的每个控制器都是我的一部分，当初创造你们是因为你们都属于通用的控制器，大家都能用得上。而自定义资源需要根据具体的业务来实现，我们不可能知道每个用户的具体业务是啥，自己一拍脑袋想出来的自定义资源，用户也不一定用得上。我们可以让用户自己编写自定义控制器，你们把之前使用的控制循环和 Informer 这些编码模式总结一下，然后提供给用户，让他们按照同样的方法编写自己的控制器。“ Deployment 控制器一惊，要把自己的秘密告诉别人？那别人把自己取代了咋办？赶忙问道：” 那将来我岂不是很危险，没有存在的余地了？“ Controller Manager 赶忙解释道：” 不用担心，虽然用户可以编写自定义控制器，但无论他们玩出什么花样，只要他们的业务跑在 Kubernetes 平台上，就免不了要跑容器，最后还是会来求你们帮忙的，你要知道，控制器是可以层层递进的，他们只不过是在你外面套了一层，最后还是要回到你这里，请求你帮忙控制 Pod。“ 这下大家都不慌了，决定就把自定义控制器这件事情交给用户自己去处理，将选择权留给用户。 6. Operator用户自从获得了编写自定义控制器的权力之后，非常开心，有的用户（CoreOS）为了方便大家控制有状态应用，开发出了一种特定的控制器模型叫 Operator，并开始在社区内推广，得到了大家的一致好评。不可否认，Operator 这种模式是很聪明的，它把需要特定领域知识的应用单独写一个 Operator 控制器，将这种应用特定的操作知识编写到软件中，使其可以利用 Kubernetes 强大的抽象能力，达到正确运行和管理应用的目的。 以 ETCD Operator 为例，假如你想手动扩展一个 ETCD 集群，一般的做法是： 使用 ETCD 管理工具添加一个新成员。 为这个成员所在的节点生成对应的启动参数，并启动它。 而 ETCD Operator 将这些特定于 etcd 的操作手法编写到了它的控制循环中，你只需要通过修改自定义资源声明集群期望的成员数量，剩下的事情交给 Operator 就好了。 本以为这是一个皆大欢喜的方案，但没过多久，就有开发 Operator 的小哥来抱怨了：” 我们有很多开发的小伙伴都是不懂运维那一套的，什么高可用、容灾根本不懂啊，现在让我们将运维的操作知识编写到软件中，臣妾做不到啊。。“ 这确实是个问题，这样一来就把开发和运维的工作都塞到了开发手里，既懂开发又懂运维的可不多啊，为了照顾大家，还得继续想办法把开发和运维的工作拆分开来。 7. OAM这时候阿里和微软发力了，他们联合发布了一个开放应用模型，叫 Open Application Model （OAM）。这个模型就是为了解决上面提到的问题，将开发和运维的职责解耦，不同的角色履行不同的职责，并形成一个统一的规范，如下图所示： 这个规范告诉我们： 开发人员负责描述组件的功能，如何配置组件，以及运行需要多少资源 运维人员负责将相关组件组合成一个应用，并配置运行时参数和运维支撑能力，比如是否需要监控，是否需要弹性伸缩。 基础设施工程师负责建立和维护应用的运行时环境（如底层系统）。 其中每一个团队负责的事情都用对应的 CRD 来配置。 这样一来，开发和运维人员的职责就被区分开来了，简化了应用的组合和运维。它将应用的配置和运维特征（如自动伸缩、流量监控）进行解耦，然后通过建模构成一个整体，避免了 Operator 这种模型带来的大量冗余。 自从用上了这个模型之后，运维和开发小哥表示现在他们的关系很融洽，没事还能一起出去喝两杯。 文章转自Kubernetes控制器的进化之旅 https://fuckcloudnative.io/posts/controllers-confession/https://fuckcloudnative.io/posts/controllers-confession/","tags":["Cloud Navite","Kubernetes"],"categories":["技术加油站"]},{"title":"OpenLDAP 快速落地实践-部署配置","path":"/2020/openldap-install-config.html","content":"下载依赖本文中相关操作系统及依赖包的版本如下： centos-release-7-4.1708.el7.centos.x86_64 openldap-clients-2.4.44-5.el7.x86_64：包含客户端程序，用来访问和修改 OpenLDAP 目录 openldap-servers-2.4.44-5.el7.x86_64：包含主 LDAP 服务器 slapd 和同步服务器 slurpd 服务器、迁移脚本和相关文件 安装部署第一步，需要切换到 root 账号来安装 OpenLDAP 相关程序包，并启动服务： $ yum install -y openldap-servers openldap-clients$ cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG$ chown ldap. /var/lib/ldap/DB_CONFIG$ systemctl enable slapd$ systemctl start slapd 第二步，我们使用 slappasswd 命令来生成一个密码，并使用 LDIF（LDAP 数据交换格式）文件将其导入到 LDAP 中来配置管理员密码： $ slappasswdNew password:Re-enter new password:&#123;SSHA&#125;KS/bFZ8KTmO56khHjJvM97l7zivH1MwG$ vim chrootpw.ldif# specify the password generated above for &quot;olcRootPW&quot; sectiondn: olcDatabase=&#123;0&#125;config,cn=configchangetype: modifyadd: olcRootPWolcRootPW: &#123;SSHA&#125;KS/bFZ8KTmO56khHjJvM97l7zivH1MwG$ ldapadd -Y EXTERNAL -H ldapi:/// -f chrootpw.ldif 第三步，我们需要向 LDAP 中导入一些基本的 Schema。这些 Schema 文件位于 /etc/openldap/schema/ 目录中，定义了我们以后创建的条目可以使用哪些属性： $ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/core.ldif$ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif$ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif$ ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif 第四步，我们需要配置 LDAP 的顶级域（以 dc=leeif,dc=me 为例）及其管理域： $ slappasswdNew password:Re-enter new password:&#123;SSHA&#125;z/rsbmAjVtLlWeUB0xS5itLPI0VA1akD$ vim chdomain.ldif# replace to your own domain name for &quot;dc=***,dc=***&quot; section# specify the password generated above for &quot;olcRootPW&quot; sectiondn: olcDatabase=&#123;1&#125;monitor,cn=configchangetype: modifyreplace: olcAccessolcAccess: &#123;0&#125;to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth&quot; read by dn.base=&quot;cn=admin,dc=leeif,dc=me&quot; read by * nonedn: olcDatabase=&#123;2&#125;mdb,cn=configchangetype: modifyreplace: olcSuffixolcSuffix: dc=leeif,dc=medn: olcDatabase=&#123;2&#125;mdb,cn=configchangetype: modifyreplace: olcRootDNolcRootDN: cn=admin,dc=leeif,dc=medn: olcDatabase=&#123;2&#125;mdb,cn=configchangetype: modifyadd: olcRootPWolcRootPW: &#123;SSHA&#125;z/rsbmAjVtLlWeUB0xS5itLPI0VA1akDdn: olcDatabase=&#123;2&#125;mdb,cn=configchangetype: modifyadd: olcAccessolcAccess: &#123;0&#125;to attrs=userPassword,shadowLastChange by dn=&quot;cn=admin,dc=leeif,dc=me&quot; write by anonymous auth by self write by * noneolcAccess: &#123;1&#125;to dn.base=&quot;&quot; by * readolcAccess: &#123;2&#125;to * by dn=&quot;cn=admin,dc=leeif,dc=me&quot; write by * read$ ldapmodify -Y EXTERNAL -H ldapi:/// -f chdomain.ldif 第五步，在上述基础上，我们来创建一个叫做 leeif News Agency 的组织，并在其下创建一个 Manager 的组织角色（该角色内的用户具有管理整个 LDAP 的权限）和 People 和 Group 两个组织单元： $ vim basedomain.ldif# replace to your own domain name for &quot;dc=***,dc=***&quot; sectiondn: dc=leeif,dc=meobjectClass: topobjectClass: dcObjectobjectclass: organizationo: leeif.IOdc: leeifdn: cn=admin,dc=leeif,dc=meobjectClass: organizationalRolecn: Managerdn: ou=people,dc=leeif,dc=meobjectClass: organizationalUnitou: peopledn: ou=group,dc=leeif,dc=meobjectClass: organizationalUnitou: group$ ldapadd -x -D cn=admin,dc=leeif,dc=me -W -f basedomain.ldif 通过以上的所有步骤，我们就设置好了一个 LDAP 目录树：其中基准 dn dc=leeif,dc=me 是该树的根节点，其下有一个管理域 cn=admin,dc=leeif,dc=me 和两个组织单元 ou=people,dc=leeif,dc=me 及 ou=group,dc=leeif,dc=me。 接下来，我们来创建一个叫作 Ada Catherine 的员工并将其分配到 Secretary 组来验证上述配置是否生效。 $ slappasswdNew password:Re-enter new password:&#123;SSHA&#125;HTGqAd4p6fOOIVHm7VZYUSorWGfnrqAA$ vim ldapuser.ldif# create new# replace to your own domain name for &quot;dc=***,dc=***&quot; sectiondn: uid=ada,ou=people,dc=leeif,dc=meobjectClass: inetOrgPersonobjectClass: posixAccountobjectClass: shadowAccountuid: adacn: Ada Catherinesn: CatherineuserPassword: &#123;SSHA&#125;HTGqAd4p6fOOIVHm7VZYUSorWGfnrqAAloginShell: /bin/bashuidNumber: 1000gidNumber: 1000homeDirectory: /home/users/adadn: cn=Secretary,ou=group,dc=leeif,dc=meobjectClass: posixGroupcn: SecretarygidNumber: 1000memberUid: ada# ldapadd -x -D cn=admin,dc=leeif,dc=me -W -f ldapuser.ldifEnter LDAP Password:adding new entry &quot;uid=ada,ou=People,dc=leeif,dc=org&quot;adding new entry &quot;cn=Secretary,ou=Group,dc=leeif,dc=org&quot; 我们也可以使用 ldapsearch 命令来查看 LDAP 目录服务中的所有条目信息： $ ldapsearch -x -b &quot;dc=leeif,dc=me&quot; -H ldap://127.0.0.1# extended LDIF## LDAPv3# base &lt;dc=leeif,dc=me&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## leeif.orgdn: dc=leeif,dc=meobjectClass: topobjectClass: dcObjectobjectClass: organizationo: leeif News Agencydc: leeif... 如果要删除一个条目，可以按下面的命令操作： $ ldapdelete -x -W -D &#x27;cn=admin,dc=leeif,dc=me&#x27; &quot;uid=ada,ou=People,dc=leeif,dc=me&quot; 常用命令记录(&amp;(&amp;(objectClass=inetOrgPerson)))mkdir /etc/yum.repos.d/backupmv /etc/yum.repos.d/* /etc/yum.repos.d/backup/curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repoyum -y install openldap-servers openldap-clients# yum reinstall --downloadonly --downloaddir=./openldap/ openldap-servers openldap-clientsmv slapd.d slapd.d.baksudo systemctl stop slapd &amp;&amp; sudo rm -rf slapd.d &amp;&amp; sudo mkdir slapd.dsudo slaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.dsudo chown -R ldap:ldap slapd.d &amp;&amp; sudo systemctl start slapdsystemctl stop slapd &amp;&amp; rm -rf slapd.d &amp;&amp; mkdir slapd.dslaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.dchown -R ldap:ldap slapd.d &amp;&amp; systemctl start slapdservice slapd stop &amp;&amp; rm -rf slapd.d &amp;&amp; mkdir slapd.dslaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.dchown -R ldap:ldap slapd.d &amp;&amp; service slapd startrm -rf /var/lib/ldap &amp;&amp; mkdir /var/lib/ldapcp /usr/share/openldap-servers/slapd.ldif /etc/openldap/cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIGchown ldap. /var/lib/ldap/DB_CONFIGchown -R ldap:ldap slapd.d chown -R ldap:ldap /var/lib/ldap/*# 方案一vim /etc/openldap/slapd.ldif ##修改后的初始化ldif文件slapadd -n 0 -F slapd.d -l slapd.ldif ##生成配置数据库信息# 方案二vi /etc/openldap/slapd.confslaptest -f /etc/openldap/slapd.conf -F /etc/openldap/slapd.d# systemctl start slapd# systemctl enable slapd# systemctl status slapd slapd.conf 文件配置pidfile /var/run/openldap/slapd.pidargsfile /var/run/openldap/slapd.argsinclude /etc/openldap/schema/core.schemainclude /etc/openldap/schema/collective.schemainclude /etc/openldap/schema/corba.schemainclude /etc/openldap/schema/cosine.schemainclude /etc/openldap/schema/duaconf.schemainclude /etc/openldap/schema/dyngroup.schemainclude /etc/openldap/schema/inetorgperson.schemainclude /etc/openldap/schema/java.schemainclude /etc/openldap/schema/misc.schemainclude /etc/openldap/schema/nis.schemainclude /etc/openldap/schema/openldap.schemainclude /etc/openldap/schema/pmi.schemainclude /etc/openldap/schema/ppolicy.schemamodulepath /usr/lib64/openldapmoduleload memberof.lamoduleload back_ldap.lamoduleload back_relay.lamoduleload pcache.lamoduleload ppolicy.lamoduleload syncprov.lamoduleload rwm.laloglevel 256# before any databaseoverlay rwmrwm-rewriteEngine onrwm-rewriteContext bindDN# rwm-rewriteRule &quot;(.+,)?dc=leeif,dc=me$&quot; &quot;$1dc=auth&quot; &quot;:@&quot;rwm-rewriteRule &quot;(^uid=.+,)(.+,)?dc=leeif,dc=me$&quot; &quot;$1dc=auth&quot; &quot;:@&quot;database configaccess to * by dn.base=&quot;gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth&quot; manage by * nonedatabase monitoraccess to dn.base=&quot;dc=ldapproxy,dc=com&quot; by ssf=256 group.exact=&quot;cn=admin,dc=ldapproxy,dc=com&quot; read by * nonedatabase hdbsuffix &quot;dc=ldapproxy,dc=com&quot;rootdn &quot;cn=admin,dc=ldapproxy,dc=com&quot;rootpw &#123;SSHA&#125;passworddirectory /var/lib/ldap# Database LDAP for OpenLDAP database ldapreadonly yessuffix &quot;dc=leeif,dc=me&quot;uri ldap://127.0.0.1:389idassert-bind bindmethod=simple binddn=&quot;cn=admin,dc=leeif,dc=me&quot; credentials=&quot;zto.com&quot; mode=none flags=non-prescriptiveidassert-authzFrom &quot;dn.exact:cn=admin,dc=ldapproxy,dc=com&quot;# Database LDAP for LDAP-Authdatabase ldapreadonly yessuffix &quot;dc=auth&quot;uri ldap://127.0.0.1:10389","tags":["OpenLDAP"],"categories":["折腾不止"]},{"title":"OpenLDAP 快速落地实践-基本介绍","path":"/2020/openldap-getting-started.html","content":"场景需求 需求当公司体量较大，内部有多个系统，如果每个平台都需要维护一个用户管理体系，那么如果一个员工拥有 N 个平台权限离职及常规权限变更，对于的管理无疑也是一个挑战，也无法做到精细化权限管理。比如每次新进或离职一位同事，我们这边 OPS 运维组的小伙伴们，都要在每个系统上去添加用户，搞得小伙伴们很不爽。 简单说一下 OPENLDAP 对运维管理的价值，支撑企业技术发展比如 GIT、 ZABBIX、 YAPI、 JUMPSERVER、 OA 等大大小小系统，乃至 Windows，Linux 系统的认证登录。 通过 LDAP 技术我们可以实现多平台账号集中管理，权限灵活控制，密码强度及其有效期的约束，将用户管理与各个平台解耦，最终实现一次修改 N 处生效。 LDAP 简介LDAP（轻量级目录访问协议，Lightweight Directory Access Protocol) 是实现提供被称为目录服务的信息服务。目录服务是一种特殊的数据库系统，其专门针对读取，浏览和搜索操作进行了特定的优化。目录一般用来包含描述性的，基于属性的信息并支持精细复杂的过滤能力。目录一般不支持通用数据库针对大量更新操作操作需要的复杂的事务管理或回卷策略。而目录服务的更新则一般都非常简单。这种目录可以存储包括个人信息、web 链结、jpeg 图像等各种信息。为了访问存储在目录中的信息，就需要使用运行在 TCP&#x2F;IP 之上的访问协议 —LDAP。 LDAP 目录中的信息是是按照树型结构组织，具体信息存储在条目 (entry) 的数据结构中。条目相当于关系数据库中表的记录；条目是具有区别名 DN （Distinguished Name）的属性（Attribute），DN 是用来引用条目的，DN 相当于关系数据库表中的关键字（Primary Key）。属性由类型（Type）和一个或多个值（Values）组成，相当于关系数据库中的字段（Field）由字段名和数据类型组成，只是为了方便检索的需要，LDAP 中的 Type 可以有多个 Value，而不是关系数据库中为降低数据的冗余性要求实现的各个域必须是不相关的。LDAP 中条目的组织一般按照地理位置和组织关系进行组织，非常的直观。LDAP 把数据存放在文件中，为提高效率可以使用基于索引的文件数据库，而不是关系数据库。类型的一个例子就是 mail，其值将是一个电子邮件地址。 OpenLADP 简介LDAP 具有两个标准，分别是 X.500 和 LDAP。OpenLDAP 是基于 X.500 标准的，而且去除了 X.500 复杂的功能并且可以根据自我需求定制额外扩展功能，但与 X.500 也有不同之处，例如 OpenLDAP 支持 TCP&#x2F;IP 协议等。 OpenLDAP 可以直接运行在更简单和更通用的 TCP&#x2F;IP 或其他可靠的传输协议层上，避免了在 OSI 会话层和表示层的开销，使连接的建立和包的处理更简单、更快，对于互联网和企业网应用更理想。 OpenLDAP 目录中的信息是以树状的层次结构来存储数据（这很类同于 DNS），最顶层即根部称作 “基准 DN”，形如 “dc&#x3D;mydomain,dc&#x3D;org” 或者 “o&#x3D;mydomain.org”，前一种方式更为灵活也是 Windows AD 中使用的方式。在根目录的下面有很多的文件和目录，为了把这些大量的数据从逻辑上分开，OpenLDAP 像其它的目录服务协议一样使用 OU（Organization Unit，组织单元），可以用来表示公司内部机构，如部门等，也可以用来表示设备、人员等。同时 OU 还可以有子 OU，用来表示更为细致的分类。 OpenLDAP 中每一条记录都有一个唯一的区别于其它记录的名字 DN（Distinguished Name）, 其处在 “叶子” 位置的部分称作 RDN (用户条目的相对标识名)。如 dn:cn&#x3D;tom,ou&#x3D;animals,dc&#x3D;ilanni,dc&#x3D;com 中 cn 即为 RDN，而 RDN 在一个 OU 中必须是唯一的。 OpenLDAP 默认以 Berkeley DB 作为后端数据库，BerkeleyDB 数据库主要以散列的数据类型进行数据存储，如以键值对的方式进行存储。 BerkeleyDB 是一类特殊的面向查询进行优化、面向读取进行优化的数据库，主要用于搜索、浏览、更新查询操作，一般对于一次写入数据、多次查询和搜索有很好的效果。BerkeleyDB 不支持事务型数据库 (MySQL、MariDB、Oracle 等) 所支持的高并发的吞吐量以及复杂的事务操作。 LDAP 简称目录 简称 全称（含义） c countryName（国家） dc domainComponent（域名） o organization（组织 - 公司） ou organization unit（组织单元 - 部门） sn suer name（真实名称） cn common name（常用名称）","tags":["OpenLDAP"],"categories":["折腾不止"]},{"title":"模块设计文档编写规范","path":"/2019/module-design-doc.html","content":"模块负责人 👩‍💻 leeifme &#x2F; XXXX项目 🚀 XXXX部门 &#x2F; XXXX事业部 📧 Email &#105;&#x40;&#x6c;&#101;&#x65;&#105;&#102;&#x2e;&#x6d;&#x65; 版本历史记录(History) （可选） 设计稿版本每发生一次比较大的迭代更新，都要记录在版本历史记录里，相比一个个去翻以前的设计稿，版本历史记录可以清晰地展现设计稿的迭代历程，有哪些需求的变动，有哪些设计时没思考清楚需要修改的地方，Review 时大家给出了哪些意见和建议等。有时版本需要回滚，可以更方便地追溯，而项目结束后浏览这一部分，可以看到自己的设计在哪些方面一开始思考不足出现了各种问题，是如何被发现、改进和提升的，下一次设计的时候是否可以更早地思考到和回避掉 排期(Schedule) （可选） 和需求方确认各阶段交付的时间节点，制定完成模块设计的具体计划，每个阶段大概做哪些工作，什么时候内部 Review，什么时候和项目组 Review 等。确保设计以一个合理的节奏展开，可以以较高的质量按时交付 模块概述(Background) 这一部分的内容在开发者和 PM、业务方充分沟通需求之后完成 模块描述，要设计的产品是什么，解决什么业务需求 业务 &#x2F; 产品现状，总结需求方现在面临的主要问题 功能设计，模块开发关键点以及业务逻辑描述 需要设计什么新的功能，需要优化哪些已有的设计 提高模块哪些使用环节的体验，引导用户做出什么操作 模块详细设计 详细描述模块实现的架构分析，采用的框架、技术栈选型，以及实现算法等 使用第三方服务：采用的框架、什么存储服务、数据库、队列等等的一些服务，以及可能需要用到的算法 程序逻辑描述：有什么样的交互逻辑，处理流程是什么样的，是不是有异步处理任务又是怎样做的 数据结构定义：程序内部主要用到的数据结构、数据库表设计、索引设计 结构 &#x2F; 架构图：根据使用了什么服务、有什么样的调用流程、或者是程序里面有什么样的结构和流程需要画的图 百度脑图 Process On 这些框架、设计都需经过可行性分析，必须是可行的 接口设计文档(Interface) 主要参考 Swagger文档（如果有），这里只做一些补充说明，用来说明调用此接口需要注意的事项(没有可不写) 原型设计（可选） 原型设计之于应用开发，是为第一要素。它所起到的不仅是沟通的作用，更有体现之效。通过内容和结构展示，以及粗略布局，能够说明用户将如何与产品进行交互 。也能更直观的体现出所设计模块的基本功能和交互方式，体现开发者及UI设计师的idea，体现用户所期望看到的内容，体现内容相对优先级等 墨刀 摹客 Axure RP 测试要点（可选） 给出测试模块的主要测试要求，和逻辑操作 注明： 以上设计规范只是通用设计要求，具体视模块功能要求做具体改动","tags":["规范建议"],"categories":["设计开发"]},{"title":"搭建 Airflow 任务调度环境","path":"/2019/deploy-airflow.html","content":"前期准备关闭防火墙和 selinuxsystemctl stop firewalldsystemctl disable firewalldsetenforce 0 sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/g&#x27; /etc/selinux/config 部署 Python 3.X 依赖包安装 Python 安装会依赖一些环境，为了避免在安装过程中因为缺少依赖而产生不必要的麻烦，需要先执行以下命令，确保安装好以下依赖包： yum -y install zlib zlib-develyum -y install bzip2 bzip2-develyum -y install ncurses ncurses-develyum -y install readline readline-develyum -y install openssl openssl-develyum -y install openssl-staticyum -y install xz lzma xz-develyum -y install sqlite sqlite-develyum -y install gdbm gdbm-develyum -y install tk tk-develyum -y install libffi-devel # 只有 3.7 才会用到这个包，如果不安装这个包的话，在 make 阶段会出现如下的报错：ModuleNotFoundError: No module named &#x27;_ctypes&#x27;yum install gccyum install wget# 安装 pip，因为 CentOs 是没有 pip 的#运行这个命令添加epel扩展源 yum -y install epel-release #安装pip yum install python-pip Python 源码下载 可以前往 https://www.python.org/ftp/python/ 查看 Python 各个版本 wget https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz 知识点补充：如果不知道 configure, make, make install 三个命令作用，点这里查看 安装 Python 解压缩 tar -zxvf Python-3.7.0.tgz 进入解压后的目录，依次执行下面命令进行手动编译 ./configure prefix=/usr/local/python3 # 指定目录make &amp;&amp; make install 如果最后没提示出错，就代表正确安装了 添加软链接 # 做好原始数据的备份mv /usr/bin/python /usr/bin/python2.backup mv /usr/bin/pip /usr/bin/pip2.backup# 设置软连接ln -s /usr/local/python3/bin/python3.7 /usr/bin/pythonln -s /usr/local/python3/bin/pip3.7 /usr/bin/pip# 检测python -Vpip -V 保证系统可用 更改 yum 配置，因为其要用到 python2 才能执行，否则会导致 yum 不能正常使用（不管安装 python3 的那个版本，都必须要做的） # 把 #! /usr/bin/python 修改为 #! /usr/bin/python2 vi /usr/bin/yum vi /usr/libexec/urlgrabber-ext-down 部署 PostgreSQL 安装 PostgreSQL 仓库 $ yum install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm 安装客户端 $ yum install postgresql10 安装服务端 $ yum install postgresql10-server 加入开机启动项 $ systemctl enable postgresql-10.service 初始化数据库 $ /usr/pgsql-10/bin/postgresql-10-setup initdb 启动数据库服务 $ systemctl start postgresql-10 检查运行状态 $ systemctl status postgresql-10 设置用户密码 $ su - postgresLast login: Mon Aug 5 11:09:14 CST 2019 on pts/0# 默认用户postgres-bash-4.2$ psqlpsql (10.9)Type &quot;help&quot; for help.postgres=# \\password# 设置密码为 &#x27;******&#x27;Enter new password:Enter it again:# 保存退出postgres=# \\q 修改监听地址 vi /var/lib/pgsql/10/data/postgresql.conf listen_addresses = &#x27;*&#x27;#listen_addresses = &#x27;localhost&#x27; 修改客户端认证方式 vi /var/lib/pgsql/10/data/pg_hba.conf # replication privilege.#local replication all peer#host replication all 127.0.0.1/32 ident#host replication all ::1/128 identhost all all 0.0.0.0/0 md5 重启服务 $ systemctl restart postgresql-10 连接测试 $ psql -h 192.168.1.2 -U postgres 部署 RabbitMQ安装 Erlang RabbitMQ 是使用 Erlang 开发的，所以需要首先安装 Erlang，本文安装其最新版本 添加 repo 文件： $ vi /etc/yum.repos.d/rabbitmq_erlang.repo 文件内容： [rabbitmq_erlang]name=rabbitmq_erlangbaseurl=https://packagecloud.io/rabbitmq/erlang/el/7/$basearchrepo_gpgcheck=1gpgcheck=0enabled=1gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkeysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300[rabbitmq_erlang-source]name=rabbitmq_erlang-sourcebaseurl=https://packagecloud.io/rabbitmq/erlang/el/7/SRPMSrepo_gpgcheck=1gpgcheck=0enabled=1gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkeysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crtmetadata_expire=300 安装： $ yum -y install erlang socat 安装 RabbitMQ 下载 RPM 包： $ wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.17/rabbitmq-server-3.7.17-1.el7.noarch.rpm 导入 GPG key： $ rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc 安装 RabbitMQ： $ rpm -Uvh rabbitmq-server-3.7.17-1.el7.noarch.rpm 启动 RabbitMQ： $ systemctl start rabbitmq-server 查看 RabbitMQ 运行状态 $ systemctl status rabbitmq-server 将 RabbitMQ 加入开机自启动： $ systemctl enable rabbitmq-server RabbitMQ 配置 启用 RabbitMQ 网页管理插件 $ rabbitmq-plugins enable rabbitmq_management 创建管理员用户并授权： $ rabbitmqctl add_user admin 你的密码$ rabbitmqctl set_user_tags admin administrator$ rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 在浏览器访问 http://IP:15672 即可进入到 RabbitMQ 网页管理页面 部署 Airflow通过 pip 安装 airflow 脚手架安装之前需要设置一下临时环境变量 SLUGIFY_USES_TEXT_UNIDECODE ，不然，会导致安装失败，命令如下： export SLUGIFY_USES_TEXT_UNIDECODE=yes 安装 airflow 脚手架: sudo pip install apache-airflow===1.10.4 airflow 会被安装到 python3 下的 site-packages 目录下，完整目录为:$&#123;PYTHON_HOME&#125;/lib/python3.6/site-packages/airflow，我的 airflow 目录如下所示： [root@n71 airflow]# pwd/usr/local/python3/lib/python3.7/site-packages/airflow 添加环境变量 vi ~/.bash_profile # User specific environment and startup programsAIRFLOW_HOME=/home/airflowSITE_AIRFLOW_HOME=/usr/local/python3/lib/python3.7/site-packages/airflowPYTHON3=/usr/local/python3PATH=$PATH:$HOME/bin:$SITE_AIRFLOW_HOME/bin:$PYTHON3/binexport AIRFLOW_HOMEexport SITE_AIRFLOW_HOMEexport PATHexport C_FORCE_ROOT=true 使修改后的使环境变量生效：sudo source /etc/profile Airflow 相关操作 执行 airflow 命令做初始化操作 airflow airflow 会在刚刚的 AIRFLOW_HOME 目录下生成一些文件。当然，执行该命令时可能会报一些错误，可以不用理会！生成的文件列表如下所示： [root@n71 airflow]# lsairflow.cfg logs unittests.cfg 为 airflow 安装依赖模块 pip install &#x27;apache-airflow[postgres,celery,hive,rabbitmq]&#x27; airflow 的包依赖安装均可采用该方式进行安装，具体可参考 airflow 官方文档 遇到的坑以及解决方案 为 airflow 安装 [rabbitmq] 依赖模块报错 具体可以参看这个 repositories https://github.com/celery/librabbitmq 解决方案： git clone https://github.com/celery/librabbitmq.gitcd librabbitmqcheckout 1.6yum install install autoconf automake libtoolmake install# 在安装依赖模块pip install &#x27;apache-airflow[rabbitmq]&#x27; 启动 webserver 组件时报错 错位如下： Error: &#x27;python:airflow.www.gunicorn_config&#x27; doesn‘t exist 或者是： FileNotFoundError: [Errno 2] No such file or directory: &#x27;gunicorn&#x27;: &#x27;gunicorn&#x27; 解决方案： # 1 : 添加软连接ln -s /usr/local/python3/bin/gunicorn /usr/bin/gunicorn# 2 : 添加 python 环境变量PYTHON3=/usr/local/python3PATH=$PATH:$HOME/bin:$SITE_AIRFLOW_HOME/bin:$PYTHON3/bin airflow worker 角色不能使用 root 启动 &#x3D;&#x3D;原因：不能用根用户启动的根本原因，在于 airflow 的 worker 直接用的 celery，而 celery 源码中有参数默认不能使用 ROOT 启动，否则将报错：&#x3D;&#x3D; C_FORCE_ROOT = os.environ.get(&#x27;C_FORCE_ROOT&#x27;, False) ROOT_DISALLOWED = &quot;&quot;&quot;\\Running a worker with superuser privileges when theworker accepts messages serialized with pickle is a very bad idea! If you really want to continue then you have to set the C_FORCE_ROOTenvironment variable (but please think about this before you do). User information: uid=&#123;uid&#125; euid=&#123;euid&#125; gid=&#123;gid&#125; egid=&#123;egid&#125;&quot;&quot;&quot; ROOT_DISCOURAGED = &quot;&quot;&quot;\\You&#x27;re running the worker with superuser privileges: this isabsolutely not recommended! Please specify a different user using the --uid option. User information: uid=&#123;uid&#125; euid=&#123;euid&#125; gid=&#123;gid&#125; egid=&#123;egid&#125;&quot;&quot;&quot; 解决方案： # 设置环境变量, 强制celery worker运行采用root模式 export C_FORCE_ROOT=True airflow remote worker log hostname 问题 当 worker 节点不是跟 webserver 部署在同一台机器的时候，有时从 webserver 查看该 worker 节点日志，出现如下错误： *** Log file isn&#x27;t local.*** Fetching here: http://n73:8793/log/.../1.log*** Failed to fetch log file from worker. HTTPConnectionPool(host=&#x27;kaimanas.serveriai.lt&#x27;, port=8793): Max retries exceeded with url: /log/.../1.log (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f64da2fab38&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)) n73 (或是其他) 不是 webserver 节点所在的 hostname 解决方案： 配置 worker 节点的 /etc/hosts 的 hostname 映射，把 worker 节点的 ip 映射为本机的 hostname，如下： 192.168.50.71 n71192.168.50.72 n72192.168.50.73 n73 配置 airflow.cfg 修改 Executor 为 CeleryExecutor executor = CeleryExecutor 指定元数据库（metestore) sql_alchemy_conn = postgresql+psycopg2://postgres:postgres@192.168.50.73:5432/airflow 设置中间人（broker) broker_url = amqp://admin:datatom.com@192.168.50.73:5672/ 设定结果存储后端 backend celery_result_backend = db+postgres://postgres:postgres@192.168.50.73:5432/airflowresult_backend = db+postgres://stork:stork@192.168.50.73:14103/airflow 置 dags 初始化后为暂停状态(启动状态) dags_are_paused_at_creation = True(False) 不引用实例脚本 load_examples = False 当定义的 dag 文件过多的时候，airflow 的 scheduler 节点运行效率缓慢 [scheduler]# The scheduler can run multiple threads in parallel to schedule dags.# This defines how many threads will run.#默认是2这里改为50max_threads = 30worker_concurrency = 5worker_max_tasks_per_child = 10 修改检测新 DAG 间隔，如果 scheduler 检测 DAG 过于频繁，会导致 CPU 负载非常高。而默认 scheduler 检测时间为 0，也就是没有时间间隔 min_file_process_interval = 5 定期刷新 DAG 定义目录中的文件列表，默认300s dag_dir_list_interval = 10 Airflow 的 DAG 并行度控制 dag_concurrency：表示一个 DAG，在同一时间点最大可以运行多少个 Taskmax_active_runs_per_dag：表示一个 DAG，在同一时间点最多可以被运行几个 # 默认值都为16dag_concurrency = 16max_active_runs_per_dag = 16","tags":["Python","Airflow"],"categories":["折腾不止"]},{"title":"GFS 一致性模型","path":"/2019/gfs-consistency.html","content":"前言quote,最近，部门内部组织了学习活动，前两课就是研读著名的可扩展分布式文件系统 GFS 论文，并布置了学习作业，就是整理 GFS 中提出的一致性模型，如下文： 一致性背景分布式存储系统中，不管是文件系统还是数据库，只要数据存在多个副本，都涉及一致性问题。其中一致性包括内部一致性和副本一致性，内部一致性即单机版数据库中的数据满足一定的约束条件。副本一致性表示同一数据的多个副本的值相同。GFS 作为一种分布式文件系统，采用了多副本机制，自然也会有一致性问题 一致性模型 具体操作修改操作： 包括写操作和追加操作，写操作需要指定文件块 + offset。追加操作成功后系统会将追加成功的偏移量返回给客户端。 并发写： 如果两个客户端同时写同一个文件块的同一偏移量，那么就有个先后顺序问题，如果接近同时，系统不保证这个顺序。那么客户端再去读，就不一定能读到自己刚写的数据。 追加失败： 追加操作会保证至少成功一次。追加操作时，假设配置三副本，但是只有两个副本写成功，最后一个副本超时了（可能对应块服务器宕机，当然重启后 GFS 会用 chunk version 来标记其过期 stale 了，从而跳过该 offset。），那么追加操作会重试，并且失败数据不会删除，但是 GFS 有对齐操作，即重试成功后，三个副本中该追加数据的起始偏移量是定义的（也就是一致的），那么其中那个上次失败的副本就会有个空洞，系统会用特殊字符填充。 info,结论： 定义未定义针对的是多客户端并发写同一个偏移量的覆盖顺序问题；一致不一致针对的是多个副本相同偏移量的内容是否相同 概念解析已定义（defined）：客户端写某个偏移量后，再读，读到的一定是自己的。 未定义的但是一致的（undefined but consistent）：多个客户端并发写同一个偏移量，不确定谁会覆盖谁（这个顺序由 Primary Replica 所在 Chunkserver 来安排，后面将会讲），即写完后再读，不确定是自己写的还是其他人写的。但是保证最终一致性，即并发写完成后，最后几个副本是一致的。 不一致的（inconsistent）：即修改操作后，所有副本同一偏移量的数据并不完全相同。","tags":["分布式"],"categories":["解决方案"]},{"title":"go pprof 性能分析","path":"/2019/go-pprof-analysis.html","content":"起因线上运行的基础平台文件管理服务进程出现内存泄露的现象下图是 grafana 针对该服务的监控指标情况，可以发现服务刚起时，内存使用量为 20M 左右，经过操作后，内存会稳定在 300M 左右，不会持续上升，也不会下降，一开始找不到原因，所以尝试使用一下 golang pprof 性能分析工具分析一下程序到底哪出问题了 添加 pprof 模块现在最新版本的 go tool 分析工具已经很人性化了，pprof 采样数据主要有三种获取方式: runtime&#x2F;pprof: 手动调用runtime.StartCPUProfile或者runtime.StopCPUProfile等 API 来生成和写入采样文件，灵活性高，适用于应用程序 net&#x2F;http&#x2F;pprof: 通过 http 服务获取 Profile 采样文件，简单易用，适用于对应用程序的整体监控，通过 runtime&#x2F;pprof 实现，适用于web服务程序、服务进程 go test: 通过 go test -bench . -cpuprofile prof.cpu生成采样文件 适用对函数进行针对性测试 其实 net&#x2F;http&#x2F;pprof 中只是使用 runtime&#x2F;pprof 包来进行封装了一下，并在 http 端口上暴露出来，让我们可以在浏览器查看程序的性能分析。可以自行查看 net&#x2F;http&#x2F;pprof 中代码，只有一个文件 pprof.go。 以上获取方式就不详细演示了，毕竟着重于解决当下问题，由于所要分析的服务程序依赖于 gin web 框架 ，因此要在 gin 中集成 pprof； Example： package mainimport ( &quot;github.com/gin-contrib/pprof&quot; // step 1 &quot;github.com/gin-gonic/gin&quot;)func main() &#123; router := gin.Default() pprof.Register(router) // step 2 router.Run(&quot;:8080&quot;)&#125; 分析启动程序，通过服务端口即可访问 pprof 的数据 查看当前总览：访问 http://$HOSTIP:$PORT/debug/pprof cpu（CPU Profiling）: $HOST/debug/pprof/profile，默认进行 30s 的 CPU Profiling，得到一个分析用的 profile 文件block（Block Profiling）：$HOST/debug/pprof/block，查看导致阻塞同步的堆栈跟踪goroutine：$HOST/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪heap（Memory Profiling）: $HOST/debug/pprof/heap，查看活动对象的内存分配情况mutex（Mutex Profiling）：$HOST/debug/pprof/mutex，查看导致互斥锁的竞争持有者的堆栈跟踪threadcreate：$HOST/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪 这里，我更多的是做程序的内存分析，并通过交互式终端使用； 在 terminal 中使用 go tool pprof http://$HOSTIP:$PORT/debug/pprof/heap 可以进入 pprof 分析工具，比如输入 top 可以显示靠前的几项，go tool pprof 可以带上参数 -inuse_space (分析应用程序的常驻内存占用情况) 或者 -alloc_space (分析应用程序的内存临时分配情况) 现在 go tool 可以直接可视化结果，只需要带上 -http=:8081 参数即可，如： $ go tool pprof -http=:8081 http://$HOSTIP:$PORT/debug/pprof/heap 之后就会在浏览器弹出 http://$HOSTIP:8081/ui，里面包含程序内存分析的 dot 格式的图、火焰图、top 列表、source 列表等，如下： 优化内存消耗停滞在一个值时，比如上述问题描述，其实不用称之为内存泄漏，而是不主动 GC，需要主动释放内存； 导致这个问题的原因是由于上传文件时，采用 multipart/form-data 传输数据，r.FormFile(&quot;file&quot;) 将导致调用Request.ParseMultipartForm()，并将32 MB用作maxMemory参数的值，创建 32M 的缓冲区；由于bytes.Buffer 用于读取内容，因此读取过程将从一个小的或空的缓冲区开始，并在需要更大的时候重新分配； 有关详细信息，请参阅 multipart.Reader.ReadFrom() 的实现。 r.ParseMultipartForm(32 &lt;&lt; 20) // 32 MBfile, _, err := r.FormFile(&quot;file&quot;)// ... rest of your handler 详细描述可以参考 stackoverflow 上的回答，Multipart form uploads + memory leaks in golang? 这里优化的方案是在 request请求的 body 中只放文件数据，其余信息放到 header 中，这样就不需要使用 MultipartForm 去解析数据； file = r.Body// ... rest of your handler 可以看到传输完成后，内存占用恢复到了服务初始的状态值 参考Golang 大杀器之性能剖析 PProf Multipart form uploads + memory leaks in golang?","tags":["Go"],"categories":["设计开发"]},{"title":"Opeartor-SDK 简单上手","path":"/2019/operator-sdk-use.html","content":"前言 本篇介绍了CoreOS（已被红帽收购）的开源项目 Operator-SDK 的基本使用。该项目是 Operator Framework 的一个组件，它是一个开源工具包，以有效，自动化和可扩展的方式管理称为 Operators 的Kubernetes原生应用程序 概述Operators 可以在Kubernetes之上轻松地管理复杂有状态的应用程序。然而，由于诸如使用低级API，编写样板以及缺乏模块导致重复性工作等挑战，导致目前编写Operator可能很困难 Operator SDK是一个框架，旨在简化Operator的编写，它提供如下功能： 高级API和抽象，更直观地编写操作逻辑 用于脚手架和代码生成的工具，可以快速引导新项目 扩展以涵盖常见的操作员用例 工作流程SDK提供以下工作流程来开发新的Operator： 使用SDK命令行界面（CLI）创建新的Operator项目 通过添加自定义资源定义（CRD）定义新资源API 使用SDK API监控指定的资源 在指定的处理程序中定义Operator协调逻辑(对比期望状态与实际状态)，并使用SDK API与资源进行交互 使用SDK CLI构建并生成Operator部署manifests Operator使用SDK在用户自定义的处理程序中以高级API处理监视资源的事件，并采取措施来reconcile（对比期望状态与实际状态）应用程序的状态 快速开始安装 Operator-SDK CLI$ mkdir -p $GOPATH/src/github.com/operator-framework$ cd $GOPATH/src/github.com/operator-framework$ git clone https://github.com/operator-framework/operator-sdk$ cd operator-sdk$ git checkout master$ make dep$ make install 注：这里可知，Operator-SDK 默认采用 dep 作为包管理方式，但 dep 当前的执行效率的确不高，如果你的 project 依赖的外部包很多，那么等待的时间可能会很长。并且由于 dep 会下载依赖包，一旦下载 qiang 外的包，那么 dep 可能会 “阻塞” 在那里！因此这里可以选择自己拉包后 go install 创建 app-operator# 创建一个定义 App 用户资源的 app-operator 项目$ mkdir -p $GOPATH/src/github.com/&lt;GitHub_ID&gt;# 创建 app-operator 项目$ cd $GOPATH/src/github.com/&lt;GitHub_ID&gt;$ operator-sdk new app-operator $ cd app-operator# 为AppService用户资源添加一个新的 API$ operator-sdk add api --api-version=app.example.com/v1alpha1 --kind=AppService# Required: --kind - 是 CRD 要定義的 kind# Required: --api-version - 是CRD 想定义的 group/version。# 添加一个新的控制器来监控 AppService$ operator-sdk add controller --api-version=app.example.com/v1alpha1 --kind=AppService# 构建并推送 app-operator 镜像到一个公开的 registry# 这里 build 镜像，使用的基础镜像，由于不可描述的原因，非常耗时# 可替换为 ： FROM docker.io/ericnie2017/helm-operator:latest$ operator-sdk build app-operator:v0.1.0$ docker push # 更新 operator manifest 来使用新构建的镜像$ sed -i &#x27;s|REPLACE_IMAGE|app-operator:v0.1.0|g&#x27; deploy/operator.yaml 注：这里采用 operator-sdk new 创建 app-operator 时，会自动生成 Gopkg.toml 并使用 dep 下载依赖包，最好挂代理，不然非常耗时，也可以直接跳过，自己拉包编译 创建 app-operator for Helm# 其他步骤都一样# 只是再创建 app-operator 时，增加 --type=helm，并且再创建 helm 类型的 operator 时，可以直接 add api 和 kind$ operator-sdk new &lt;project-name&gt; --type=helm --kind=&lt;kind&gt; --api-version=&lt;group/version&gt; # 例如$ operator-sdk new app-operator api --api-version=app.example.com/v1alpha1 --kind=AppService --type=helm 部署 app-operator上述两种创建方式，都会自动生成 /deploy 文件夹，其中包含一组可以 deploy 到 K8s cluser 上的 resource files； deploy&#x2F;service_account.yaml: 建立一个该自定义 operator 名称的 ServiceAccount deploy&#x2F;role.yaml: 建立一个 role 定义它能存取 K8s cluster 的规则 deploy&#x2F;role_binding.yaml: 把上面的 ServiceAccount 和 Role 绑定起来，使该 ServiceAccount 拥有这个 Role 定义的存取 rule deploy&#x2F;operator.yaml: 是 deploy operator 到 K8s cluster 上的 deployment，使用的 ServiceAccount 是我们 deploy/service_account.yaml 定义的名称 deploy&#x2F;crds&#x2F;GROUP_VERSION_CRDNAME_crd.yaml: 就是我們自己定义 resource type，More detail: Extend the Kubernetes API with CustomResourceDefinitions deploy&#x2F;crds&#x2F;GROUP_VERSION_CRDNAME_cr.yaml: 是我们要 deploy 自定义的 resource，CR 代表 Custom Resource ，More detail: Create custom objects ，该文件中的 spec 就是完全复制 helm-charts 下的 values.yaml，所以原本用 helm 怎么定义 values.yaml 中的值，该文件中就怎么写 # 建立Service Account$ kubectl create -f deploy/service_account.yaml# 建立RBAC$ kubectl create -f deploy/role.yaml$ kubectl create -f deploy/role_binding.yaml# 建立CRD$ kubectl create -f deploy/crds/app_v1alpha1_appservice_crd.yaml# 部署app-operator# 这里部署时，由于自动生成的 operator.yaml 文件中的 拉取镜像，默认为 imagePullPolicy: Always ；到镜像仓库拉取# 我一般镜像打包到本地，所以替换为 imagePullPolicy: IfNotPresent ；本地有，就不到镜像仓库拉取$ kubectl create -f deploy/operator.yaml# 创建一个AppService用户资源# 默认控制器将监视AppService对象并为每一个CR创建一个pod$ kubectl create -f deploy/crds/app_v1alpha1_appservice_cr.yaml# 验证pod是否创建$ kubectl get pod -l app=example-appserviceNAME READY STATUS RESTARTS AGEexample-appservice-pod 1/1 Running 0 1m 最后这样通过 operator-framework/operator-sdk 要完成自己的 CRD 和 operator 真的很快速和方便，可以预见，如果是开发或运维人员，在了解需求后，可以不用写很多的 operator 复杂和繁琐的重复程序，就可以快速开发和部署 operator ，且后续一样可以很方便的使用 K8s 的 API 资源；不过，是否要使用 operator-framework/operator-sdk ，一切还是需要自行的评估和结合当前应用服务的体量来看是否适合使用，小心服用。","tags":["Cloud Navite","Kubernetes"],"categories":["技术加油站"]},{"title":"Select -- 无阻塞读写 channel","path":"/2019/go-channel-select.html","content":"通道阻塞在之前的 Go 的并发模型 可以了解到，FAN 流水模型可以多个 Goroutine 读一个 Channel 中的数据(FAN-OUT)，或者多个 Chanel 将数据发送到一个 Goroutine 中接收(FAN-IN)，但是无论是无缓冲通道，还是有缓冲通道，都存在阻塞的情况 无缓冲通道 特点：发送的数据需要被读取后，发送才会完成 阻塞场景： 通道中无数据，但执行都通道 通道中无数据，向通道中写数据，但无其他协程读取该通道中的数据 代码示例： // 场景 1func ReadNoDataFromNoBufCh()&#123; noBufCh := make(chan int) // 通道中无数据 &lt;- noBufCh fmt.Println(&quot;read from no buffer channel success&quot;) // Output: // fatal error: all goroutines are asleep - deadlock!&#125;// 场景 2func WriteNoBufCh()&#123; ch := make(chan int) ch &lt;- 1 fmt.Println(&quot;write success no block&quot;) // Output: // fatal error: all goroutines are asleep - deadlock!&#125; 有缓冲通道 特点：有缓存时可以向通道中写入数据后直接返回，缓存中有数据时可以从通道中读到数据直接返回，这时有缓存通道是不会阻塞的 阻塞场景： 通道的缓存无数据，但执行读通道 通道的缓存已经占满，向通道写数据，但无协程读 代码示例： // 场景 1func ReadNoDataFromBufCh()&#123; bufCh := make(chan int, 1) // 通道中无数据 &lt;- bufCh fmt.Println(&quot;read from no buffer channel success&quot;) // Output: // fatal error: all goroutines are asleep - deadlock!&#125;// 场景 2func WriteBufChButFull()&#123; ch := make(chan int, 1) // 写数据，占满缓冲 ch &lt;- 1 // 无协程读取缓冲中的数据，继续写，阻塞 ch &lt;- 2 fmt.Println(&quot;write success no block&quot;) // Output: // fatal error: all goroutines are asleep - deadlock!&#125; Select 功能Select 由关键字 select 和 case 组成，default 不是必须的，如果没其他事可做，可以省略 default，在多个通道上进行读或写操作，让函数可以处理多个事情，但 1 次只处理 1 个，有以下特性： 每次执行 select，都会只执行其中 1 个 case 或者执行 default 语句 当没有 case 或者 default 可以执行时，select 则阻塞，等待直到有 1 个 case 可以执行 当有多个 case 可以执行时，则随机选择 1 个 case 执行 case 后面跟的必须是读或者写通道的操作，否则编译出错","tags":["Go"],"categories":["设计开发"]},{"title":"Kuberntes 创建 LoadBalancer 类型服务","path":"/2019/k8s-deploy-metallb-LoadBalancer.html","content":"前言 我们知道，Service 机制，以及 Kubernetes 里的 DNS 插件，都是在帮助我们解决同样一个问题，即：如何找到某一个容器；而 Service 是由 kube-proxy 组件，加上 iptables 来共同实现的；所谓 Service 的访问入口，其实就是每台宿主机上由 kube-proxy 生成的 iptables 规则，以及 kube-dns 生成的 DNS 记录。而一旦离开了这个集群，这些信息对用户来说，也就自然没有作用了 在使用 Kubernetes 的 Service 时，一个必须要面对和解决的问题就是：如何从外部（Kubernetes 集群之外），访问到 Kubernetes 里创建的 Service？ 从外界连通 Service三种方式 NodePort ExternalIP LoadBalance 这里 NodePort 和 externalIPs 是 K8S 集群本身就支持的特性，这两个方案让很多私有云用户成为了 K8S 世界中的二等公民，而 NodePort 也是我们最常用的； 而 kubernetes 没有为裸机群集提供网络负载均衡器（类型为 LoadBalancer 的服务）的实现，如果你的 K8S 集群没有在公有云的 IaaS 平台（GCP，AWS，Azure …）上运行，则 LoadBalancers 将在创建时无限期地保持 “挂起” 状态，也就是说只有公有云厂商自家的 kubernetes 支持 LoadBalancer，对 LoadBalancer 类型的服务的支持应该是众多表面差异中最醒目的一个了 纯软件解决方案: MetalLB 该项目发布于 2017 年底，当前处于 Beta 阶段，旨在解决上述中的不平衡，通过提供与标准网络设备集成的网络 LB 实现来纠正这种不平衡，以便裸机集群上的外部服务也 “尽可能” 地工作；即 MetalLB 能够帮助你在 kubernetes 中创建 LoadBalancer 类型的 kubernetes 服务 项目地址：https://github.com/google/metallb 版本说明：https://metallb.universe.tf/release-notes/ Metallb 会在 Kubernetes 内运行，监控服务对象的变化，一旦察觉有新的 LoadBalancer 服务运行，并且没有可申请的负载均衡器之后，就会完成两部分的工作： 地址分配 用户需要在配置中提供一个地址池，Metallb 将会在其中选取地址分配给服务。 地址广播 根据不同配置，Metallb 会以二层（ARP&#x2F;NDP）或者 BGP 的方式进行地址的广播 安装部署演示部署 Metallb 负载均衡器Metallb 支持 Helm 和 YAML 两种安装方法(这里推荐第二种) Helm $ helm install --name metallb stable/metallb YAML $ kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yaml 很简单，Metallb 就会开始安装，会生成自己的命名空间以及 RBAC 配置 [root@lee ~]# kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/metallb.yamlnamespace/metallb-system createdserviceaccount/controller createdserviceaccount/speaker createdclusterrole.rbac.authorization.k8s.io/metallb-system:controller createdclusterrole.rbac.authorization.k8s.io/metallb-system:speaker createdrole.rbac.authorization.k8s.io/config-watcher createdclusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller createdclusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker createdrolebinding.rbac.authorization.k8s.io/config-watcher createddaemonset.apps/speaker createddeployment.apps/controller created[root@lee ~]# kubectl get pods -n metallb-system -owideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODEcontroller-765899887-bdwdk 1/1 Running 0 82s 10.0.0.22 lee &lt;none&gt;speaker-qldl6 1/1 Running 0 82s 192.168.50.124 lee &lt;none&gt; 目前还没有宣布任何内容，因为我们没有提供 ConfigMap，也没有提供负载均衡地址的服务；接下来我们要生成一个 ConfigMap文件，为 Metallb 设置网址范围以及协议相关的选择和配置 提供 IP pool通过之前提到的原理图可知，需要创建一个 ConfigMap 文件，以提供 IP 池； $ wget https://raw.githubusercontent.com/google/metallb/v0.7.3/manifests/example-layer2-config.yaml 修改 ip 地址池和集群节点网段相同，且必须为一个 IP 区间 apiVersion: v1kind: ConfigMapmetadata: namespace: metallb-system name: configdata: config: | address-pools: - name: my-ip-space protocol: layer2 addresses: # 与集群节点网段相同 - 192.168.50.211-192.168.50.220 **IP 地址为 无占用 ** [root@lee ~]# ping 192.168.50.211PING 192.168.50.211 (192.168.50.211) 56(84) bytes of data.From 192.168.50.124 icmp_seq=1 Destination Host UnreachableFrom 192.168.50.124 icmp_seq=2 Destination Host UnreachableFrom 192.168.50.124 icmp_seq=3 Destination Host UnreachableFrom 192.168.50.124 icmp_seq=4 Destination Host Unreachable^C--- 192.168.50.211 ping statistics ---5 packets transmitted, 0 received, +4 errors, 100% packet loss, time 4001ms 部署 example-layer2-config.yaml 文件 $ kubectl apply -f example-layer2-config.yaml 部署应用服务测试$ wget https://raw.githubusercontent.com/google/metallb/master/manifests/tutorial-2.yaml$ kubectl apply -f tutorial-2.yaml 查看 yaml 文件配置，包含了一个 deployment 和一个 LoadBalancer 类型的 service，默认即可； 查看 service 分配的 EXTERNAL-IP [root@lee ~]# kubectl get svc -owideNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORnginx LoadBalancer 10.0.228.36 192.168.50.211 80:31796/TCP 65s app=nginx ping 该 EXTERNAL-IP 地址，发现该地址可以访问了 [root@lee ~]# ping 192.168.50.211PING 192.168.50.211 (192.168.50.211) 56(84) bytes of data.64 bytes from 192.168.50.211: icmp_seq=1 ttl=64 time=0.050 ms64 bytes from 192.168.50.211: icmp_seq=2 ttl=64 time=0.082 ms64 bytes from 192.168.50.211: icmp_seq=3 ttl=64 time=0.068 ms 集群内访问该 EXTERNAL-IP 地址 [root@lee ~]# curl 192.168.50.211&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;...............&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 从集群外访问该 IP 地址 Administrator at 16:47:09 / $ curl 192.168.50.211 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 612 100 612 0 0 597k 0 --:--:-- --:--:-- --:--:-- 597k&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;................&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 另外使用 Node IP + NodePort 也可以访问 Administrator at 16:47:09 / $ curl 192.168.50.124:31796 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed100 612 100 612 0 0 597k 0 --:--:-- --:--:-- --:--:-- 597k&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;................&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;","tags":["Cloud Navite","Kubernetes"],"categories":["解决方案"]},{"title":"Go 并发模型","path":"/2019/go-concurrent-model.html","content":"前言 Go 语言是为并发而生的语言，Go 语言是为数不多的在语言层面实现并发的语言；也正是 Go 语言的并发特性，吸引了全球无数的开发者 并发 (concurrency) 和并行(parallellism)在了解 Go 的并发原理之前，先了解什么是并发什么是并行； 并发 ( concurrency ) 两个或两个以上的任务在一段时间内被执行。我们不必 care 这些任务在某一个时间点是否是同时执行，可能同时执行，也可能不是，我们只关心在一段时间内，哪怕是很短的时间（一秒或者两秒）是否执行解决了两个或两个以上任务 并行 ( parallellism ) 两个或两个以上的任务在同一时刻被同时执行 并发说的是逻辑上的概念，而并行，强调的是物理运行状态；并发 “包含” 并行；( 详情请见：Rob Pike 的 PPT) CSP 并发模型Go 实现了两种并发形式。第一种是大家普遍认知的：多线程共享内存。其实就是 Java 或者 C++ 等语言中的多线程开发。另外一种是 Go 语言特有的，也是 Go 语言推荐的：CSP（communicating sequential processes）并发模型 请记住下面这句话： Do not communicate by sharing memory; instead, share memory by communicating.“不要以共享内存的方式来通信，相反，要通过通信来共享内存” 普通的线程并发模型，就是像 Java、C++、或者 Python，他们线程间通信都是通过共享内存的方式来进行的。非常典型的方式就是，在访问共享数据（例如数组、Map、或者某个结构体或对象）的时候，通过锁来访问，因此，在很多时候，衍生出一种方便操作的数据结构，叫做 “线程安全的数据结构” Go 的 CSP 并发模型，是通过goroutine和channel来实现的。 goroutine: 是 Go 语言中并发的执行单位，有点抽象，其实就是和传统概念上的线程 类似，但它比线程更为轻量，称之为协程 channel： 是 Go 语言中各个并发结构体 (goroutine) 之前的通信机制。 通俗的讲，就是各个goroutine之间通信的” 管道 “，有点类似于 Linux 中的管道 创建一个 goroutine 很简单，只要使用 go 关键字就可以了，如下； go func() 通信机制 channel 也很方便，传数据用 channel &lt;- data ，取数据用 &lt;-channel 在通信过程中，传数据 channel &lt;- data 和取数据 &lt;-channel 必然会成对出现，因为这边传，那边取，两个goroutine之间才会实现通信，而且不管传还是取，必阻塞，直到另外的goroutine传或者取为止 这便是 Golang CSP 并发模型最基本的形式，本问内容不详细阐述并发原理 并发模型的运用流水线模型 Golang 并发核心思路是关注数据流动。数据流动的过程交给 channel，数据处理的每个环节都交给 goroutine，把这些流程画起来，有始有终形成一条线，那就能构成流水线模型 流水线并不是什么新奇的概念，它能极大的提高生产效率，在当代社会流水线非常普遍，我们用的几乎任何产品（手机、电脑、汽车、水杯），都是从流水线上生产出来的；在 Golang 中，流水线由多个阶段组成，每个阶段之间通过 channel 连接，每个节点可以由多个同时运行的 goroutine 组成 如上图，从最简单的流水线入手，由 3 个阶段组成，分别是 A、B、C；第一个阶段的协程是生产者，它们只生产数据，最后一个阶段的协程是消费者，A 是生成者，C 是消费者，而 B 只是中间过程的处理者；A 和 B 之间是通道aCh，B 和 C 之间是通道bCh，A 生成数据传递给 B，B 生成数据传递给 C 举个例子，设计一个程序：计算一个整数切片中元素的平方值并把它打印出来。非并发的方式是使用 for 遍历整个切片，然后计算平方，打印结果 我们使用流水线模型实现这个简单的功能，从流水线的角度，可以分为 3 个阶段： 遍历切片，这是生产者。 计算平方值。 打印结果，这是消费者。 具体代码，参考 simple.go producer()负责生产数据，它会把数据写入通道，并把它写数据的通道返回 square()负责从某个通道读数字，然后计算平方，将结果写入通道，并把它的输出通道返回 main()负责启动 producer 和 square，并且还是消费者，读取 suqre 的结果，并打印出来 流水线的特点 每个阶段把数据通过 channel 传递给下一个阶段 每个阶段要创建 1 个 goroutine 和 1 个通道，这个 goroutine 向里面写数据，函数要返回这个通道 有 1 个函数来组织流水线，我们例子中是 main 函数 流水线 FAN 模式 流水线模型进阶，FAN-IN 和 FAN-OUT 模式，FAN 模式可以让我们的流水线模型更好的利用 Golang 并发，提高软件性能 这里还是以生产汽车的流水线为例，汽车生产线上有个阶段是给小汽车装 4 个轮子，可以把这个阶段任务交给 4 个人同时去做，这 4 个人把轮子都装完后，再把汽车移动到生产线下一个阶段；这个过程中，就有任务的分发，和任务结果的收集；其中任务分发是 FAN-OUT，任务收集是 FAN-IN FAN-OUT 模式：多个 goroutine 从同一个通道读取数据，直到该通道关闭；OUT 是一种张开的模式，所以又被称为扇出，可以用来分发任务 FAN-IN 模式：1 个 goroutine 从多个通道读取数据，直到这些通道关闭；IN 是一种收敛的模式，所以又被称为扇入，用来收集处理的结果 如下图所示， 依然延用上面的案例需求，计算一个整数切片中元素的平方值并把它打印出来，这次我们修改一下，添加 merge() 方法，具体代码参考 fan.go producer()保持不变，负责生产数据 squre()也不变，负责计算平方值 修改main()，启动 3 个 square，这 3 个 squre 从 producer 生成的通道读数据，这是 FAN-OUT 增加merge()，入参是 3 个 square 各自写数据的通道，给这 3 个通道分别启动 1 个协程，把数据写入到自己创建的通道，并返回该通道，这是 FAN-IN","tags":["Go"],"categories":["设计开发"]},{"title":"简化 Kubernetes 应用部署工具 -- Helm","path":"/2018/k8s-deploy-tool-helm.html","content":"先区分下概念 Docker: 镜像是把一个单纯的 App 和它的安装环境整合在一起。 Kubertnetes: 管理 Docker 容器的生成和毁灭，保证 Docker 容器对应 App 的高可用（监控、自动创建）和易维护（部署和对外暴露、动态扩容、启动停止删除等）。 Helm: 是为了方便配置和部署、升级和回滚应用，尤其是多个 Service 组合创建的一个大型应用，比如网站 为什么要用？ 首先在原来项目中都是基于 yaml 文件来进行部署发布的，而目前项目大部分微服务化或者模块化，会分成很多个组件来部署，每个组件可能对应一个 deployment.yaml, 一个 service.yaml, 一个 Ingress.yaml 还可能存在各种依赖关系，这样一个项目如果有 5 个组件，很可能就有 15 个不同的 yaml 文件，这些 yaml 分散存放，如果某天进行项目恢复的话，很难知道部署顺序，依赖关系等，而所有这些包括 基于 yaml 配置的集中存放 基于项目的打包 组件间的依赖 都可以通过 helm 来进行解决 Helm 基本概念 Helm 可以理解为 Kubernetes 的包管理工具，可以方便地发现、共享和使用为 Kubernetes 构建的应用，它包含几个基本概念 Chart：一个 Helm 包，其中包含了运行一个应用所需要的镜像、依赖和资源定义等，还可能包含 Kubernetes 集群中的服务定义 Release: 在 Kubernetes 集群上运行的 Chart 的一个实例。在同一个集群上，一个 Chart 可以安装很多次每次安装都会创建一个新的 release。例如一个 MySQL Chart，如果想在服务器上运行两个数据库，就可以把这个 Chart 安装两次。每次安装都会生成自己的 Release，会有自己的 Release 名称 Repository：用于发布和存储 Chart 的仓库 要点 Helm 是一个 Chart 管理器: GitHub - kubernetes&#x2F;helm: The Kubernetes Package Manager Charts 是一组配置好的 Kubernetes 资源（定义）组合 Release 是一组已经部署到 Kubernetes 上的资源集合 Chart 的基本结构.├── Chart.yaml├── README.md├── templates│ ├── NOTES.txt│ ├── _helpers.tpl│ ├── deployment.yaml│ ├── pvc.yaml│ ├── secrets.yaml│ └── svc.yaml└── values.yaml 用途 创建可配置的 Release 升级、删除、查看由 Helm 创建的 Release 组成 Helm Client 客户端 制作、拉取、查找和验证 Chart 安装服务端 Tiller 指示服务端 Tiller 做事，比如根据 chart 创建一个 Release helm 服务端 tiller安装在 Kubernetes 集群内的一个应用， 用来执行客户端发来的命令，管理 Release Helm的安装Helm Client 安装下载 helm 的相关版本: https://github.com/kubernetes/helm/releases 安装过程如下： 下载 Helm 解包：tar -zxvf helm-v2.11.0-linux-amd64.tgz helm 二进制文件移到 &#x2F; usr&#x2F;local&#x2F;bin 目录 Helm Tiller 安装 因为 Kubernetes APIServer 开启了 RBAC 访问控制，所以需要创建 tiller 使用的 service account: tiller 并分配合适的角色给它。这里简单起见直接分配 cluster-admin 这个集群内置的 ClusterRole 给它。创建 rbac-config.yaml 文件： # rbac-config.yamlapiVersion: v1kind: ServiceAccountmetadata: name: tiller namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: tillerroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects: - kind: ServiceAccount name: tiller namespace: kube-system 接下来使用 helm 部署 tiller: helm init --service-account tiller --skip-refresh 如果直接执行部署语句，要链接 https://kubernetes-charts.storage.googleapis.com 去下载镜像；在国内这个地址不能直接访问，所以需要下载其他镜像；docker pull fengzos&#x2F;tiller:v2.11.0 这个镜像是直接从 gcr.io&#x2F;kubernetes-helm&#x2F;tiller:v2.11.0 继承过来的，可以直接使用。 docker pull fengzos/tillerhelm init --service-account tiller --upgrade -i fengzos/tiller:latest --skip-refresh 帮助文档 helm help 查看 helm 支持的命令 helm somecommand -h 查看某个命令的使用方法 helm version 查看客户端和服务端的版本，如果只显示了客户端版本，说明没有连上服务端。 它会自动去 K8s 上 kube-system 命名空间下查找是否有 Tiller 的 Pod 在运行，除非你通过 --tiller-namespace标签 or TILLER_NAMESPACE环境变量指定 Helm的使用使用 Chart helm search 查找可用的 Charts helm inspect 查看指定 Chart 的基本信息 helm install 根据指定的 Chart 部署一个 Release 到 K8s helm create 创建自己的 Chart helm package 打包 Chart，一般是一个压缩包文件 管理 Release helm list 列出已经部署的 Release helm delete [RELEASE] 删除一个 Release. 并没有物理删除， 出于审计需要，历史可查 helm delete --purge [RELEASE] 移除所有与指定 Release 相关的 K8s资源和所有这个 Release 的记录 helm status [RELEASE] 查看指定的 Release 信息，即使使用helm delete命令删除的 Release. helm upgrade 升级某个 Release helm rollback [RELEASE] [REVISION] 回滚 Release 到指定发布序列 helm get values [RELEASE] 查看 Release 的配置文件值 管理 Chart Repository helm repo list helm repo add [RepoName] [RepoUrl] helm repo update","tags":["Cloud Navite","Kubernetes"],"categories":["技术加油站"]},{"title":"vscode + sftp 开发环境同步差异文件","path":"/2018/sftp-sync-project.html","content":"前言radiation,解决需求： 本地是 win10 系统，代码需要在 linux 下跑，又不想装虚拟机或双系统； 所以，项目用到连接远程测试服务器进行开发联调，需要安装 SFTP&#x2F;FTP 的扩展插件才能同步代码； 还有其他实现方法，如，Git 工作流、winscp、rzlz 等，但大都不太灵活，甚至麻烦 CentOS 7 配置使用 SFTP 服务器何为 SFTP？SFTP，即 SSH 文件传输协议（ SSH File Transfer Protocol ），或者说是安全文件传输协议（ Secure File Transfer Protocol ）。SFTP 是一个独立的 SSH 封装协议包，通过安全连接以相似的方式工作。它的优势在于可以利用安全的连接传输文件，还能浏览本地和远程系统上的文件系统。 在很多情况下，SFTP 都比 FTP 更可取，因为它具有最基本的安全特性和能利用 SSH 连接的能力，FTP 是一种不安全的协议，只能在有限的情况下或在您信任的网络上使用。 先决条件： 服务器 OpenSSH-Server 版本最低 4.8p1，因为配置权限需要版本添加的新配置项 ChrootDirectory 来完成。 如何查看 OpenSSH 版本，命令如下： $ ssh -VOpenSSH_7.4p1, OpenSSL 1.0.2k-fips 26 Jan 2017 创建用户信息添加用户组： $ groupadd sftp 添加用户： $ useradd -g sftp -s /sbin/nologin -M leeifme 参数注解： -g # 加入用户组-s # 指定用户登入后所使用的shell/sbin/nologin # 用户不允许登录-M # 不要自动建立用户的登入目录 设置用户密码： $ passwd leeifme 创建用户目录并设置权限创建 sftp 主目录： $ mkdir /home/danaos 设置 sftp 主目录权限： $ chown root:sftp /home/danaos 文件夹所有者必须是 root，用户组可以不是 root $ chmod 755 /home/danaos 权限不能超过 755 但不包括 755，否则会导致登录报错 创建上传目录并设置权限在/home/danaos/主目录下创建archer项目文件夹，并设置所有者是：leeifme，用户组隶属：sftp，这样新增的帐号才能有上传编辑的权限。 $ mkdir -p /home/danaos/archer$ chown leeifme:sftp /home/danaos/archer 修改 sshd_config 配置文件$ vim /etc/ssh/sshd_config 将此行注释掉，例如： #Subsystem sftp /usr/libexec/openssh/sftp-server 在此行下面添加如下内容： Subsystem sftp internal-sftp # 指定使用sftp服务使用系统自带的internal-sftpMatch Group sftp # 匹配sftp组的用户,若要匹配多个组,可用逗号分开ChrootDirectory /home/danaos # 限制用户的根目录ForceCommand internal-sftp # 只能用于sftp登录AllowTcpForwarding no # 禁止用户使用端口转发X11Forwarding no # 禁止用户使用端口转发 重启 SSH 服务$ systemctl restart sshd 测试是否能够登录、上传、下载等操作在10.28.204.61服务器执行以下命令登录： $ sftp leeifme@192.168.50.124leeifme@192.168.50.124&#x27;s password:Connected to leeifme@192.168.50.124.sftp&gt; lsarchersftp&gt; cd archer/sftp&gt; 上传 sftp&gt; put test.goUploading test.go to /archer/test.gotest.go 100% 3824 626.2KB/s 00:00sftp&gt; 下载 sftp&gt; get test.goFetching /archer/test.go to test.go/archer/oplog.go 100% 3824 475.1KB/s 00:00sftp&gt; 删除 sftp&gt; rm test.goRemoving test.go 更多命令请参阅 sftp&gt; help vscode 配置 sftp下载 sftp 插件 在 vscode 中快捷键 ctrl+shift+P 打开指令窗口，输入extension:install，回车，左侧即打开扩展安装的界面 在搜索框中输入sftp，第一个就是需要安装的，点安装(可以参考下载数，选择适合自己的插件，功能大都大同小异) 在 vscode 的工程中配置 sftp.json然后快捷键 ctrl+shift+P 打开指令窗口，输入sftp:config，回车，就会在当前工作工程的.vscode文件夹下生成一个sftp.json文件，不知道哪天似乎是插件更新了，默认的文件非常空，我们只能手动配置文件的参数了。配置好host, port, username, privateKeyPath, remotePath, ignore这参数即可： host：工作站的 IP 地址 port：ssh 的端口 username：工作站自己的用户名 privateKeyPath：存放在本地的已配置好的用于登录工作站的密钥文件。和下面的使用密码二选一（可以是 openssh 格式的，也可以是 ppk 格式的） password：工作站自己的用户密码。使用密钥和使用密码选用一种即可；使用密码的话工作站不用配置 ssh，但使用密钥的话工作站上需要配置好 ssh，password 就可以填 null protocol：协议类型，默认选&quot;sftp&quot; remotePath：工作站上与本地工程同步的文件夹路径，需要和本地工程文件根目录同名，且在使用 sftp 上传文件之前要手动在工作站上使用mkdir生成这个根目录，根目录下的其他子目录会自动对应生成 ignore：指定在使用sftp: sync to remote的时候忽略的文件及文件夹，注意每一行后面有逗号，最后一行没有逗号 debug： 默认是 false，如果设置为 true，可以看到通过菜单的 查看 -&gt; 输出 打开输出界面，看到打印，怀疑自己连接有问题的可以打开看看 uploadOnSave: 默认是 false，建议设置成 true，这样每次修改后 ctrl+s 保存后会自动同步。否则就需要手动同步 举个栗子：（记住不能有任何注释内容） &#123; &quot;protocol&quot;: &quot;sftp&quot;, &quot;host&quot;: &quot;192.168.50.124&quot;, &quot;port&quot;: 22, &quot;username&quot;: &quot;leeifme&quot;, &quot;password&quot;: &quot;XXXXXXXXXX&quot;, &quot;remotePath&quot;: &quot;archer/&quot;, &quot;watcher&quot;: &#123; &quot;files&quot;: &quot;**/&quot;, &quot;autoUpload&quot;: true, &quot;autoDelete&quot;: true &#125;, &quot;ignore&quot;: [ &quot;**/.git/**&quot; ]&#125;","tags":["VSCode","Linux"],"categories":["折腾不止"]},{"title":"暴力学习 k8s - 集群搭建","path":"/2018/k8s-cluster-deploy.html","content":"前言 其实，搭建一个 Kubernetes（K8S）集群不是一件容易的事情，主要困难有两个： 那一道厚厚的墙 对 K8S 的知识不熟悉 只要能解决上面两个问题，搭建的过程实际上就没有那么复杂了。 本系列是我在搭建过程中踩的无数坑 、以及查阅众多相关问题解决的文章的一些记录和总结。 集群规划网络配置 节点网络： 192.168.31.0&#x2F;24 service 网络： 10.96.0.0&#x2F;12 pod 网络： 10.244.0.0&#x2F;16 kubeadm 部署基本情况 kubeadm 项目链接地址 master、node： 安装 kubelet、 kubeadm、 docker master： kubeadm init node： kubeadm join apiserver、scheduler、Controller-manager、etcd 在 master 上以 Pod 运行 kubeproxy 以 Pod 方式运行在每一个 node 节点上。 以上 pod 均为静态 Pod 每一个节点都需要运行 flannel（也是以 Pod 方式运行），以提供 Pod 网络 kubeadm 的介绍 安装步骤 master，node 需要安装 kubelet， kubeadm， docker master 节点上运行 kubeadm init node 节点上运行 kubeadm join 加入集群 准备环境我的环境[root@master yum.repos.d]# cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) [root@master yum.repos.d]# uname -aLinux master 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 节点解析通过 /etc/hosts 文件解析 192.168.31.81 master.test.com master192.168.31.82 node01.test.com node01192.168.31.83 node02.test.com node02 集群通过时间服务器做时钟同步，我没做 节点互信可以按照此文档配置节点互信，也没有做 选择版本使用 kubernetes v1.11.2 开始部署确保 iptables firewalld 等未启动, 且不开机自启动，可参考我之前的 CentOS 安装 配置 yum 仓库使用 aliyun 源，链接 docker 源使用如下命令获取cd /etc/yum.repos.dwget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo kubernetes 源[root@master yum.repos.d]# cat kubernetes.repo [kubernetes]name=Kubernetes Repobaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgenabled=1 查看源是否生效# yum clean all# yum repolist**********Determining fastest mirrorskubernetes 243/243repo id repo name statusbase/7/x86_64 CentOS-7 - Base - 163.com 9,911docker-ce-stable/x86_64 Docker CE Stable - x86_64 16extras/7/x86_64 CentOS-7 - Extras - 163.com 370kubernetes Kubernetes Repo 243updates/7/x86_64 CentOS-7 - Updates - 163.com 1,054repolist: 11,594 安装软件三台机器都需要安装 使用 yum install docker-ce kubelet kubeadm kubectl 安装 安装的软件包如下： Installing : kubectl-1.11.2-0.x86_64 1/7 Installing : cri-tools-1.11.0-0.x86_64 2/7 Installing : socat-1.7.3.2-2.el7.x86_64 3/7 Installing : kubernetes-cni-0.6.0-0.x86_64 4/7 Installing : kubelet-1.11.2-0.x86_64 5/7 Installing : kubeadm-1.11.2-0.x86_64 6/7 Installing : docker-ce-18.06.0.ce-3.el7.x86_64 7/7 启动 docker 服务等由于国内网络原因，kubernetes 的镜像托管在 google 云上，无法直接下载，需要设置 proxy在 /usr/lib/systemd/system/docker.service 文件中添加如下两行 [root@master ~]# cat /usr/lib/systemd/system/docker.service |grep PROXYEnvironment=&quot;HTTPS_PROXY=http://www.ik8s.io:10080&quot;Environment=&quot;NO_PROXY=127.0.0.0/8,192.168.31.0/24&quot; 之后，启动 docker systemctl daemon-reloadsystemctl start dockersystemctl enable docker 确认 proc 的这两个参数如下，均为 1 [root@master ~]# cat /proc/sys/net/bridge/bridge-nf-call-iptables 1[root@master ~]# cat /proc/sys/net/bridge/bridge-nf-call-ip6tables 1解决方法：修改系统文件是的机器 bridge 模式开启设置机器开机启动的时候执行下面两条命令编辑 vim /etc/rc.d/rc.local 添加下面两条命令 echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-ip6tablescentos7 需要增加执行权限： chmod +x　/etc/rc,d/rc.local重启系统 设置 kubelet查看 kubelet 安装生成了哪些文件 [root@master ~]# rpm -ql kubelet/etc/kubernetes/manifests # 清单目录/etc/sysconfig/kubelet # 配置文件/etc/systemd/system/kubelet.service # unit file/usr/bin/kubelet # 主程序 默认的配置文件 [root@master ~]# cat /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS= 修改 kubelet 的配置文件 [root@master ~]# cat /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS=&quot;--fail-swap-on=false&quot; 此时还无法正常启动 kubelet，先设置 kubelet 开机自启动，使用如下命令： systemctl enable kubelet 。 kubeadm init在 master 节点上执行 kubeadm init --kubernetes-version=v1.11.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap kubeadm init 的输出可见于此链接 此命令，下载了如下 image [root@master ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEk8s.gcr.io/kube-proxy-amd64 v1.11.2 46a3cd725628 7 days ago 97.8MBk8s.gcr.io/kube-apiserver-amd64 v1.11.2 821507941e9c 7 days ago 187MBk8s.gcr.io/kube-controller-manager-amd64 v1.11.2 38521457c799 7 days ago 155MBk8s.gcr.io/kube-scheduler-amd64 v1.11.2 37a1403e6c1a 7 days ago 56.8MBk8s.gcr.io/coredns 1.1.3 b3b94275d97c 2 months ago 45.6MBk8s.gcr.io/etcd-amd64 3.2.18 b8df3b177be2 4 months ago 219MBk8s.gcr.io/pause 3.1 da86e6ba6ca1 7 months ago 742kB 现在，正在运行的 docker 如下 [root@master ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES1c03e043e6b7 46a3cd725628 &quot;/usr/local/bin/kube?? 3 minutes ago Up 3 minutes k8s_kube-proxy_kube-proxy-6fgjm_kube-system_f85e8660-a090-11e8-8ee7-000c29f71e04_05f166bd11566 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 3 minutes ago Up 3 minutes k8s_POD_kube-proxy-6fgjm_kube-system_f85e8660-a090-11e8-8ee7-000c29f71e04_00f306f98cc52 b8df3b177be2 &quot;etcd --advertise-cl?? 3 minutes ago Up 3 minutes k8s_etcd_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_08f01317b9e20 37a1403e6c1a &quot;kube-scheduler --ad?? 3 minutes ago Up 3 minutes k8s_kube-scheduler_kube-scheduler-master_kube-system_a00c35e56ebd0bdfcd77d53674a5d2a1_04e6a71ab20d3 821507941e9c &quot;kube-apiserver --au?? 3 minutes ago Up 3 minutes k8s_kube-apiserver_kube-apiserver-master_kube-system_d25d40ebb427821464356bb27a38f487_069e4c5dae335 38521457c799 &quot;kube-controller-man?? 3 minutes ago Up 3 minutes k8s_kube-controller-manager_kube-controller-manager-master_kube-system_6363f7ebf727b0b95d9a9ef72516a0e5_0da5981dc546a k8s.gcr.io/pause:3.1 &quot;/pause&quot; 3 minutes ago Up 3 minutes k8s_POD_kube-controller-manager-master_kube-system_6363f7ebf727b0b95d9a9ef72516a0e5_0b7a8fdc35029 k8s.gcr.io/pause:3.1 &quot;/pause&quot; 3 minutes ago Up 3 minutes k8s_POD_kube-apiserver-master_kube-system_d25d40ebb427821464356bb27a38f487_0b09efc7ff7bd k8s.gcr.io/pause:3.1 &quot;/pause&quot; 3 minutes ago Up 3 minutes k8s_POD_kube-scheduler-master_kube-system_a00c35e56ebd0bdfcd77d53674a5d2a1_0ab11d6ffadab k8s.gcr.io/pause:3.1 &quot;/pause&quot; 3 minutes ago Up 3 minutes k8s_POD_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0 node 节点可以通过如下命令加入集群 kubeadm join 192.168.31.81:6443 --token n84v6t.c7d83cn4mo2z8wyr --discovery-token-ca-cert-hash sha256:b946c145416fe1995e1d4d002c149e71a897acc7b106d94cee2920cb2c85ce29 在 kubeadm init 的输出中，提示我们需要以普通用户做如下操作，我此时用 root 执行 [root@master ~]# mkdir -p $HOME/.kube[root@master ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 此时可以通过 kubelet get 获取各种资源信息。比如 [root@master ~]# kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy &#123;&quot;health&quot;: &quot;true&quot;&#125; 此时的监听状态 [root@master ~]# ss -tnlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.1:2379 *:* LISTEN 0 128 127.0.0.1:10251 *:* LISTEN 0 128 127.0.0.1:2380 *:* LISTEN 0 128 127.0.0.1:10252 *:* LISTEN 0 128 *:22 *:* LISTEN 0 128 127.0.0.1:33881 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 192.168.18.128:10010 *:* LISTEN 0 128 127.0.0.1:10248 *:* LISTEN 0 128 127.0.0.1:10249 *:* LISTEN 0 128 :::6443 :::* LISTEN 0 128 :::10256 :::* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* LISTEN 0 128 :::10250 :::* 此时的节点状态 [root@master ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster NotReady master 9m v1.11.2 状态为 NotReady ， 需要部署 flannel，链接 部署 flannel在文档中，找到如下命令，部署 [root@master ~]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.ymlclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.extensions/kube-flannel-ds-amd64 createddaemonset.extensions/kube-flannel-ds-arm64 createddaemonset.extensions/kube-flannel-ds-arm createddaemonset.extensions/kube-flannel-ds-ppc64le createddaemonset.extensions/kube-flannel-ds-s390x created 按如下方法查看： [root@master ~]# kubectl get pods -n kube-systemNAME READY STATUS RESTARTS AGEcoredns-78fcdf6894-cv4gp 1/1 Running 0 13mcoredns-78fcdf6894-wmd25 1/1 Running 0 13metcd-master 1/1 Running 0 49skube-apiserver-master 1/1 Running 0 49skube-controller-manager-master 1/1 Running 0 48skube-flannel-ds-amd64-r42wr 1/1 Running 0 2mkube-proxy-6fgjm 1/1 Running 0 13mkube-scheduler-master 1/1 Running 0 48s[root@master ~]# docker images |grep flannelquay.io/coreos/flannel v0.10.0-amd64 f0fad859c909 6 months ago 44.6MB[root@master ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 14m v1.11.2 此时 master 节点状态变为 Ready 。 在 node 节点上执行 kubeadm join 命令使用 master 节点执行 kubeadm init 命令的输出，在 node 上执行，使其加入集群。 [root@node01 ~]# kubeadm join 192.168.18.128:6443 --token n84v6t.c7d83cn4mo2z8wyr --discovery-token-ca-cert-hash sha256:b946c145416fe1995e1d4d002c149e71a897acc7b106d94cee2920cb2c85ce29 --ignore-preflight-errors=Swap[preflight] running pre-flight checks [WARNING RequiredIPVSKernelModulesAvailable]: the IPVS proxier will not be used, because the following required kernel modules are not loaded: [ip_vs ip_vs_rr ip_vs_wrr ip_vs_sh] or no builtin kernel ipvs support: map[ip_vs_sh:&#123;&#125; nf_conntrack_ipv4:&#123;&#125; ip_vs:&#123;&#125; ip_vs_rr:&#123;&#125; ip_vs_wrr:&#123;&#125;]you can solve this problem with following methods: 1. Run &#x27;modprobe -- &#x27; to load missing kernel modules;2. Provide the missing builtin kernel ipvs support [WARNING Swap]: running with swap on is not supported. Please disable swapI0815 22:02:30.751069 15460 kernel_validator.go:81] Validating kernel versionI0815 22:02:30.751145 15460 kernel_validator.go:96] Validating kernel config [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.06.0-ce. Max validated version: 17.03[discovery] Trying to connect to API Server &quot;192.168.18.128:6443&quot;[discovery] Created cluster-info discovery client, requesting info from &quot;https://192.168.18.128:6443&quot;[discovery] Requesting info from &quot;https://192.168.18.128:6443&quot; again to validate TLS against the pinned public key[discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server &quot;192.168.18.128:6443&quot;[discovery] Successfully established connection with API Server &quot;192.168.18.128:6443&quot;[kubelet] Downloading configuration for the kubelet from the &quot;kubelet-config-1.11&quot; ConfigMap in the kube-system namespace[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[preflight] Activating the kubelet service[tlsbootstrap] Waiting for the kubelet to perform the TLS Bootstrap...[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;node01&quot; as an annotationThis node has joined the cluster:* Certificate signing request was sent to master and a response was received.* The Kubelet was informed of the new secure connection details.Run &#x27;kubectl get nodes&#x27; on the master to see this node join the cluster. 在两个节点上，执行完毕上述命令后，在 master 上查看 [root@master ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONmaster Ready master 23m v1.11.2node01 Ready &lt;none&gt; 2m v1.11.2node02 Ready &lt;none&gt; 1m v1.11.2 部署成功。 部署完成后的观察检查现在正在运行的 pod [root@master ~]# kubectl get pods -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODEcoredns-78fcdf6894-cv4gp 1/1 Running 0 28m 10.244.0.3 master &lt;none&gt;coredns-78fcdf6894-wmd25 1/1 Running 0 28m 10.244.0.2 master &lt;none&gt;etcd-master 1/1 Running 0 15m 192.168.18.128 master &lt;none&gt;kube-apiserver-master 1/1 Running 0 15m 192.168.18.128 master &lt;none&gt;kube-controller-manager-master 1/1 Running 0 15m 192.168.18.128 master &lt;none&gt;kube-flannel-ds-amd64-48rvq 1/1 Running 3 6m 192.168.18.130 node02 &lt;none&gt;kube-flannel-ds-amd64-7dw42 1/1 Running 3 7m 192.168.18.129 node01 &lt;none&gt;kube-flannel-ds-amd64-r42wr 1/1 Running 0 16m 192.168.18.128 master &lt;none&gt;kube-proxy-6fgjm 1/1 Running 0 28m 192.168.18.128 master &lt;none&gt;kube-proxy-6mngv 1/1 Running 0 7m 192.168.18.129 node01 &lt;none&gt;kube-proxy-9sh2n 1/1 Running 0 6m 192.168.18.130 node02 &lt;none&gt;kube-scheduler-master 1/1 Running 0 15m 192.168.18.128 master &lt;none&gt; 可以发现： kube-apiserver， kube-scheduler， kube-controller，etcd-master 运行在 master 上， kube-flannel 在三个节点上均有运行 kube-proxy 在三个节点均有运行","tags":["Cloud Navite","Kubernetes"],"categories":["折腾不止"]},{"title":"开启云原生之门","path":"/2018/open-cloud-native-study.html","content":"什么是云原生CNCF组织在讲云原生之前，我们先了解一下 CNCF ，即云原生计算基金会，2015年由谷歌牵头成立，基金会成员目前已有一百多企业与机构，包括亚马逊、微软。思科等巨头。目前 CNCF 所托管的应用已达14个，下图为其公布的Cloud Native Landscape，给出了云原生生态的参考体系： 云原生(Cloud Native)CNCF 给出了云原生应用的三大特征： 容器化封装：以容器为基础，提高整体开发水平，形成代码和组件重用，简化云原生应用程序的维护。在容器中运行应用程序和进程，并作为应用程序部署的独立单元，实现高水平资源隔离。 动态管理：通过集中式的编排调度系统来动态的管理和调度。 面向微服务：明确服务间的依赖，互相解耦。 云原生包含了一组应用的模式，用于帮助企业快速，持续，可靠，规模化地交付业务软件。云原生由微服务架构，DevOps 和以容器为代表的敏捷基础架构组成。这边引用网上关于云原生所需要的能力和特征总结： 应用部署运行模式的变迁 学习一个新事物之前呢，我们应该先了解\t该事物发展的历程和规律，Kubernetes 的出现就是应用部署运行模式在外部条件需求变更的情况下，演化出来的结果 物理机模式(物理机-操作系统-应用) 虚拟化模式(虚拟机-应用) 容器化模式 以 Docker为代表的内核容器技术不是新技术,而是将已有技术(LXC、 groups、 Union fs)进行了更好的整合和包装,并形成了一种标准镜像格式 与VM相比,容器具有开发交付流程操作对象同步、执行更为高效资源占用更为集约等优势。 计算基本单元由虚拟机变为了容器,越来越多应用的构建、部署与运行选择在容器中进行。 云原生模式 随着容器技术的岀现以及应用所面临的外部环境的变化,云原生逐渐成为一种应用云化开发、部署和运行的主流方式 基础前提:应用的容器化和微服务化。容器,作为应用部署、运行和管理的基本单元 核心:借助容器管理自动化平台进行动态编排和资源优化利用 云原生应用的三大特征容器化封装最近几年Docker容器化技术很火，经常在各种场合能够听到关于 Docker 的分享。Docker 让开发工程师可以将他们的应用和依赖封装到一个可移植的容器中。Docker 背后的想法是创建软件程序可移植的轻量容器，让其可以在任何安装了 Docker 的机器上运行，而不用关心底层操作系统。 Docker 可以解决虚拟机能够解决的问题，同时也能够解决虚拟机由于资源要求过高而无法解决的问题。其优势包1括： 隔离应用依赖 创建应用镜像并进行复制 创建容易分发的即启即用的应用 允许实例简单、快速地扩展 测试应用并随后销毁它们 自动化运维工具可以降低环境搭建的复杂度，但仍然不能从根本上解决环境的问题。在看似稳定而成熟的场景下，使用 Docker 的好处越来越多。 服务编排 动态管理Jimmy Song 对云原生架构中运用服务编排的总结是： Kubernetes——让容器应用进入大规模工业生产 编排调度的开源组件还有：Kubernetes、Mesos 和 Docker Swarm; 他们为云原生应用提供的强有力的编排和调度能力，它们是云平台上的分布式操作系统。在单机上运行容器，无法发挥它的最大效能，只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势 微服务架构近几年微服务架构（Micro-Service，Archeticture）是最流行的架构风格，旨在通过将功能模块分解到各个独立的子系统中以实现解耦，它并没有一成不变的规定，而是需要根据业务来做设计。微服务架构是对SOA的传承，是SOA的具体实践方法。微服务架构中，每个微服务模块只是对简单、独立、明确的任务进行处理，通过REST API返回处理结果给外部。在微服务推广实践角度来看，微服务将整个系统进行拆分，拆分成更小的粒度，保持这些服务独立运行，应用容器化技术将微服务独立运行在容器中。过去设计架构时，是在内存中以参数或对象的方式实现粒度细化。微服务使用各个子服务控制模块的思想代替总线。不同的业务要求，服务控制模块至少包含服务的发布、注册、路由、代理功能。 容器化的出现，一定程度上带动了微服务架构。架构演化从单体式应用到分布式，再从分布式架构到云原生架构，微服务在其中有着不可或缺的角色。微服务带给我们很多开发和部署上的灵活性和技术多样性，但是也增加了服务调用的开销、分布式系事务、调试与服务治理方面的难题。 总结技术架构的演变非常快，各种新的名词也是层出不穷。本文主要是对云原生的概述。云原生应用的三大特征：容器化封装、动态管理、面向微服务。首先由CNCF组织介绍了云原生的概念，然后分别对这三个特征进行详述。云原生架构是当下很火的讨论话题，是不同思想的集合，集目前各种热门技术之大成","tags":["Docker","Cloud Navite","Kubernetes"],"categories":["设计开发"]},{"title":"优化睡觉的沙发","path":"/2018/optimization-blog-theme.html","content":"博客太久没动了，刚好没事做的时候，就特别改博客主题，感觉像是强迫症，得改~ 玩博客久了，就像谈恋爱，刚开始很美好，久而久之，问题就冒出来，总想让她变的更好， 其实这些都是次要的，我也知道更应该专注文章的内容，哎…… 集成GitmentGitment 是作者实现的一款基于 GitHub Issues 的评论系统。支持在前端直接引入，不需要任何后端代码。可以在页面进行登录、查看、评论、点赞等操作，同时有完整的 Markdown &#x2F; GFM 和代码高亮支持。尤为适合各种基于 GitHub&#x2F;Coding Pages 的静态博客或项目页面 项目地址 示例页面 当然，人家作者也说了，着这个项目的时候考虑过到底有没有滥用 GitHub ，为此还特地 Email 了官方，GitHub 给出的回复是： We’re pleased to see you making use of the tools and resources available on GitHub. 所以啊，我们在使用的时候，也要恪尽职守，维护一个好的开源环境，善用 GitHub 好了，说多了，下面开始： 注册 OAuth Application点击此处 来注册一个新的 OAuth Application，成功之后就会拿到 Client ID 和 Client Secret 修改主题配置文件############################################################################### Plugins################################################################################ Gitmentgitment: enable: true owner: your_id repo: your_repo client_id: your_client_id client_secret: your_client_secret 为 Gitment 添加 layout 布局这里以我的主题 cactus 为例，在 layout/_partial/comments.ejs 下列代添加码： &lt;% if(is_post() || page.comments) &#123; %&gt;&lt;div id=&quot;gitment_title&quot; class=&quot;gitment_title&quot;&gt;&lt;/div&gt;&lt;div id=&quot;container&quot; style=&quot;display:none&quot;&gt;&lt;/div&gt;&lt;script src=&quot;https://imsun.github.io/gitment/dist/gitment.browser.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://code.jquery.com/jquery-3.3.1.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt; const myTheme = &#123; render(state, instance) &#123; const container = document.createElement(&#x27;div&#x27;); container.lang = &quot;en-US&quot;; container.className = &#x27;gitment-container gitment-root-container&#x27;; container.appendChild(instance.renderHeader(state, instance)); container.appendChild(instance.renderEditor(state, instance)); container.appendChild(instance.renderComments(state, instance)); container.appendChild(instance.renderFooter(state, instance)); return container; &#125; &#125; function showGitment() &#123; $(&quot;#gitment_title&quot;).attr(&quot;style&quot;, &quot;display:none&quot;); $(&quot;#container&quot;).attr(&quot;style&quot;, &quot;&quot;).addClass(&quot;gitment_container&quot;); var gitment = new Gitment(&#123; id: decodeURI(window.location.pathname), theme: myTheme, owner: &quot;&lt;%=theme.gitment.owner%&gt;&quot;, repo: &quot;&lt;%=theme.gitment.repo%&gt;&quot;, oauth: &#123; client_id: &quot;&lt;%=theme.gitment.client_id%&gt;&quot;, client_secret: &quot;&lt;%=theme.gitment.client_secret%&gt;&quot; &#125; &#125;); gitment.render(&#x27;container&#x27;); &#125; showGitment();&lt;/script&gt;&lt;% &#125; %&gt; 为 Gitment 添加样式_gitment.styl 这是我自定义的 Gitment 的样式文件，比较契合我的主题 cactus ，可以自行修改；将样式文件拷贝到 source/css/ 目录下 引入 Gitment 样式 在 source/css/style.styl 文件中，添加： @import &quot;_gitment.styl&quot; ok，更新博客，就可以看到评论了 主题首页添加 一言 一言：随机一句话副标题， 可以是一本书，一部电影，一句歌词， 可以是中文，英文，日语， 总之是一句话 感谢作者：isecret，是从他他制作的 Hexo 主题 Hola 获取的灵感 修改主题配置文件############################################################################### Plugins################################################################################ 一言hitokoto: enabled 为一言添加 layout 布局在 layout/index.styl 文件中的 &lt;section id=&quot;about&quot;&gt; 内添加： &lt;% if (theme.hitokoto == &#x27;enabled&#x27;) &#123; %&gt; &lt;p&gt; &lt;script&gt; fetch(&#x27;https://api.hitokoto.cn&#x27;) .then(function (res)&#123; return res.json(); &#125;) .then(function (data) &#123; var hitokoto = document.getElementById(&#x27;hitokoto&#x27;); hitokoto.innerText = data.hitokoto + &#x27; ——&#x27; + &#x27;『&#x27; + data.from + &#x27;』&#x27;; &#125;) .catch(function (err) &#123; console.error(err); &#125;); &lt;/script&gt; &lt;a id=&quot;hitokoto&quot;&gt;&lt;/a&gt; &lt;/p&gt; &lt;% &#125; %&gt; 演示地址 gulp 文件压缩安装 npm 依赖组件# 在站点的根目录下执行以下命令npm install gulp -gnpm install gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp --save# 模块作用gulp-htmlclean // 清理htmlgulp-htmlmin // 压缩htmlgulp-minify-css // 压缩cssgulp-uglify // 混淆jsgulp-imagemin // 压缩图片 新建 gulp 配置/* 在站点根目录添加 gulpfile.js 文件，内容如下： */var gulp = require(&#x27;gulp&#x27;);var minifycss = require(&#x27;gulp-minify-css&#x27;);var uglify = require(&#x27;gulp-uglify&#x27;);var htmlmin = require(&#x27;gulp-htmlmin&#x27;);var htmlclean = require(&#x27;gulp-htmlclean&#x27;);// 压缩 public 目录 cssgulp.task(&#x27;minify-css&#x27;, function() &#123; return gulp.src(&#x27;./public/**/*.css&#x27;) .pipe(minifycss()) .pipe(gulp.dest(&#x27;./public&#x27;));&#125;);// 压缩 public 目录 htmlgulp.task(&#x27;minify-html&#x27;, function() &#123; return gulp.src(&#x27;./public/**/*.html&#x27;) .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest(&#x27;./public&#x27;))&#125;);// 压缩 public/js 目录 jsgulp.task(&#x27;minify-js&#x27;, function() &#123; return gulp.src(&#x27;./public/**/*.js&#x27;) .pipe(uglify()) .pipe(gulp.dest(&#x27;./public&#x27;));&#125;);// 执行 gulp 命令时执行的任务gulp.task(&#x27;default&#x27;, [ &#x27;minify-html&#x27;,&#x27;minify-css&#x27;,&#x27;minify-js&#x27;]); 部署命令在站点根目录执行 gulp 命令，就能压缩 public 文件夹里面的文件了 hexo g &amp;&amp; gulp;hexo d; 后续有其他优化，会持续更新的……","tags":["Hexo"],"categories":["折腾不止"]},{"title":"你和大佬之间就差一个 vim","path":"/2018/vim-common-hotkey.html","content":"进入 vim 命令 描述 vim filename 打开或新建文件, 并将光标置于第一行首 vim +n filename 打开文件，并将光标置于第 n 行首 vim + filename 打开文件，并将光标置于最后一行首 vim +&#x2F;pattern filename 打开文件，并将光标置于第一个与 pattern 匹配的串处 vim -r filename 在上次正用 vim 编辑时发生系统崩溃，恢复 filename vim filename….filename 打开多个文件，依次编辑 vim 配置 命令 描述 :set number &#x2F; set nonumber 显示 &#x2F; 不显示行号 :set ruler &#x2F;set noruler 显示 &#x2F; 不显示标尺 :set hlsearch 高亮显示查找到的单词 :set nohlsearch 关闭高亮显示 :syntax on 语法高亮 :set nu 显示行号 :set tabstop&#x3D;8 设置 tab 大小, 8 为最常用最普遍的设置 :set softtabstop&#x3D;8 4:4 个空格, 8: 正常的制表符, 12: 一个制表符 4 个空格, 16: 两个制表符 :set autoindent 自动缩进 :set cindent C 语言格式里面的自动缩进 移动光标 命令 描述 k nk 上 向上移动 n 行 j nj 下 向下移动 n 行 h nh 左 向左移动 n 行 l nl 右 向右移动 n 行 Space 光标右移一个字符 Backspace 光标左移一个字符 Enter 光标下移一行 w&#x2F;W 光标右移一个字至字首 b&#x2F;B 光标左移一个字至字首 e 或 E 光标右移一个字至字尾 ) 光标移至句尾 ( 光标移至句首 } 光标移至段落开头 { 光标移至段落结尾 n$ 光标移至第 n 行尾 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 0 （注意是数字零）光标移至当前行首 ^ 移动光标到行首第一个非空字符上去 $ 光标移至当前行尾 gg 移到第一行 G 移到最后一行 f 移动光标到当前行的字符 a 上 F 相反 % 移动到与制匹配的括号上去（），{}，[]，&lt;&gt; 等 nG 移动到第 n 行上 G 到最后一行 屏幕滚动 命令 描述 Ctrl+u 向文件首翻半屏 Ctrl+d 向文件尾翻半屏 Ctrl+f 向文件尾翻一屏 Ctrl＋b 向文件首翻一屏 nz 将第 n 行滚至屏幕顶部，不指定 n 时将当前行滚至屏幕顶部 插入文本类 命令 描述 i 在光标前 I 在当前行首 a 光标后 A 在当前行尾 o 在当前行之下新开一行 O 在当前行之上新开一行 r 替换当前字符 R 替换当前字符及其后的字符，直至按 ESC 键 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入文本代替之 ncw&#x2F;nCW 修改指定数目的字 nCC 修改指定数目的行 删除命令 命令 描述 x&#x2F;X 删除一个字符，x 删除光标后的，而 X 删除光标前的 dw 删除一个单词 (删除光标位置到下一个单词开始的位置) dnw 删除 n 个单词 dne 也可，只是删除到单词尾 do 删至行首 d$ 删至行尾 dd 删除一行 ndd 删除当前行及其后 n-1 行 dnl 向右删除 n 个字母 dnh 向左删除 n 个字母 dnj 向下删除 n 行, 当前行 + 其上 n 行 dnk 向上删除 n 行, 当期行 + 其下 n 行 cnw[word] 将 n 个 word 改变为 word C$ 改变到行尾 cc 改变整行 shift+j 删除行尾的换行符，下一行接上来了 复制粘贴 命令 描述 p 粘贴用 x 或 d 删除的文本 ynw 复制 n 个单词 yy 复制一行 ynl 复制 n 个字符 y$ 复制当前光标至行尾处 nyy 拷贝 n 行 撤销 命令 描述 u 撤销前一次的操作 shif+u(U) 撤销对该行的所有操作 搜索及替换 命令 描述 &#x2F;pattern 从光标开始处向文件尾搜索 pattern ?pattern 从光标开始处向文件首搜索 pattern n 在同一方向重复上一次搜索命令 N 在反方向上重复上一次搜索命令 cw newword 替换为 newword n 继续查找 . 执行替换 :s&#x2F;p1&#x2F;p2&#x2F;g 将当前行中所有 p1 均用 p2 替代, g 表示执行 用 c 表示需要确认 :n1,n2 s&#x2F;p1&#x2F;p2&#x2F;g 将第 n1 至 n2 行中所有 p1 均用 p2 替代 :g&#x2F;p1&#x2F;s&#x2F;&#x2F;p2&#x2F;g 将文件中所有 p1 均用 p2 替换 :1,$ s&#x2F;string1&#x2F;string2&#x2F;g 在全文中将 string1 替换为 string2 书签 命令 描述 m[a-z] 在文中做标记，标记号可为 a-z 的 26 个字母 &#96;a 移动到标记 a 处 visual 模式 命令 描述 v 进入 visual 模式 V 进入行的 visual 模式 ctrl+v 进如块操作模式用 o 和 O 改变选择的边的大小 在所有行插入相同的内容如 include&lt; 将光标移到开始插入的位置，按 CTRL+V 进入 VISUAL 模式，选择好模块后按 I（shift+i)，后插入要插入的文本，按 [ESC] 完成 行方式命令 命令 描述 :n1,n2 co n3 或者 :n1,n2 copy n3 将 n1 行到 n2 行之间的内容拷贝到第 n3 行下 :n1,n2 m n3 或者 :n1,n2 move n3 将 n1 行到 n2 行之间的内容移至到第 n3 行下 :n1,n2 d 将 n1 行到 n2 行之间的内容删除 :n1,n2 w!command 将文件中 n1 行至 n2 行的内容作为 command 的输入并执行之 若不指定 n1，n2，则表示将整个文件内容作为 command 的输入 宏 命令 描述 q[a-z] 开始记录但前开始的操作为宏，名称可为【a-z】，然后用 q 终止录制宏 reg 显示当前定义的所有的宏，用 @[a-z] 来在当前光标处执行宏 [a-z] 窗口操作 命令 描述 :split 分割一个窗口 :split file.c 为另一个文件 file.c 分隔窗口 :nsplit file.c 为另一个文件 file.c 分隔窗口，并指定其行数 ctrl＋w 在窗口中切换 :close 关闭当前窗口 文件及其他 命令 描述 :q 退出 vi :q! 不保存文件并退出 vi :e filename 打开文件 filename 进行编辑 :e! 放弃修改文件内容，重新载入该文件编辑 :w 保存当前文件 :wq 存盘退出 :ZZ 保存当前文档并退出 VIM :!command 执行 shell 命令 command :r!command 将命令 command 的输出结果放到当前行 :read file.c 将文件 file.c 的内容插入到当前光标所在的下面 常用正则 删除行尾空格：:%s/\\s+$//g 删除行首多余空格：%s/^\\s*// 或者 %s/^ *// 删除沒有內容的空行：%s/^$// 或者 g/^$/d 删除包含有空格组成的空行：%s/^\\s*$// 或者 g/^\\s*$/d 删除以空格或 TAB 开头到结尾的空行：%s/^[ |\\t]*$// 或者 g/^[ |\\t]*$/d 清空某一行或多行文本：:n1,n2 s/\\w//g 给一行或多行首字符添加注释：n1,n2 s/^/#/g 给一行或多行首字符删除注释：n1,n2 s/^#//g","tags":["Linux","Vim"],"categories":["安利系列"]},{"title":"gin-swagger 自动化构建 API 文档","path":"/2018/gin-swagger-build-document.html","content":"前后端的交互一般流程是这样的，后端暴露出 API 后，交给前端，前端根据 API 的响应，编写前端页面，一定程度上 API 是前后端的交互桥梁。 API 文档主要要包含: 路由：包括路径参数、请求参数、还是请求体参数 动作：HTTP 请求动作，GET、POST、DELETE、PUT 响应：请求之后的返回值包含哪些信息，一般是 JSON swagger 可以将代码和 api 文档维护在一起，通过访问服务进程的 swagger 页面就可以得到完善的 api 文档，还可以直接 Try out。 doc文档 gin-swagger swagger-doc 做法 要知道 swagger 注释的语法 如何在 gin 内怎么使用 注释语法这个，全靠查文档。对着文档来。 当然我觉得最好的方法是什么呢，是模仿，找一个别人已经写好的，修修改改，看看能不能编译通过，编译通过后是不是你预期的结果。不是的话，继续修修改改，再编译，再看是不是你希望的结果。如此反复。 1. 编写全局信息注释，在主函数上编写格式：// @param info // @title Swagger Example API// @version 1.0// @description This is a sample server Petstore server.// @termsOfService http://swagger.io/terms/// @contact.name API Support// @contact.url http://www.swagger.io/support// @contact.email support@swagger.io// @license.name Apache 2.0// @license.url http://www.apache.org/licenses/LICENSE-2.0.html// @host 127.0.0.1:8080// @BasePath /v1func main() &#123; r := gin.Default() r.GET(&quot;/docs/*any&quot;, ginSwagger.WrapHandler(swaggerFiles.Handler)) r.GET(&quot;v1/hello/:name&quot;, Name) r.Run()&#125; r.GET(&quot;/docs/*any&quot;, ginSwagger.WrapHandler(swaggerFiles.Handler)) 这个路由和响应需要有，路由随便的定义，但我觉得我这种方式一目了然，知道是文档。 其他注释对照着参考文档即可。 2. 编写应用注释即在响应函数的上方编写注释 // Name will print hello name// @Summary Print// @Accept json// @Tags Name// @Security Bearer// @Produce json// @Param name path string true &quot;name&quot;// @Resource Name// @Router /hello/&#123;name&#125; [get]// @Success 200 &#123;object&#125; main.Messagefunc Name(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) if name == &quot;&quot; &#123; return &#125; var message Message message = Message&#123; MessageInfo: fmt.Sprintf(&quot;hello %s&quot;, name), &#125; c.JSON(http.StatusOK, message.Serializer())&#125; 这里最好把响应体统一成结构体的形式。即 type Message struct &#123; MessageInfo string `json:&quot;message&quot;`&#125;func (m *Message) Serializer()Message&#123; return Message&#123; MessageInfo: m.MessageInfo, &#125;&#125; 3. 目录下 执行命令swag init 自动生成 docs 文件夹，内含 swagger.json 、swagger.json 、 docs.go 编译不通过，查看报错信息，修改注释。 4. 导入生成的 docs 文件import ( &quot;github.com/swaggo/gin-swagger&quot; &quot;github.com/swaggo/gin-swagger/swaggerFiles&quot; _ &quot;./docs&quot; // docs is generated by Swag CLI, you have to import it. &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot; &quot;fmt&quot;) 即这个 ./docs 5. go run main.go访问：http://127.0.0.1:8080/docs/index.html 即可查看 swagger 文档。","tags":["Go"],"categories":["技术加油站"]},{"title":"高性能的 Go Web 框架 - gin","path":"/2018/gin-go-web-frame.html","content":"Gin 的使用安装和更新首次安装，使用 go get命令获取即可。 $ go get github.com/gin-gonic/gin 更新就是常规的 go get -u。 $ go get -u github.com/gin-gonic/gin 快速运行在你的 main 包中，引入 gin 包并初始化。 package mainimport ( &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot;)func main() &#123; // 初始化引擎 engine := gin.Default() // 注册一个路由和处理函数 engine.Any(&quot;/&quot;, WebRoot) // 绑定端口，然后启动应用 engine.Run(&quot;:9205&quot;)&#125;/*** 根请求处理函数* 所有本次请求相关的方法都在 context 中，完美* 输出响应 hello, world*/func WebRoot(context *gin.Context) &#123; context.String(http.StatusOK, &quot;hello, world&quot;)&#125; 一个最简单的应用就写好了，来运行下试试: $ go run[GIN-debug] Listening and serving HTTP on :9205 访问 http://127.0.0.1:9205 ，就可以得到响应 “hello, world” 。 路由 (Router)Restful Api你可以注册路由方法有 GET, POST, PUT, PATCH, DELETE 和 OPTIONS. 使用很简单，直接调用同名的方法即可。 // 省略的代码 ...func main() &#123; router := gin.Default() router.GET(&quot;/someGet&quot;, getting) router.POST(&quot;/somePost&quot;, posting) router.PUT(&quot;/somePut&quot;, putting) router.DELETE(&quot;/someDelete&quot;, deleting) router.PATCH(&quot;/somePatch&quot;, patching) router.HEAD(&quot;/someHead&quot;, head) router.OPTIONS(&quot;/someOptions&quot;, options) // 默认绑定 :8080 router.Run()&#125;// 省略的代码 ... 动态路由（参数路由）有时候我们需要动态的路由，如 /user/:id，通过调用的 url 来传入不同的 id . 在 Gin 中很容易处理这种路由： // 省略的代码 ...func main() &#123; router := gin.Default() // 注册一个动态路由 // 可以匹配 /user/leeifme // 不能匹配 /user 和 /user/ router.GET(&quot;/user/:name&quot;, func(c *gin.Context) &#123; // 使用 c.Param(key) 获取 url 参数 name := c.Param(&quot;name&quot;) c.String(http.StatusOK, &quot;Hello %s&quot;, name) &#125;) // 注册一个高级的动态路由 // 该路由会匹配 /user/leeifme/ 和 /user/leeifme/send // 如果没有任何路由匹配到 /user/leeifme, 那么他就会重定向到 /user/leeifme/，从而被该方法匹配到 router.GET(&quot;/user/:name/*action&quot;, func(c *gin.Context) &#123; name := c.Param(&quot;name&quot;) action := c.Param(&quot;action&quot;) message := name + &quot; is &quot; + action c.String(http.StatusOK, message) &#125;) router.Run(&quot;:8080&quot;)&#125;// 省略的代码 ... 路由组一些情况下，我们会有统一前缀的 url 的需求，典型的如 Api 接口版本号 /v1/something。Gin 可以使用 Group 方法统一归类到路由组中： // 省略的代码 ...func main() &#123; router := gin.Default() // 定义一个组前缀 // /v1/login 就会匹配到这个组 v1 := router.Group(&quot;/v1&quot;) &#123; v1.POST(&quot;/login&quot;, loginEndpoint) v1.POST(&quot;/submit&quot;, submitEndpoint) v1.POST(&quot;/read&quot;, readEndpoint) &#125; // 定义一个组前缀 // 不用花括号包起来也是可以的。上面那种只是看起来会统一一点。看你个人喜好 v2 := router.Group(&quot;/v2&quot;) v2.POST(&quot;/login&quot;, loginEndpoint) v2.POST(&quot;/submit&quot;, submitEndpoint) v2.POST(&quot;/read&quot;, readEndpoint) router.Run(&quot;:8080&quot;)&#125;// 省略的代码 ... 中间件 (Middleware)golang 的 net&#x2F;http 设计的一大特点就是特别容易构建中间件。需要注意的是中间件只对注册过的路由函数起作用。对于分组路由，嵌套使用中间件，可以限定中间件的作用范围。中间件分为全局中间件，单个路由中间件和群组中间件。 现代化的 Web 编程，中间件已经是必不可少的了。我们可以通过中间件的方式，验证 Auth 和身份鉴别，集中处理返回的数据等等。Gin 提供了 Middleware 的功能，并与路由紧紧相连。 单个路由中间件单个路由使用中间件，只需要在注册路由的时候指定要执行的中间件即可。 // 省略的代码 ...func main() &#123; router := gin.Default() // 注册一个路由，使用了 middleware1，middleware2 两个中间件 router.GET(&quot;/someGet&quot;, middleware1, middleware2, handler) // 默认绑定 :8080 router.Run()&#125;func handler(c *gin.Context) &#123; log.Println(&quot;exec handler&quot;)&#125;// 省略的代码 ... 执行流程控制用上面的实例代码，我们来看一下中间件是怎么执行的。 // 省略的代码 ...func middleware1(c *gin.Context) &#123; log.Println(&quot;exec middleware1&quot;) //你可以写一些逻辑代码 // 执行该中间件之后的逻辑 c.Next()&#125;// 省略的代码 ... 可以看出，中间件的写法和路由的 Handler 几乎是一样的，只是多调用 c.Next()。 正是有个c.Next()，我们可以在中间件中控制调用逻辑的变化，看下面的 middleware2 代码。 // 省略的代码 ...func middleware2(c *gin.Context) &#123; log.Println(&quot;arrive at middleware2&quot;) // 执行该中间件之前，先跳到流程的下一个方法 c.Next() // 流程中的其他逻辑已经执行完了 log.Println(&quot;exec middleware2&quot;) //你可以写一些逻辑代码&#125;// 省略的代码 ... 在 middleware2中，执行到 c.Next()时，Gin 会直接跳到流程的下一个方法中，等到这个方法执行完后，才会回来接着执行 middleware2 剩下的代码。 所以请求上面注册的路由 url /someGet ，请求先到达middleware1，然后到达 middleware2，但此时 middleware2调用了 c.Next()，所以 middleware2的代码并没有执行，而是跳到了 handler，等 handler执行完成后，跳回到 middleware2，执行 middleware2剩下的代码。 所以我们可以在控制台上看到以下日志输出: exec middleware1arrive at middleware2exec handlerexec middleware2 路由组使用中间件路由组使用中间件和单个路由类似，只不过是要把中间件放到 Group 上. // 省略的代码 ...func main() &#123; router := gin.Default() // 定义一个组前缀, 并使用 middleware1 中间件 // 访问 /v2/login 就会执行 middleware1 函数 v2 := router.Group(&quot;/v2&quot;, middleware1) v2.POST(&quot;/login&quot;, loginEndpoint) v2.POST(&quot;/submit&quot;, submitEndpoint) v2.POST(&quot;/read&quot;, readEndpoint) router.Run(&quot;:8080&quot;)&#125;// 省略的代码 ...","tags":["Go"],"categories":["技术加油站"]},{"title":"Docker 常用命令记录","path":"/2018/docker-common-command .html","content":"Docker 是什么Docker 是一个改进的容器技术。具体的 “改进” 体现在，Docker 为容器引入了镜像，使得容器可以从预先定义好的模版（images）创建出来，并且这个模版还是分层的。 Docker 经常被提起的特点： 轻量，体现在内存占用小，高密度 快速，毫秒启动 隔离，沙盒技术更像虚拟机 Docker 技术的基础： namespace，容器隔离的基础，保证 A 容器看不到 B 容器. 6 个名空间：User,Mnt,Network,UTS,IPC,Pid cgroups，容器资源统计和隔离。主要用到的 cgroups 子系统：cpu,blkio,device,freezer,memory unionfs，典型：aufs&#x2F;overlayfs，分层镜像实现的基础 Docker 组件： docker Client 客户端————&gt; 向 docker 服务器进程发起请求，如: 创建、停止、销毁容器等操作 docker Server 服务器进程—–&gt; 处理所有 docker 的请求，管理所有容器 docker Registry 镜像仓库——&gt; 镜像存放的中央仓库，可看作是存放二进制的 scm Docker 安装Docker 的安装非常简单，支持目前所有主流操作系统，从 Mac 到 Windows 到各种 Linux 发行版具体参考： docker 安装 Docker 常见命令容器相关操作docker create # 创建一个容器但是不启动它docker run # 创建并启动一个容器docker stop # 停止容器运行，发送信号 SIGTERMdocker start # 启动一个停止状态的容器docker restart # 重启一个容器docker rm # 删除一个容器docker kill # 发送信号给容器，默认 SIGKILLdocker attach # 连接 (进入) 到一个正在运行的容器docker wait # 阻塞到一个容器，直到容器停止运行 获取容器相关信息docker ps # 显示状态为运行（Up）的容器docker ps -a # 显示所有容器, 包括运行中（Up）的和退出的 (Exited)docker inspect # 深入容器内部获取容器所有信息docker logs # 查看容器的日志 (stdout/stderr)docker events # 得到 docker 服务器的实时的事件docker port # 显示容器的端口映射docker top # 显示容器的进程信息docker diff # 显示容器文件系统的前后变化 导出容器docker cp # 从容器里向外拷贝文件或目录docker export # 将容器整个文件系统导出为一个 tar 包，不带 layers、tag 等信息 执行docker exec # 在容器里执行一个命令，可以执行 bash 进入交互式 镜像操作docker images # 显示本地所有的镜像列表docker import # 从一个 tar 包创建一个镜像，往往和 export 结合使用docker build # 使用 Dockerfile 创建镜像（推荐）docker commit # 从容器创建镜像docker rmi # 删除一个镜像docker load # 从一个 tar 包创建一个镜像，和 save 配合使用docker save # 将一个镜像保存为一个 tar 包，带 layers 和 tag 信息docker history # 显示生成一个镜像的历史命令docker tag # 为镜像起一个别名 镜像仓库 (registry) 操作docker login # 登录到一个 registrydocker search # 从 registry 仓库搜索镜像docker pull # 从仓库下载镜像到本地docker push # 将一个镜像 push 到 registry 仓库中 获取 Container IP 地址（Container 状态必须是 Up）docker inspect id | grep IPAddress | cut -d &#x27;&quot;&#x27; -f 4 获取端口映射docker inspect -f &#x27;&#123;&#123;range $p, $conf := .NetworkSettings.Ports&#125;&#125; &#123;&#123;$p&#125;&#125; -&gt; &#123;&#123;(index $conf 0).HostPort&#125;&#125; &#123;&#123;end&#125;&#125;&#x27; id 获取环境变量docker exec container_id env 杀掉所有正在运行的容器docker kill $(docker ps -q) 删除老的 (一周前创建) 容器docker ps -a | grep &#x27;weeks ago&#x27; | awk &#x27;&#123;print $1&#125;&#x27; | xargs docker rm 删除已经停止的容器docker rm `docker ps -a -q` 删除所有镜像，小心docker rmi $(docker images -q) DockerfileDockerfile 是 docker 构建镜像的基础，也是 docker 区别于其他容器的重要特征，正是有了 Dockerfile，docker 的自动化和可移植性才成为可能。 不论是开发还是运维，学会编写 Dockerfile 几乎是必备的，这有助于你理解整个容器的运行。 FROM , 从一个基础镜像构建新的镜像FROM ubuntu MAINTAINER , 维护者信息MAINTAINER William &lt;wlj@nicescale.com&gt; ENV , 设置环境变量ENV TEST 1 RUN , 非交互式运行 shell 命令RUN apt-get -y update RUN apt-get -y install nginx ADD , 将外部文件拷贝到镜像里, src 可以为 urlADD http://nicescale.com/ /data/nicescale.tgz WORKDIR &#x2F;path&#x2F;to&#x2F;workdir, 设置工作目录WORKDIR /var/www USER , 设置用户 IDUSER nginx VULUME &lt;#dir&gt;, 设置 volumeVOLUME [‘/data’] EXPOSE , 暴露哪些端口EXPOSE 80 443 ENTRYPOINT [‘executable’, ‘param1’,’param2’] 执行命令ENTRYPOINT [&quot;/usr/sbin/nginx&quot;] CMD [“param1”,”param2”]CMD [&quot;start&quot;] docker 创建、启动 container 时执行的命令，如果设置了 ENTRYPOINT，则 CMD 将作为参数 Dockerfile 最佳实践 尽量将一些常用不变的指令放到前面 CMD 和 ENTRYPOINT 尽量使用 json 数组方式 通过 Dockerfile 构建 imagedocker build csphere/nginx:1.7 . 镜像仓库 Registry镜像从 Dockerfile build 生成后，需要将镜像推送 (push) 到镜像仓库。企业内部都需要构建一个私有 docker registry，这个 registry 可以看作二进制的 scm，CI&#x2F;CD 也需要围绕 registry 进行。 部署 registrymkdir /registrydocker run -p 80:5000 -e STORAGE_PATH=/registry -v /registry:/registry registry:2.0 推送镜像保存到仓库假设 192.168.1.2 是 registry 仓库的地址： docker tag csphere/nginx:1.7 192.168.1.2/csphere/nginx:1.7docker push 192.168.1.2/csphere/nginx:1.7 几个简单小例子容器操作1. 创建并拉取 busybox# docker run -it --name con01 busybox:latest/ # ip addr #容器里执行1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft foreverSegmentation fault (core dumped)/ # ping www.csphere.cnPING www.csphere.cn (117.121.26.243): 56 data bytes64 bytes from 117.121.26.243: seq=0 ttl=48 time=3.139 ms64 bytes from 117.121.26.243: seq=1 ttl=48 time=3.027 ms^C--- www.csphere.cn ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 3.027/3.083/3.139 msexit #退出容器 2. 创建测试容器docker run -d --name con03 csphere/test:0.1efc9bda4a2ff2f479b18e0fc4698e42c47c9583a24c93f5ce6b28a828a172709 3. 登陆到 con03 中# docker exec -it con03 /bin/bash[root@efc9bda4a2ff /]# exit 4. 停止 con03# docker stop con03con03 5. 开启 con03# docker start con03con03 6. 删除 con03# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESefc9bda4a2ff csphere/test:0.1 &quot;/usr/local/bin/run 4 minutes ago Up 17 seconds con03 99aa6ee25adc busybox:latest &quot;/bin/sh&quot; 14 minutes ago Exited (0) 12 minutes ago con02 831c93de9b9f busybox:latest &quot;/bin/sh&quot; 2 hours ago Up 27 minutes con01# docker rm con02 #容器停止的状态# docker rm -f con03 #容器开启的状态 镜像操作1. 从 docker hub 官方镜像仓库拉取镜像# docker pull busybox:latestatest: Pulling from busyboxcf2616975b4a: Pull complete 6ce2e90b0bc7: Pull complete 8c2e06607696: Already exists busybox:latest: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.Digest: sha256:38a203e1986cf79639cfb9b2e1d6e773de84002feea2d4eb006b52004ee8502dStatus: Downloaded newer image for busybox:latest 2. 从本地上传镜像到镜像仓库docker push 192.168.1.2/csphere/nginx:1.7 3. 查找镜像仓库的某个镜像# docker search centos/nginxNAME DESCRIPTION STARS OFFICIAL AUTOMATEDjohnnyzheng/centos-nginx-php-wordpress 1 [OK]sergeyzh/centos6-nginx 1 [OK]hzhang/centos-nginx 1 [OK] 4. 查看本地镜像列表# docker imagesTAG IMAGE ID CREATED VIRTUAL SIZEdocker.io/csphere/csphere 0.10.3 604c03bf0c9e 3 days ago 62.72 MBdocker.io/csphere/csphere latest 604c03bf0c9e 3 days ago 62.72 MBcsphere/csphere 0.10.3 604c03bf0c9e 3 days ago 62.72 MBregistry 2.0 2971b6ce766c 7 days ago 548.1 MBbusybox latest 8c2e06607696 3 weeks ago 2.43 MB 5. 删除镜像docker rmi busybox:latest #没有容器使用此镜像创建，如果有容器在使用此镜像会报错：Error response from daemon: Conflict, cannot delete 8c2e06607696 because the running container 831c93de9b9f is using it, stop it and use -f to forceFATA[0000] Error: failed to remove one or more imagesdocker rmi -f busybox:latest #容器使用此镜像创建，此容器状态为Exited 6. 查看构建镜像所用过的命令# docker history busybox:latestIMAGE CREATED CREATED BY SIZE8c2e06607696 3 weeks ago /bin/sh -c #(nop) CMD [&quot;/bin/sh&quot;] 0 B6ce2e90b0bc7 3 weeks ago /bin/sh -c #(nop) ADD file:8cf517d90fe79547c4 2.43 MBcf2616975b4a 3 weeks ago /bin/sh -c #(nop) MAINTAINER Jérôme Petazzo 0 B","tags":["Docker","Cloud Navite"],"categories":["技术加油站"]},{"title":"初学 Redis 作缓存层","path":"/2018/redis-for-mysql-cache.html","content":"项目需求：数据库用的是MySQL，考虑用Redis&#x2F;memcached做数据库的缓存层。在读DB前，先读缓存层，如果有直接返回，如果没有再读DB，然后写入缓存层并返回。 思路：###缓存读取流程 先到缓存中查数据 缓存中不存在则到实际数据源中取，取出来后放入缓存 下次再来取同样信息时则可直接从缓存中获取 ###缓存更新流程 更新数据库 使缓存过期或失效，这样会促使下次查询数据时在缓存中查不到而重新从数据库去一次。 ###通用缓存机制 用查询的方法名 + 参数作为查询时的 key value 对中的 key 值 向 memcache 或 redis 之类的 nosql 数据库（或者内存 hashmap）插入数据3、取数据时也用方法名 + 参数作为 key 向缓存数据源获取信息。 应用场景判断缓存是否存在dataList, err := dataRedis.Get(CacheKey).Result()if err == redis.Nil &#123; // 不存在redis key return &quot;&quot;, false&#125; else if err != nil &#123; log.Errorf(&quot;Get cache err, cache_key: %s, error: %s&quot;, CacheKey, err) return &quot;&quot;, false&#125; else &#123; // 缓存值为空 if dataList == &quot;&quot; &#123; return &quot;&quot;, false &#125;&#125;return dataList, true 对数据做处理CacheKey := &quot;key&quot;Data, isTrue := isGetDataCache(CacheKey)if isTrue &#123; // 从`redis`中获取数据直接返回 err := json.Unmarshal([]byte(Data), &amp;dataList) if err != nil &#123; log.Errorf(&quot;Json unmarshal datalist err:%s&quot;, err) return dataList &#125;&#125; else &#123; // 从db中获取数据 dataList = GetDataWhere(&quot;`deleted`=0 order by sort limit ? offset ?&quot;, limit, offset) // 更新redis缓存 err := dataRedis.Set(CacheKey, xutil.ToJSONString(dataList), 1*time.Minute).Err() if err != nil &#123; log.Errorf(&quot;Set rediscache error:%s&quot;, err) return dataList &#125;&#125;return dataList 思考写入数据是否立刻更新缓存如果需要立刻更新缓存的话，使用 findAndModify 获取最新结果并设置进缓存中，但这带来了一个弊端，有些并不是热数据，这时候放进了 redis 会导致占用内存，如果设置过快，redis 内存的使用量增长得非常快；好处需要与另一种方式对比才明显，另一种方式是写入数据后立刻删掉该缓存，等待有需要才再加载缓存，这样的好处是 redis 占用缓存不会过高，总是保留着热数据，弊端就是加载缓存读取从库的数据还是未同步的，这样导致脏数据，所以前者的直接更新保证了不会是脏数据。至于采取那种方式，要看使用场景，如果不需要最新的数据，最方便是删除掉该缓存就可以了，否则就需要立刻更新缓存数据，如果键数量特别多的情况下，可以设置过期时间短一些，尽快释放 redis 的内存占用。 读取 Set 和 SortedSet 数据缓存失效问题这种大数据集合，无法单个操作就可以判断其 key 存在还是该 key 是否有值。通常需要两个操作：加载和获取需要的数据。问题就出现在加载和获取的间隙中，这个间隙缓存刚好过期，就会出现数据错误的后果，我觉得最佳实践是这样: 保证在服务运行过程中，这些数据集合不会缓存过期。像我们使用排行榜的时候用到大量了 SortedSet，当时设置了 1 天就过期，这样导致出现排行榜数据出现不全的问题。又如 Set 保存着比赛名单的数据，发现 key 是存在，不再加载数据，准备判断某个项是否存在该 set 的时候，这个 set 就过期了，用sismember就会返回False，就无法判断这个 False 的意思是该数据项不存在该 set 里面还是该 set 的 key 已经过期了。 在项目中 Redis 做缓存 首先，对于数据缓存不是所有东西都缓存到 redis 就是好的，而是要针对一些改动不大或者访问率大的数据进行缓存来减少关系型数据库的压力。 redis 作为缓存使用，不作数据库用途，遵循以下规则：如果缓存没有数据，即加载数据到缓存，并会设置过期时间。 凡是可以用 String 保存的，尽量将数据用json.dumps之后再放进 String，如果需要 Set 和 SortedSet 就需要警惕缓存 key 刚好过期时候，会有一定读取错误的问题，这个无法避免。 对于一些不分页，不需要实时（需要多表查询）的列表，我们可以将列表结果缓存到 redis 中，设定一定缓存时间作为该数据的存活时间。用获取该列表的方法名作为 key，列表结果为 value；这种情况只试用于不经常更新且不需要实时的情况下。 不需要实时的，需要分页的列表：可以把分页的结果列表放到一个 map（key 为分页标识，value 为分页结果）中，然后将该 map 存到 redis 的 list 中（用该方法名为 key）。然后给该 list 设置一个缓存存活时间（用 expire）。这样通过方法名 lrange 出来就能获取存有分页列表的数据，遍历该 list，通过遍历 list 中 map 的 key 判断该分页数据是否在缓存内，是则返回，不存在则 rpush 进去。这种做法能解决比如 1-5 页的数据已经重新加载，而 6-10 页的数据依然是缓存的数据而导致脏数据的情况。","tags":["Go","Redis"],"categories":["技术加油站"]},{"title":"Windows 利器 - babun","path":"/2018/babun-windows-tool.html","content":"什么是 babunbabun 是 windows 上的一个第三方 shell，在这个 shell 上面你可以使用几乎所有 linux，unix 上面的命令，他几乎可以取代 windows 的 shell。用官方的题目说就是 A Windows shell you will love! babun 的几个特点使用 babun 无需管理员权限先进的安装包管理器 (类似于 linux 上面的 apt-get 或 yum)预先配置了 Cygwin 和很多插件拥有 256 色的兼容控制台HTTP(S) 的代理支持面向插件的体系结构可以使用它来配置你的 git集成了 oh-my-zsh自动升级支持 shell 编程，内置 VIM 等 babun 官网链接：&lt;http://babun.github.io/&gt; 什么是 cmdercmder 是 window 下的多标签命令行工具，可以方便的新建 cmd、cmd admin、powershell、powershell admin 多种命令行，设置很多，功能强大。 安装cmder 安装下载：http://cmder.net/ cmder 是开箱即用的软件就不在详述了，具体使用可参考官网说明。 babun 安装下载：http://babun.github.io/ 默认安装下载完成之后解压 babun，直接双击目录中 install.bat 脚本 (需管理员权限) 进行安装。几分钟之后自动安装完成，默认会被安装在%userprofile%\\.babun目录下。 自定义安装位置通过 cmd 命令行在执行 install.bat 时指定参数 &#x2F; t 或 &#x2F; target 指定安装的目录。 执行：babun.bat /t c:\\babun 安装好之后会在 c:\\babun 目录下生成一个. babun 的目录，babun 所有文件都在这个目录中。注意安装目录最好不要有空格，这是 cygwin 要求的。 测试安装成功安装完毕后，一般需要以下两个命令检查 babun check(用于判断环境是否正确)babun update(用于判断是否有新的更新包) babun 主要配置主题配置 字体下载（不安装会乱码） # clone(克隆git)git clone https://github.com/powerline/fonts.git --depth=1# install(运行安装脚本)cd fonts./install.sh# clean-up a bit(清楚克隆git文件)_cd ..rm -rf fonts 安装 [在~\\.local\\share\\fonts目录下找到DejaVu Sans Mono for Powerline字体] 把ZSH_THEME=”babun”设置为ZSH_THEME=”agnoster”（详情参考.zshrc配置） 修改~/.minttyrc # open ~/.minttyrcvi ~/.minttyrc# 把下面这段复制粘贴进去BoldAsFont=noColumns=90Rows=55Font=DejaVu Sans Mono for PowerlineFontHeight=10Transparency=lowForegroundColour=248,248,242BackgroundColour=27,29,30CursorColour=160,160,160Black=249,38,114Red=249,38,114Green=130,180,20Yellow=253,151,31Blue=38,139,210Magenta=140,84,254Cyan=86,194,214White=204,204,198BoldRed=255,89,149BoldBlack=80,83,84BoldGreen=183,235,70BoldYellow=254,237,108BoldBlue=98,173,227BoldMagenta=191,160,254BoldCyan=148,216,229BoldWhite=248,248,242Scrollbar=none babun 插件安装zsh-syntax-highlighting &amp;&amp; zsh-autosuggestionscd ~/.oh-my-zsh/custom/pluginsgit clone git://github.com/zsh-users/zsh-syntax-highlighting.gitgit clone git://github.com/zsh-users/zsh-autosuggestionsvi ~/.zshrc # add below to ~/.zshrcplugins=(zsh-syntax-highlighting zsh-autosuggestions) source ~/.zshrc or src autojumpcd ~/.oh-my-zsh/custom/pluginsgit clone git://github.com/joelthelion/autojump.gitcd autojump./install.pyvi ~/.zshrc # add below to ~/.zshrc[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; . ~/.autojump/etc/profile.d/autojump.shautoload -U compinit &amp;&amp; compinit -u 然后定位到 plugins&#x3D;(git) 的位置，将其修改成： plugins=(git autojump) .zshrc配置# Path to your oh-my-zsh installation.export ZSH=$HOME/.oh-my-zsh# Set name of the theme to load.# Look in ~/.oh-my-zsh/themes/ZSH_THEME=&quot;agnoster&quot;# DEFAULT_USER=&quot;$USER&quot;# Uncomment the following line if you want to disable marking untracked files# under VCS as dirty. This makes repository status check for large repositories# much, much faster.# DISABLE_UNTRACKED_FILES_DIRTY=&quot;true&quot;# The optional three formats: &quot;mm/dd/yyyy&quot;|&quot;dd.mm.yyyy&quot;|&quot;yyyy-mm-dd&quot;HIST_STAMPS=&quot;yyyy-mm-dd&quot;# Would you like to use another custom folder than $ZSH/custom?# ZSH_CUSTOM=/path/to/new-custom-folder# Which plugins would you like to load? (plugins can be found in ~/.oh-my-zsh/plugins/*)# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/# Example format: plugins=(rails git textmate ruby lighthouse)# Add wisely, as too many plugins slow down shell startup.plugins=(git autojump sh-autosuggestions zsh-syntax-highlighting wd web-search history history-substring-search)[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; . ~/.autojump/etc/profile.d/autojump.shautoload -U compinit &amp;&amp; compinit -usource ~/.bash_profile# Load zsh-syntax-highlighting.source ~/.oh-my-zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh## Load zsh-autosuggestions.source ~/.oh-my-zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh# User configurationexport PATH=$HOME/bin:/usr/local/bin:$PATH# export MANPATH=&quot;/usr/local/man:$MANPATH&quot;source $ZSH/oh-my-zsh.sh# Compilation flags# export ARCHFLAGS=&quot;-arch x86_64&quot;# ssh# export SSH_KEY_PATH=&quot;~/.ssh/dsa_id&quot;# Example aliasesalias zshconfig=&quot;mate ~/.zshrc&quot;alias ohmyzsh=&quot;mate ~/.oh-my-zsh&quot;alias cls=&#x27;clear&#x27;alias mysql=&#x27;/usr/local/opt/mysql/bin/mysql&#x27;alias mysqladmin=&#x27;/usr/local/opt/mysql/bin/mysqladmin&#x27;alias rake=&#x27;noglob rake&#x27;alias code=&quot;/Applications/Visual\\ Studio\\ Code.app/Contents/Resources/app/bin/code&quot;alias vi=&quot;vim&quot;alias vim=&quot;vim&quot;alias tmux=&quot;tmux -2&quot;alias ssh=&quot;ssh -X&quot;alias s=&quot;ssh -X&quot;alias md=&quot;mkdir -p&quot;alias rd=&quot;rmdir&quot;alias df=&quot;df -h&quot;alias mv=&quot;mv -i&quot;alias slink=&quot;link -s&quot;alias sed=&quot;sed -E&quot;alias l=&quot;ls -l&quot;alias la=&quot;ls -a&quot;alias ll=&quot;ls -la&quot;alias lt=&quot;ls -lhtrF&quot;alias l.=&quot;ls -lhtrdF .*&quot;alias grep=&quot;grep --color=auto&quot;alias cd..=&quot;cd ..&quot;alias cd...=&quot;cd ../..&quot;alias cd....=&quot;cd ../../..&quot;alias ..=&quot;cd ..&quot;alias ...=&quot;cd ../..&quot;alias ....=&quot;cd ../../..&quot;alias zb=&quot;cat /dev/urandom | hexdump -C | grep --color=auto \\&quot;ca fe\\&quot;&quot;alias mtr=&quot;/usr/local/sbin/mtr&quot;alias gs=&quot;git status&quot;alias gsm=&quot;git summary&quot;alias ga=&#x27;git add&#x27;alias gd=&#x27;git diff&#x27;alias gf=&#x27;git fetch&#x27;alias grv=&#x27;git remote -v&#x27;alias grb=&#x27;git rebase&#x27;alias gbr=&#x27;git branch&#x27;alias gpl=&quot;git pull&quot;alias gps=&quot;git push&quot;alias gco=&quot;git checkout&quot;alias gl=&quot;git log&quot;alias gc=&quot;git commit -m&quot;alias gm=&quot;git merge&quot;alias pro=&quot;proxychains4&quot;alias gb=&quot;go build&quot;alias -s go=vialias -s html=vialias -s rb=vialias -s py=vialias -s txt=vialias -s ex=vialias -s exs=vialias -s js=vialias -s json=vialias qas01=&#x27;ssh root@123.59.56.118 -p38390&#x27;alias rdp01=&#x27;ssh lei.li@rdp01.xiaoenai.net -p38390&#x27;alias rdp=&#x27;ssh lei.li@rdp01.xiaoenai.net -p38390&#x27;_COLUMNS=$(tput cols)_MESSAGE=&quot; FBI Warining &quot;y=$(( ( $_COLUMNS - $&#123;#_MESSAGE&#125; ) / 2 ))spaces=$(printf &quot;%-$&#123;y&#125;s&quot; &quot; &quot;)echo &quot; &quot;echo -e &quot;$&#123;spaces&#125;\\033[41;37;5m FBI WARNING \\033[0m&quot;echo &quot; &quot;_COLUMNS=$(tput cols)_MESSAGE=&quot;Ferderal Law provides severe civil and criminal penalties for&quot;y=$(( ( $_COLUMNS - $&#123;#_MESSAGE&#125; ) / 2 ))spaces=$(printf &quot;%-$&#123;y&#125;s&quot; &quot; &quot;)echo -e &quot;$&#123;spaces&#125;$&#123;_MESSAGE&#125;&quot;_COLUMNS=$(tput cols)_MESSAGE=&quot;the unauthorized reproduction, distribution, or exhibition of&quot;y=$(( ( $_COLUMNS - $&#123;#_MESSAGE&#125; ) / 2 ))spaces=$(printf &quot;%-$&#123;y&#125;s&quot; &quot; &quot;)echo -e &quot;$&#123;spaces&#125;$&#123;_MESSAGE&#125;&quot;_COLUMNS=$(tput cols)_MESSAGE=&quot;copyrighted motion pictures (Title 17, United States Code,&quot;y=$(( ( $_COLUMNS - $&#123;#_MESSAGE&#125; ) / 2 ))spaces=$(printf &quot;%-$&#123;y&#125;s&quot; &quot; &quot;)echo -e &quot;$&#123;spaces&#125;$&#123;_MESSAGE&#125;&quot;_COLUMNS=$(tput cols)_MESSAGE=&quot;Sections 501 and 508). The Federal Bureau of Investigation&quot;y=$(( ( $_COLUMNS - $&#123;#_MESSAGE&#125; ) / 2 ))spaces=$(printf &quot;%-$&#123;y&#125;s&quot; &quot; &quot;)echo -e &quot;$&#123;spaces&#125;$&#123;_MESSAGE&#125;&quot;_COLUMNS=$(tput cols)_MESSAGE=&quot;investigates allegations of criminal copyright infringement&quot;y=$(( ( $_COLUMNS - $&#123;#_MESSAGE&#125; ) / 2 ))spaces=$(printf &quot;%-$&#123;y&#125;s&quot; &quot; &quot;)echo -e &quot;$&#123;spaces&#125;$&#123;_MESSAGE&#125;&quot;_COLUMNS=$(tput cols)_MESSAGE=&quot;(Title 17, United States Code, Section 506).&quot;y=$(( ( $_COLUMNS - $&#123;#_MESSAGE&#125; ) / 2 ))spaces=$(printf &quot;%-$&#123;y&#125;s&quot; &quot; &quot;)echo -e &quot;$&#123;spaces&#125;$&#123;_MESSAGE&#125;&quot;echo &quot; &quot;","tags":["Windows","Shell"],"categories":["安利系列"]},{"title":"Python 之正则表达式","path":"/2018/python-regular-expression.html","content":"1. 什么是正则表达式正则表达式：也成为规则表达式，英文名称 Regular Expression，我们在程序中经常会缩写为 regex 或者 regexp，专门用于进行文本检索、匹配、替换等操作的一种技术。注意：正则表达式是一种独立的技术，并不是某编程语言独有的 正则表达式，是一种特殊的符号，这样的符号是需要解释才能使用的，也就是需要正则表达式引擎来进行解释，目前正则表达式的引擎主要分三种：DFA，NFA、POSIX NFA，有兴趣了正则表达式引擎的童鞋，可以自己查看资料 2. 正则表达式语法结构接下来，我们开始了解这样一个神秘的可以类似人类神经网络一样思考问题的技术的语法结构。注意：我们通过 python 程序进行测试，但是正则表达式的语法结构在各种语言环境中都是通用的。 2.1. 入门案例：了解正则表达式我们通过一个简单的案例入手：通常情况下，我们会验证用户输入的手机号码是否合法，是否 156&#x2F;186&#x2F;188 开头的手机号码，如果按照常规验证手段，就需要对字符串进行拆分处理，然后逐步匹配 重要提示：python 中提供了re模块，包含了正则表达式的所有功能，专门用于进行正则表达式的处理； 我们首先看一下，常规的手机号码验证过程 userphone = input(&quot;请输入手机号码：&quot;)# 验证用户手机号码是否合法的函数def validatePhone(phone): msg = &quot;提示信息：请输入手机号码&quot; # 判断输入的字符的长度是否合法 if len(phone) == 11: # 判断是否156/186/188开头 if phone.startswith(&quot;156&quot;) or phone.startswith(&quot;186&quot;) or phone.startswith(&quot;188&quot;): # 判断每一个字符都是数字 for num in phone: # isdigit()函数用于判断调用者是否数字 if not num.isdigit(): msg = &quot;不能包含非法字符&quot; return msg msg = &quot;手机号码合法&quot; else: msg = &quot;开头数字不合法&quot; else: msg = &quot;长度不合法&quot; return msg# 开始测试print(validatePhone(userphone)) 执行上面的代码，分别输入不同的手机号码，结果如下 请输入手机号码：188长度不合法 请输入手机号码：15568686868开头数字不合法 请输入手机号码：1566868686a不能包含非法字符 请输入手机号码：15688888888手机号码合法 我们再次使用正则表达式来改造这段程序注意：如果下面的程序中出现了一些语法不是很明白，没关系，后面会详细讲解 import re# 接收用户输入userphone = input(&quot;请输入手机号码&quot;)# 定义验证手机号码的函数def validatePhone(phone): # 定义正则表达式，Python中的正则表达式还是一个字符串，是以r开头的字符串 regexp = r&quot;^(156|186|188)\\d&#123;8&#125;$&quot; # 开始验证 if re.match(regexp, phone): return &quot;手机号码合法&quot; else: return &quot;手机号码只能156/186/188开头，并且每一个字符都是数字，请检查&quot;# 开始验证print(validatePhone(userphone)) 执行上面的代码，我们得到正常验证的结果，大家可以自己试一试。我们从这两套代码中，可以看出来，使用了正则表达式之后的程序变得非常简洁了，那保持好你的冲动和热情，让正则表达式来搞事吧 2.3. python 中的正则表达式模块 repython 提供的正则表达式处理模块 re，提供了各种正则表达式的处理函数 2.3.1 字符串查询匹配的函数： 函数 描述 re.match(reg, info) 用于在开始位置匹配目标字符串 info 中符合正则表达式 reg 的字符，匹配成功会返回一个 match 对象，匹配不成功返回 None re.search(reg, info) 扫描整个字符串 info，使用正则表达式 reg 进行匹配，匹配成功返回匹配的第一个 match 对象，匹配不成功返回 None re.findall(reg, info) 扫描整个字符串 info，将符合正则表达式 reg 的字符全部提取出来存放在列表中返回 re.fullmatch(reg, info) 扫描整个字符串，如果整个字符串都包含在正则表达式表示的范围中，返回整个字符串，否则返回 None re.finditer(reg, info) 扫描整个字符串，将匹配到的字符保存在一个可以遍历的列表中 参考官方 re.py 源代码如下： def match(pattern, string, flags=0): &quot;&quot;&quot;Try to apply the pattern at the start of the string, returning a match object, or None if no match was found.&quot;&quot;&quot; return _compile(pattern, flags).match(string)def fullmatch(pattern, string, flags=0): &quot;&quot;&quot;Try to apply the pattern to all of the string, returning a match object, or None if no match was found.&quot;&quot;&quot; return _compile(pattern, flags).fullmatch(string)def search(pattern, string, flags=0): &quot;&quot;&quot;Scan through string looking for a match to the pattern, returning a match object, or None if no match was found.&quot;&quot;&quot; return _compile(pattern, flags).search(string)def findall(pattern, string, flags=0): &quot;&quot;&quot;Return a list of all non-overlapping matches in the string. If one or more capturing groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result.&quot;&quot;&quot; return _compile(pattern, flags).findall(string)def finditer(pattern, string, flags=0): &quot;&quot;&quot;Return an iterator over all non-overlapping matches in the string. For each match, the iterator returns a match object. Empty matches are included in the result.&quot;&quot;&quot; return _compile(pattern, flags).finditer(string) 2.3.2 字符串拆分替换的函数： 函数 描述 re.split(reg, string) 使用指定的正则表达式 reg 匹配的字符，将字符串 string 拆分成一个字符串列表，如：re.split(r”\\s+”, info)，表示使用一个或者多个空白字符对字符串 info 进行拆分，并返回一个拆分后的字符串列表 re.sub(reg, repl, string) 使用指定的字符串 repl 来替换目标字符串 string 中匹配正则表达式 reg 的字符 参考官方源代码如下： def split(pattern, string, maxsplit=0, flags=0): &quot;&quot;&quot;Split the source string by the occurrences of the pattern, returning a list containing the resulting substrings. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list.&quot;&quot;&quot; return _compile(pattern, flags).split(string, maxsplit)def sub(pattern, repl, string, count=0, flags=0): &quot;&quot;&quot;Return the string obtained by replacing the leftmost non-overlapping occurrences of the pattern in string by the replacement repl. repl can be either a string or a callable; if a string, backslash escapes in it are processed. If it is a callable, it&#x27;s passed the match object and must return a replacement string to be used.&quot;&quot;&quot; return _compile(pattern, flags).sub(repl, string, count) 接下来，我们进入正则表达式干货部分 2.4. 正则表达式中的元字符在使用正则表达式的过程中，一些包含特殊含义的字符，用于表示字符串中一些特殊的位置，非常重要，我们先简单了解一下一些常用的元字符 元字符 描述 ^ 表示匹配字符串的开头位置的字符 $ 表示匹配字符串的结束位置的字符 . 表示匹配任意一个字符 \\d 匹配一个数字字符 \\D 匹配一个非数字字符 \\s 匹配一个空白字符 \\S 匹配一个非空白字符 \\w 匹配一个数字 &#x2F; 字母 &#x2F; 下划线中任意一个字符 \\W 匹配一个非数字字母下划线的任意一个字符 \\b 匹配一个单词的边界 \\B 匹配不是单词的开头或者结束位置 上干货：代码案例 # 导入正则表达式模块import re# 定义测试文本字符串，我们后续在这段文本中查询数据msg1 = &quot;&quot;&quot;Python is an easy to learn, powerful programming language.It has efficient high-level data structures and a simple but effective approach to object-oriented programming.Python’s elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms.&quot;&quot;&quot;msg2 = &quot;hello&quot;msg3 = &quot;hello%&quot;# 定义正则表达式，匹配字符串开头是否为pythonregStart = r&quot;efficient&quot;# 从字符串开始位置匹配，是否包含符合正则表达式的内容，返回匹配到的字符串的Match对象print(re.match(regStart, msg1))# 扫描整个字符串，是否包含符合正则表达式的内容，返回匹配到的第一个字符串的Match对象print(re.search(regStart, msg1))# 扫描整个字符串，是否包含符合正则表达式的内容，返回匹配到的所有字符串列表print(re.findall(regStart, msg1))# 扫描整个字符串，是否包含符合正则表达式的内容，返回匹配到的字符串的迭代对象for r in re.finditer(regStart, msg1): print(&quot;-&gt;&quot;+ r.group())# 扫描整个字符串，是否包含在正则表达式匹配的内容中，是则返回整个字符串，否则返回Noneprint(re.fullmatch(r&quot;\\w*&quot;, msg2))print(re.fullmatch(r&quot;\\w*&quot;, msg3)) 上述代码执行结果如下： ~ None~&lt;sre.SRE_Match object; span&#x3D;(66, 75), match&#x3D;’efficient’&gt;~[‘efficient’]~-&gt;efficient~&lt;sre.SRE_Match object; span&#x3D;(0, 5), match&#x3D;’hello’&gt;~None 2.5. 正则表达式中的量词正则表达式中的量词，是用于限定数量的特殊字符 量词 描述 x* 用于匹配符号 * 前面的字符出现 0 次或者多次 x+ 用于匹配符号 + 前面的字符出现 1 次或者多次 x？ 用于匹配符号？前面的字符出现 0 次或者 1 次 x{n} 用于匹配符号 {n} 前面的字符出现 n 次 x{m,n} 用于匹配符号 {m,n} 前面的字符出现至少 m 次，最多 n 次 x{n,} 用于匹配符号 {n,} 前面的字符出现至少 n 次 接上代码干货： # 导入正则表达式模块import re# 定义测试文本字符串，我们后续在这段文本中查询数据msg1 = &quot;&quot;&quot;goodgoodstudy!,dooodooooup&quot;&quot;&quot;# 匹配一段字符串中出现单词o字符0次或者多次的情况print(re.findall(r&quot;o*&quot;, msg1))# 匹配一段字符串中出现单词o字符1次或者多次的情况print(re.findall(r&quot;o+&quot;, msg1))# 匹配一段字符串中出现单词o字符0次或者1次的情况print(re.findall(r&quot;o?&quot;, msg1))# 匹配字符串中连续出现2次字符o的情况print(re.findall(r&quot;o&#123;2&#125;&quot;, msg1))# 匹配字符串中连续出现2次以上字符o的情况print(re.findall(r&quot;o&#123;2,&#125;&quot;, msg1))# 匹配字符串中连续出现2次以上3次以内字符o的情况print(re.findall(r&quot;o&#123;2,3&#125;&quot;, msg1)) 上述代码大家可以自行尝试并分析结果。执行结果如下： 2.6. 正则表达式中的范围匹配在正则表达式中，针对字符的匹配，除了快捷的元字符的匹配，还有另一种使用方括号进行的范围匹配方式，具体如下： 范围 描述 [0-9] 用于匹配一个 0~9 之间的数字，等价于 \\ d [^0-9] 用于匹配一个非数字字符，等价于 \\ D [3-6] 用于匹配一个 3~6 之间的数字 [a-z] 用于匹配一个 a~z 之间的字母 [A-Z] 用于匹配一个 A~Z 之间的字母 [a-f] 用于匹配一个 a~f 之间的字母 [a-zA-Z] 用于匹配一个 a~z 或者 A-Z 之间的字母，匹配任意一个字母 [a-zA-Z0-9] 用于匹配一个字母或者数字 [a-zA-Z0-9_] 用于匹配一个字母或者数字或者下划线，等价于 \\ w [^a-zA-Z0-9_] 用于匹配一个非字母或者数字或者下划线，等价于 \\ W 注意：不要使用 [0-120] 来表示 0~120 之间的数字，这是错误的 整理测试代码如下： # 引入正则表达式模块import remsg = &quot;Hello, The count of Today is 800&quot;# 匹配字符串msg中所有的数字print(re.findall(r&quot;[0-9]+&quot;, msg))# 匹配字符串msg中所有的小写字母print(re.findall(r&quot;[a-z]+&quot;, msg))# 匹配字符串msg中所有的大写字母print(re.findall(r&quot;[A-Z]+&quot;, msg))# 匹配字符串msg中所有的字母print(re.findall(r&quot;[A-Za-z]+&quot;, msg)) 上述代码执行结果如下： [‘800’][‘ello’, ‘he’, ‘count’, ‘of’, ‘oday’, ‘is’][‘H’, ‘T’, ‘T’][‘Hello’, ‘The’, ‘count’, ‘of’, ‘Today’, ‘is’] 2.7. 正则表达式中的分组正则表达式主要是用于进行字符串检索匹配操作的利器在一次完整的匹配过程中，可以将匹配到的结果进行分组，这样就更加的细化了我们对匹配结果的操作正则表达式通过圆括号 () 进行分组，以提取匹配结果的部分结果 常用的两种分组： 分组 描述 (expression) 使用圆括号直接分组；正则表达式本身匹配的结果就是一个组，可以通过 group() 或者 group(0) 获取；然后正则表达式中包含的圆括号就是按照顺序从 1 开始编号的小组 (?Pexpression) 使用圆括号分组，然后给当前的圆括号表示的小组命名为 name，可以通过 group(name) 进行数据的获取 废话少说，上干货： # 引入正则表达式模块import re# 用户输入座机号码，如&quot;010-6688465&quot;phone = input(&quot;请输入座机号码：&quot;)# 1.进行正则匹配,得到Match对象，对象中就包含了分组信息res1 = re.search(r&quot;^(\\d&#123;3,4&#125;)-(\\d&#123;4,8&#125;)$&quot;, phone)# 查看匹配结果print(res1)# 匹配结果为默认的组，可以通过group()或者group(0)获取print(res1.group())# 获取结果中第一个括号对应的组数据：处理区号print(res1.group(1))# 获取结果中第二个括号对应的组数据：处理号码print(res1.group(2))# 2.进行正则匹配,得到Match对象，对象中就包含了命名分组信息res2 = re.search(r&quot;^(?P&lt;nstart&gt;\\d&#123;3,4&#125;)-(?P&lt;nend&gt;\\d&#123;4,8&#125;)$&quot;, phone)# 查看匹配结果print(res2)# 匹配结果为默认的组，可以通过group()或者group(0)获取print(res2.group(0))# 通过名称获取指定的分组信息：处理区号print(res2.group(&quot;nstart&quot;))# 通过名称获取指定分组的信息：处理号码print(res2.group(&quot;nend&quot;)) 上述代码就是从原始字符串中，通过正则表达式匹配得到一个结果，但是使用了分组之后，就可以将结果数据通过分组进行细化处理，执行结果如下： 请输入座机号码：021-6565789&lt;_sre.SRE_Match object; span&#x3D;(0, 11), match&#x3D;’021-6565789’&gt;021-65657890216565789&lt;_sre.SRE_Match object; span&#x3D;(0, 11), match&#x3D;’021-6565789’&gt;021-65657890216565789 2.8. 正则表达式中的特殊用法使用分组的同时，会有一些特殊的使用方式如下： 表达式 描述 (?:expression) 作为正则表达式的一部分，但是匹配结果丢弃 (?&#x3D;expression) 匹配 expression 表达式前面的字符，如 “How are you doing” , 正则 “(?.+(?&#x3D;ing))” 这里取 ing 前所有的字符，并定义了一个捕获分组名字为 “txt” 而 “txt” 这个组里的值为 “How are you do” (?&lt;&#x3D;expression) 匹配 expression 表达式后面的字符，如 “How are you doing” 正则 “(?(?&lt;&#x3D;How).+)”这里取”How”之后所有的字符，并定义了一个捕获分组名字为”txt”而”txt”这个组里的值为” are you doing”; (?!expression) 匹配字符串后面不是 expression 表达式字符，如 “123abc” 正则 “\\d{3}(?!\\d)” 匹配 3 位数字后非数字的结果 (?&lt;!expression) 匹配字符串前面不是 expression 表达式字符，如 “abc123” 正则 “(?&lt;![0-9])123”匹配”123”前面是非数字的结果也可写成”(?!&lt;\\d)123” 2.9 正则表达式的贪婪模式和懒惰模式在某些情况下，我们匹配的字符串出现一些特殊的规律时，就会出现匹配结果不尽如人意的意外情况如：在下面的字符串中，将 div 标签中的所有内容获取出来 &lt;div&gt;内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2&lt;/div&gt; 此时，我们想到的是，使用 作为关键信息进行正则表达式的定义，如下 regexp = r&quot;&lt;div&gt;.*&lt;/div&gt;&quot; 本意是使用上述代码来完成 div 开始标签和结束标签之间的内容匹配，但是，匹配的结果如下 &lt;div&gt; [内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2] &lt;/div&gt; 我们可以看到，上面匹配的结果，是将字符串开头的 标签和字符串结束的 当成了匹配元素，对包含在中间的内容直接进行了匹配，也就得到了我们期望之外的结果： 内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2 上述就是我们要说的正则表达式的第一种模式：贪婪模式贪婪模式：正则表达式匹配的一种模式，速度快，但是匹配的内容会从字符串两头向中间搜索匹配（比较贪婪~），一旦匹配选中，就不继续向字符串中间搜索了，过程如下： 开始：&lt;div&gt;内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2&lt;/div&gt;第一次匹配：【&lt;div&gt;内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2&lt;/div&gt;】第二次匹配&lt;div&gt;【内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2】&lt;/div&gt;匹配到正则中需要的结果，不再继续匹配，直接返回匹配结果如下：内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2 明显贪婪模式某些情况下，不是我们想要的，所以出现了另一种模式：懒惰模式懒惰模式：正则表达式匹配的另一种模式，会首先搜索匹配正则表达式开始位置的字符，然后逐步向字符串的结束位置查找，一旦找到匹配的就返回，然后接着查找 regexp = r&quot;&lt;div&gt;.*?&lt;/div&gt;&quot; 开始：&lt;div&gt;内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2&lt;/div&gt;第一次匹配：【&lt;div&gt;】内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2&lt;/div&gt;第二次匹配【&lt;div&gt;内容1&lt;/div&gt;】&lt;p&gt;这本来是不需要的内容&lt;/p&gt;&lt;div&gt;内容2&lt;/div&gt;匹配到正则中需要的结果：内容1继续向后查找第三次匹配&lt;div&gt;内容1&lt;/div&gt;【&lt;p&gt;这本来是不需要的内容&lt;/p&gt;】&lt;div&gt;内容2&lt;/div&gt;第四次匹配&lt;div&gt;内容1&lt;/div&gt;&lt;p&gt;这本来是不需要的内容&lt;/p&gt;【&lt;div&gt;内容2&lt;/div&gt;】匹配到正则中需要的结果：内容2查找字符串结束！ 正则表达式匹配的两种模式：贪婪模式、懒惰模式贪婪模式：从目标字符串的两头开始搜索，一次尽可能多的匹配符合条件的字符串，但是有可能会匹配到不需要的内容，正则表达式中的元字符、量词、范围等都模式是贪婪匹配模式，使用的时候一定要注意分析结果，如：&lt;div&gt;.*&lt;/div&gt;就是一个贪婪模式，用于匹配 和 之间所有的字符懒惰模式：从目标字符串按照顺序从头到位进行检索匹配，尽可能的检索到最小范围的匹配结果，语法结构是在贪婪模式的表达式后面加上一个符号? 即可，如&lt;div&gt;.*?&lt;/div&gt;就是一个懒惰模式的正则，用于仅仅匹配最小范围的 和 之间的内容 不论贪婪模式还是懒惰模式，都有适合自己使用的地方，大家一定要根据实际需求进行解决方案的确定 转载: https://www.imooc.com/article/22158","tags":["Python"],"categories":["技术加油站"]},{"path":"/index.html","content":"近期日程开源项目无任何盈利目的，所有项目均会在闲暇之余维护，开源项目如有任何问题建议提交 issue，紧急问题（包括但不限于安全缺陷等问题）请发送邮件 Open Source Project &nbsp; &nbsp; 暂无开源计划，先好好工作，努力学习 近期动态平时的所见所闻或是接触到的知识点，不系统，比较凌乱，只做记录或是分享详情见：#issues"},{"path":"/about/index.html","content":"读一些无用的书，做一些无用的事，花一些无用的时间，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。文章友链关于留言 Hey 👋, I’m LLIEI0X👨🏻‍💻 一个工作是后端但正在学习前端，平常还兼职安全和运维的开发者👾 Gopher &amp; 学了又忘的 Rustacean@lliei0x &amp; @lliei-x.创始人 &amp; 软件工程师@liei.cc.服主 &amp; 运维 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;🎉 感谢：感谢 @LLIEI0X 和 @LIEI.CC 为我提供网络与计算基础设施"},{"path":"/friends/index.html","content":"读一些无用的书，做一些无用的事，花一些无用的时间，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。文章友链关于留言 友人帐，我们要去浪迹天涯 yx-hh 如何交换友链？ 先友后链，在我们有一定了解了之后才可以交换友链，除此之外，您的网站还应满足以下全部条件： 合法的、非营利性、无商业广告、无木马植入 有实质性原创内容的 HTTPS 站点，发布过至少 5 篇原创文章，内容题材不限 有独立域名，非免费域名 博客已运行至少半年，非刚搭建好"},{"path":"/more/index.html","content":"读一些无用的书，做一些无用的事，花一些无用的时间，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。文章友链关于留言"},{"path":"/notes/index.html","content":"前言日常接触到的知识点，不系统，比较凌乱，只作记录，整理后转至 WIKI (专栏)当我说出「你」这个字，我的意思是，一百个宇宙。"},{"title":"数据库","path":"/notes/database/index.html","content":"trdsqltrdsql一个可以在CSV和LTSV上执行SQL查询的工具 https://github.com/noborus/trdsqlhttps://github.com/noborus/trdsql trdsql 使用示例./trdsql -oat -config config.json &quot;select * from table_example where id=1&quot; config.json 配置示例&#123; &quot;db&quot;: &quot;mdb&quot;, &quot;database&quot;: &#123; &quot;sdb&quot;: &#123; &quot;driver&quot;: &quot;sqlite3&quot;, &quot;dsn&quot;: &quot;&quot; &#125;, &quot;pdb&quot;: &#123; &quot;driver&quot;: &quot;postgres&quot;, &quot;dsn&quot;: &quot;user=test dbname=test&quot; &#125;, &quot;mdb&quot;: &#123; &quot;driver&quot;: &quot;mysql&quot;, &quot;dsn&quot;: &quot;test:test@tcp(ubuntu.wsl:4000)/example?charset=utf8mb4&quot; &#125; &#125;&#125;"},{"title":"Docker","path":"/notes/docker/index.html","content":"容器技术四个组成部分 镜像 包含虚拟运行环境的文件包，是一堆文件的合集，服务在该系统之上能够运行起来。docker 镜像采用了分层架构。 容器 镜像的运行状态，用来隔离虚拟环境的基础设施。主要包含：镜像、运行环境、指令集 网络 网络是应用之间通讯的媒介。 数据卷 应用肯定会涉及到数据持久化操作，数据卷就是用于宿主机和容器之间共享或者持久化。三点技术 Namespace 命名空间 作用是隔离 Control Groups 控制组 作用是限制计算机资源的使用 Union File System 联合文件系统 作用是实现不同目录挂载到同一目录 docker logs－查看 docker 容器日志命令格式： docker logs [OPTIONS] CONTAINER Options: --details 显示更多的信息 -f, --follow 跟踪实时日志 --since string 显示自某个timestamp之后的日志，或相对时间，如42m（即42分钟） --tail string 从日志末尾显示多少行日志， 默认是all -t, --timestamps 显示时间戳 --until string 显示自某个timestamp之前的日志，或相对时间，如42m（即42分钟） 例子：查看指定时间后的日志，只显示最后 100 行： docker logs -f -t --since=&quot;2018-02-08&quot; --tail=100 CONTAINER_ID 查看最近 30 分钟的日志: docker logs --since 30m CONTAINER_ID 查看某时间之后的日志： docker logs -t --since=&quot;2018-02-08T13:23:37&quot; CONTAINER_ID 查看某时间段日志： docker logs -t --since=&quot;2018-02-08T13:23:37&quot; --until &quot;2018-02-09T12:23:37&quot; CONTAINER_ID"},{"title":"Git","path":"/notes/git/index.html","content":"git commit emoji 使用指南目录 commit 格式 emoji 指南 如何在命令行中显示 emoji 执行 git commit 时使用 emoji 为本次提交打上一个 “标签”, 使得此次 commit 的主要工作得以凸现，也能够使得其在整个提交历史中易于区分与查找。 例如，gitmoji commit 格式git commit 时，提交信息遵循以下格式： :emoji1: :emoji2: 不超过 50 个字的摘要，首字母大写，使用祈使语气，句末不要加句号提交信息主体引用相关 issue 或 PR 编号 &lt;#110&gt; 初次提交示例： git commit -m &quot;:tada: Initialize Repo&quot; emoji 指南 emoji emoji 代码 commit 说明 🎉 (庆祝) :tada: 初次提交 🆕 (全新)✨ (火花) :new: :sparkles: 引入新功能 feature 🔖 (书签) :bookmark: 发行&#x2F;版本标签 🐛 (bug) :bug: 修复 bug 🚑 (急救车) :ambulance: 重要补丁 🌐 (地球) :globe_with_meridians: 国际化与本地化 💄 (口红) :lipstick: 更新 UI 和样式文件 🎬 (场记板) :clapper: 更新演示&#x2F;示例 🚨 (警车灯) :rotating_light: 移除 linter 警告 🔧 (扳手) :wrench: 修改配置文件 ➕ (加号) :heavy_plus_sign: 增加一个依赖 ➖ (减号) :heavy_minus_sign: 减少一个依赖 ⬆️ (上升箭头) :arrow_up: 升级依赖 ⬇️ (下降箭头) :arrow_down: 降级依赖 ⚡ (闪电)🐎 (赛马) :zap: :racehorse: 提升性能 📈 (上升趋势图) :chart_with_upwards_trend: 添加分析或跟踪代码 🚀 (火箭) :rocket: 部署功能 ✅ (白色复选框) :white_check_mark: 增加测试 📝 (备忘录)📖 (书) :memo::book: 撰写文档 🔨 (锤子) :hammer: 重大重构 🎨 (调色板) :art: 改进代码结构&#x2F;代码格式 🔥 (火焰) :fire: 移除代码或文件 ✏️ (铅笔) :pencil2: 修复 typo 🚧 (施工) :construction: 工作进行中 🗑️ (垃圾桶) :wastebasket: 废弃或删除 ♿ (轮椅) :wheelchair: 可访问性 👷 (工人) :construction_worker: 添加 CI 构建系统 💚 (绿心) :green_heart: 修复 CI 构建问题 🔒 (锁) :lock: 修复安全问题 🐳 (鲸鱼) :whale: Docker 相关工作 🍎 (苹果) :apple: 修复 macOS 下的问题 🐧 (企鹅) :penguin: 修复 Linux 下的问题 🏁 (旗帜) :checkered_flag: 修复 Windows 下的问题 🔀 (交叉箭头) :twisted_rightwards_arrows: 分支合并 🤖 (机器人) :robot: 修复 Android 下的问题 🍏 (苹果) :green_apple: 修复 IOS下的问题 📌 (图钉) :pushpin: 依赖固定到特定版本 ♻️ (回收) :recycle: 添加 CI 构建系统 📦(包裹) :package: 更新编译文件或Package 👽 (外星人) :alien: 由于外部API的更改而更新了代码 🚚 (卡车) :truck: 移动或重命名文件 📄(文件) :page_facing_up: 添加或更新 Licence 💥 (隆隆声) :boom: 引入重大变化 🍱 (便当) :bento: 添加或更新 Assets 👌(OK) :ok_hand: 由于代码评审更改而更新代码 ♿ (轮椅) :wheelchair: 提高可访问性 💡 (电灯泡) :bulb: 记录源代码 🍻 (啤酒) :beers: 醉醺醺地编写代码 💬 (发言) :speech_balloon: 更新文本和文字 🗃️ (文件盒) :card_file_box: 执行与数据库相关的更改 🔊 (巨大声响) :loud_sound: 添加日志 🔇 (静音) :mute: 移除日志 👥 (轮廓半身像) :busts_in_silhouette: 添加贡献者 🚸 (儿童通过) :children_crossing: 提高用户体验&#x2F;可用性 🏗️ (房屋) :building_construction: 使建筑变化 📱 (苹果手机) :iphone: 致力于响应式设计 🤡 (小丑) :clown_face: Mock 相关 🥚(彩蛋) :egg: 加入一个复活节彩蛋 🙈(非礼勿视) :see_no_evil: 添加或更新 .gitignore 文件 📸 (相机) :camera_flash: 添加或更新快照 ⚗️ (蒸馏器) :alembic: 尝试新事物 🔍 (放大镜) :mag: SEO 提升 ☸️ (达摩车轮) :wheel_of_dharma: Kubernetes 相关工作 🏷️ (标签) :label: 添加或更新 types (Flow, TypeScript) 🌱 (种子) :seedling: 添加或更新种子文件 🚩 (旗帜) :triangular_flag_on_post: 添加、更新或删除功能标志 💫 (头昏眼花) :dizzy: 添加或更新动画和转换 emoji-cheat-sheet&nbsp;-&nbsp;汇总 关于其它个性化的 emoji 汇总网站http://www.webpagefx.com/tools/emoji-cheat-sheet/ 如何在命令行中显示 emoji默认情况下，在命令行中并不会显示出 emoji, 仅显示 emoji 代码。不过可以使用 emojify 使得在命令行也可显示 emoji, 它是一个 shell 脚本，安装与使用都很简单，在 这里 查看如何安装与使用。"},{"title":"Kubernetes","path":"/notes/kubernetes/index.html","content":"K8S 的架构像大多数的分布式系统，K8S 集群至少需要一个主节点 Master 和多个计算节点 NodeMaster（控制节点）由三个紧密协作的独立组件组合而成负责 API 服务的 kube-apiserver负责调度的 kube-scheduler负责容器编排的 kube-controller-manager整个集群的持久化数据，则由 kube-apiserver 处理后保存在 Etcd 中Node（计算节点）最核心的是 kubelet 的组件，具备以下功能负责同容器运行时（比如 Docker 项目）打交道。而这个交互所依赖的，是一个称作 CRI（Container Runtime Interface）的远程调用接口，这个接口定义了容器运行时的各项核心操作通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互。这个插件，是 K8S 项目用来管理 GPU 等宿主机物理设备的主要组件调用网络插件和存储插件为容器配置网络和持久化存储。这两个插件与 kubelet 进行交互的接口，分别是 CNI（Container Networking Interface）和 CSI（Container Storage Interface）补充：K8S 项目并不关心你部署的是什么容器运行时、使用的什么技术实现，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 CRI 接入到 K8S 项目当中；而具体的容器运行时，比如 Docker 项目，则一般通过 OCI 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 CRI 请求翻译成对 Linux 操作系统的调用（操作 Linux Namespace 和 Cgroups 等） Prometheus、Metrics Server 与 K8S 监控体系Prometheus 项目工作的核心，是使用 Pull （抓取）的方式去搜集被监控对象的 Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，以便后续可以按照时间进行检索；其主要的特点如下： 多维度的数据模型：由指标名称和键 &#x2F; 值对标签标识的时间序列数据来组成多维的数据模型。 灵活的查询语言：在 Prometheus 中使用强大的查询语言 PromSQL 来进行查询。 不依赖分布式存储，Prometheus 单个节点也可以直接工作，支持本地存储（TSDB）和远程存储的模式。 服务端采集数据：Prometheus 基于 HTTP pull 方式去对不同的端采集时间序列数据。 客户端主动推送：支持通过 PushGateway 组件主动推送时间序列数据。 Prometheus 作用和工作方式，如下图 Prometheus 剩下的组件就是用来配合这套机制的运行 Prometheus Server：Prometheus 服务端，用于收集指标和存储时间序列数据，并提供一系列的查询和设置接口。 Client Libraries：客户端库，用于帮助需要监控采集的服务暴露 metrics handler 给 Prometheus server，直接调用 promhttp 暴露了一个 metrics 接口。 Push Gateway：推送网关，Prometheus 服务端仅支持 HTTP pull 的采集方式，而有一些指存在的时间短，Prometheus 来 pull 前就结束了。又或是该类指标，就是要客户端自行上报的，这时候就可以采用 Push Gateway 的方式，客户端将指标 push 到 Push Gateway，再由 Prometheus Server 从 Pushgateway 上 pull Exporters：用于暴露已有的第三方服务的 metrics 给 Prometheus Server Alertmanager：可以根据 Metrics 信息灵活地设置报警，从 Prometheus server 端接收到 alerts 后，会进行去重，分组，然后路由到对应的 Receiver，发出报警 Grafana：对外暴露出的、可以灵活配置的监控数据可视化界面 按照 Metrics 数据的来源，来对 K8S 的监控体系做一个汇总： 第一种 Metrics，是宿主机的监控数据。这部分数据的提供，需要借助一个由 Prometheus 维护的Node Exporter 工具 第二种 Metrics，是来自于 Kubernetes 的 API Server、kubelet 等组件的 &#x2F;metrics API。除了常规的 CPU、内存的信息外，这部分信息还主要包括了各个组件的核心监控指标。比如，对于 API Server 来说，它就会在 &#x2F;metrics API 里，暴露出各个 Controller 的工作队列 第三种 Metrics，是 Kubernetes 相关的监控数据。这部分数据，一般叫作 Kubernetes 核心监控数据（core metrics）。这其中包括了 Pod、Node、容器、Service 等主要 Kubernetes 核心概念的 Metrics。 其中，容器相关的 Metrics 主要来自于 kubelet 内置的 cAdvisor 服务。在 kubelet 启动后，cAdvisor 服务也随之启动，而它能够提供的信息，可以细化到每一个容器的 CPU 、文件系统、内存、网络等资源的使用情况。 需要注意的是，这里提到的 Kubernetes 核心监控数据，其实使用的是 Kubernetes 的一个非常重要的扩展能力，叫作 Metrics Server。 声明式 API 和 K8S 控制器 声明式 API 是 Kubernetes 项目编排能力“赖以生存”的核心所在 首先，所谓“声明式”，指的就是我只需要提交一个定义好的 API 对象来“声明”，我所期望的状态是什么样子 其次，“声明式 API”允许有多个 API 写端，以 PATCH 的方式对 API 对象进行修改，而无需关心本地原始 YAML 文件的内容 最后，也是最重要的，有了上述两个能力，Kubernetes 项目才可以基于对 API 对象的增、删、改、查，在完全无需外界干预的情况下，完成对“实际状态”和“期望状态”的调谐（Reconcile）过程 实际运用项目： Istio 项目使用的，是 K8S 中的一个非常重要的功能，叫作 Dynamic Admission Control（动态入场控制），也叫作：Initializer（初始化器）。提供了一种“热插拔”式的 Admission 机制 Kubernetes 控制器 Kubernetes控制器的进化之旅 https://leeif.me/2020/kubernetes-operator.htmlhttps://liei.cc/2020/kubernetes-operator.html GPU 在容器云中的方案及使用核心功能模块: GPU Share Scheduler Extender: 利用 Kubernetes 的调度器扩展机制，负责在全局调度器 Filter 和 Bind 的时候判断节点上单个 GPU 卡是否能够提供足够的 GPU Mem，并且在 Bind 的时刻将 GPU 的分配结果通过 annotation 记录到 Pod Spec 以供后续 Filter 检查分配结果。 GPU Share Device Plugin: 利用 Device Plugin 机制，在节点上被 Kubelet 调用负责 GPU 卡的分配，依赖 scheduler Extender 分配结果执行。 具体流程： 资源上报 GPU Share Device Plugin利用nvml库查询到GPU卡的数量和每张GPU卡的显存， 通过 ListAndWatch() 将节点的GPU总显存（数量 显存）作为另外 Extended Resource 汇报给 Kubelet； Kubelet 进一步汇报给 Kubernetes API Server 扩展调度 GPU Share Scheduler Extender 可以在分配 gpu-mem 给 Pod 的同时将分配信息以 annotation 的形式保留在 Pod spec 中，并且在过滤时刻根据此信息判断每张卡是否包含足够可用的 gpu-mem 分配。 节点上运行 当Pod和节点绑定的事件被Kubelet接收到后，Kubelet就会在节点上创建真正的Pod实体，在这个过程中, Kubelet会调用GPU Share Device Plugin的 Allocate 方法, Allocate 方法的参数是Pod申请的gpu-mem。而在 Allocate 方法中，会根据GPU Share Scheduler Extender的调度决策运行对应的Pod"},{"title":"Linux","path":"/notes/linux/index.html","content":"Systemctl 守护进程Unit 介绍 Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。 systemctl list-units 命令可以查看当前系统的所有 Unit # 列出正在运行的 Unitsystemctl list-units# 列出所有Unit，包括没有找到配置文件的或者启动失败的systemctl list-units --all# 列出所有没有运行的 Unitsystemctl list-units --all --state=inactive# 列出所有加载失败的 Unitsystemctl list-units --failed# 列出所有正在运行的、类型为 service 的 Unitsystemctl list-units --type=service systemctl status 命令用于查看系统状态和单个 Unit 的状态 # 显示系统状态systemctl status# 显示单个 Unit 的状态sysystemctl status bluetooth.service# 显示远程主机的某个 Unit 的状态systemctl -H root@rhel7.example.com status httpd.service除了 status 命令，systemctl 还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。# 显示某个 Unit 是否正在运行systemctl is-active application.service# 显示某个 Unit 是否处于启动失败状态systemctl is-failed application.service# 显示某个 Unit 服务是否建立了启动链接systemctl is-enabled application.service 最常用的是下面这些命令，用于启动和停止 Unit（主要是 service） # 立即启动一个服务sudo systemctl start apache.service# 立即停止一个服务sudo systemctl stop apache.service# 重启一个服务sudo systemctl restart apache.service# 杀死一个服务的所有子进程sudo systemctl kill apache.service# 重新加载一个服务的配置文件sudo systemctl reload apache.service# 重载所有修改过的配置文件sudo systemctl daemon-reload# 显示某个 Unit 的所有底层参数systemctl show httpd.service# 显示某个 Unit 的指定属性的值systemctl show -p CPUShares httpd.service# 设置某个 Unit 的指定属性sudo systemctl set-property httpd.service CPUShares=500 Unit 的配置文件 Systemd 默认从目录 /etc/systemd/system/ 读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录 /usr/lib/systemd/system/，真正的配置文件存放在那个目录 systemctl daemon-reload 重新加载配置文件 systemctl enable 激活开机启动 systemctl disable 撤销开机启动 Unit 配置文件示例# vi /lib/systemd/system/example.service[Unit]Description=exampleAfter=network.target[Install]WantedBy=multi-user.target[Service]Type=simpleUser=rootGroup=rootRestart=always# Prevent writes to /usr, /boot, and /etcProtectSystem=full# Doesn&#x27;t yet work properly with SELinux enabled# NoNewPrivileges=truePrivateDevices=trueWorkingDirectory=/optExecStart=/opt/example --http-port=:8080 --env=pro --apollo-appid=example --apollo-url=http://apollo.example.com:80 --apollo-cluster=exampleKillMode=processKillSignal=SIGTERM# Don&#x27;t want to see an automated SIGKILL everSendSIGKILL=noRestartSec=1sUMask=007------------------------- 守护进程日志管理Unit 日志常用操作# 查看所有日志（默认情况下 ，只保存本次启动的日志）sudo journalctl# 查看内核日志（不显示应用日志）sudo journalctl -k# 查看系统本次启动的日志sudo journalctl -bsudo journalctl -b -0# 查看上一次启动的日志（需更改设置）sudo journalctl -b -1# 查看指定时间的日志sudo journalctl --since=&quot;2012-10-30 18:17:16&quot;sudo journalctl --since &quot;20 min ago&quot;sudo journalctl --since yesterdaysudo journalctl --since &quot;2015-01-10&quot; --until &quot;2015-01-11 03:00&quot;sudo journalctl --since 09:00 --until &quot;1 hour ago&quot;# 显示尾部的最新10行日志sudo journalctl -n# 显示尾部指定行数的日志sudo journalctl -n 20# 实时滚动显示最新日志sudo journalctl -f# 查看指定服务的日志sudo journalctl /usr/lib/systemd/systemd# 查看指定进程的日志sudo journalctl _PID=1# 查看某个路径的脚本的日志sudo journalctl /usr/bin/bash# 查看指定用户的日志sudo journalctl _UID=33 --since today# 查看某个 Unit 的日志sudo journalctl -u nginx.servicesudo journalctl -u nginx.service --since today# 实时滚动显示某个 Unit 的最新日志sudo journalctl -u nginx.service -f# 合并显示多个 Unit 的日志journalctl -u nginx.service -u php-fpm.service --since today# 查看指定优先级（及其以上级别）的日志，共有8级# 0: emerg# 1: alert# 2: crit# 3: err# 4: warning# 5: notice# 6: info# 7: debugsudo journalctl -p err -b# 以 JSON 格式（单行）输出sudo journalctl -b -u nginx.service -o json# 以 JSON 格式（多行）输出，可读性更好sudo journalctl -b -u nginx.serviceqq -o json-pretty# 显示日志占据的硬盘空间sudo journalctl --disk-usage# 指定日志文件占据的最大空间sudo journalctl --vacuum-size=1G# 指定日志文件保存多久sudo journalctl --vacuum-time=1years 日志切割转存sudo du -ah|grep messages sudo rm messages-202101*sudo vim /etc/logrotate.d/messagelog // 新建messagelog配置/var/log/messages&#123; size 2000000 // 2G rotate 4 // 保存4份 copytruncate compress&#125;sudo vim /etc/logrotate.d/syslog // 注释引用/var/log/messagessudo crontab -e // 新增crontab*/30 * * * * sudo /usr/sbin/logrotate /etc/logrotate.conf sudo crontab -l // 参看crontab"},{"title":"临时记录","path":"/notes/record/index.html","content":"每日接触到的知识点，不系统，比较凌乱，只是记录 2020-08-13Uber 的分布式追踪系统 Jaeger2019-09-19nohup。使用 nohup 命令让程序在关闭窗口（切换 SSH 连接）的时候程序还能继续在后台运行。如：nohup ./caster &amp; or nohup ./caster &gt;/dev/null 2&gt;&amp;1 &amp; 2019-08-29DSL（Domain Specific Language 领域特定语言） &amp; GPL（General Purpose Language 通用编程语言） 2019-08-28缓存优化，常见缓存算法 &amp; 快照与备份的区别，常见快照机制 cow 和 row2019-08-27状态机，有助于编码实现，有限状态机 FSM 的原理与 Go 的实现"},{"title":"常用 Shell","path":"/notes/shell/index.html","content":"docker clikill -9 $(ps -ef|grep caster|awk &#x27;NR==1 &#123;print $3&#125;&#x27;)docker rmi $(docker images | grep &#x27;&lt;none&gt;&#x27;| awk &#x27;&#123;print $3&#125;&#x27;)docker rmi $(docker images | grep &#x27;&lt;none&gt;&#x27;| awk &#x27;&#123;next&#125;&#123;print $3&#125;&#x27;) umount $(df -h|grep danaos|awk &#x27;&#123;print $6&#125;&#x27;)shuf -n 1000000 alluser_id | awk &#x27;&#123;print $2&#125;&#x27; &gt; test_random_1000000awk &#x27;END&#123;print NR&#125;&#x27; test_random_1000000docker inspect --format &#x27;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#x27; centosdocker run -itd --name=centos --privileged=true -v /sys/fs/cgroup:/sys/fs/cgroup -p 8888:8888 centos:centos7 /usr/sbin/init 开通防火墙端口iptables -I INPUT -p tcp --dport 8888 -j ACCEPT 允许远程主机访问本机的 80 端口iptables -Fiptables -Xiptables -A INPUT -p tcp --dport 80 -j acceptiptables -A INPUT -p tcp -j REJECT# 或者iptables -A INPUT -m state --state NEW-m tcp -p tcp --dport 80 -j ACCEPT 查看最大空间占用目录sudo du -h --exclude=&quot;mnt*&quot; --exclude=&quot;proc*&quot; -d 1 / 监控 linux 磁盘根分区 打印根分区大小 # 注解：awk ‘&#123;print $5&#125;’意思是打印第 5 个域，-F 的意思为分隔，例如以 % 分隔，简单意思就是去掉百分号，awk –F. ‘&#123;print $1&#125;’分隔点. 号df -h |sed -n &#x27;//$/p&#x27;|awk &#x27;&#123;print $5&#125;&#x27;|awk –F ”%” &#x27;&#123;print $1&#125;&#x27; if 条件判断该大小是否大于 90，如果大于 90 则发送邮件报警 while sleep 5mdo for i in `df -h |sed -n &#x27;//$/p&#x27; |awk &#x27;&#123;print $5&#125;&#x27; |sed &#x27;s/%//g&#x27;` do echo $i if [$i -ge 90];then echo “More than 90% Linux of disk space ,Please LinuxSA Check Linux Disk !” |mail -s “Warn Linux / Parts is $i%” XXX@XXX.XX fi donedone 网络抓包 tcpdump# 抓取 56.7 通过 80 请求的数据包。tcpdump -nn host 192.168.56.7 and port 80 # 80 排除 0.22 80 端口！tcpdump -nn host 192.168.56.7 or ! host 192.168.0.22 and port # tcp/ip 7 层协议物理层–数据链路层 - 网络层 - 传输层 - 会话层 - 表示层 - 应用层。 使用 snmpd 抓取版本为 v2 的 cacti 数据方式snmpwalk -v2c -c public 192.168.0.241 CPU 满载测试用例# 由于连续执行Ｎ个 (Ｎ是CPU个数) 的 dd 命令, 且使用率为100%,　这时调度器会调度每个 dd 命令在不同的 CPU 上处理；最终就实现所有 CPU 占用率 100%for i in `seq 1 $(cat /proc/cpuinfo |grep &quot;physical id&quot; |wc -l)`; do dd if=/dev/zero of=/dev/null &amp; done 说明: cat /proc/cpuinfo |grep &quot;physical id&quot; | wc -l 可以获得 CPU 的个数,　我们将其表示为 N. seq 1 N 用来生成１到Ｎ之间的数字 for i in seq 1 N; 就是循环执行命令, 从１到Ｎ dd if=/dev/zero of=/dev/null 执行 dd 命令,　输出到 /dev/null, 实际上只占用 CPU,　没有 IO 操作. 另外，上述程序的结束可以使用： fg 后按 ctrl + C (因为该命令是放在后台执行) pkill -9 dd 查找当前目录下以 .tar 的文件移动到指定目录find . -name “*.tar” -exec mv &#123;&#125; ./backup/ # 注解：find –name 主要用于查找某个文件名字，-exec 、xargs 可以用来承接前面的结果，然后将要执行的动作，一般跟 find 在一起用的很多，find 使用我们可以延伸 - mtime 查找修改时间、-type 是指定对象类型（常见包括 f 代表文件、d 代表目录），-size 指定大小，例如经常用到的：查找当前目录 30 天以前大于 100M 的 LOG 文件并删除find . -name &quot;*.log&quot; –mtime +30 –typef –size +100M |xargs rm –rf &#123;&#125; 批量解压当前目录下 .zip 的所有文件到指定目录# 注解：forI in （command）;do … done 为 for 循环的一个常用格式，其中 I 为变量，可以自己指定for i in `find . –name “*.zip”–type f `do unzip –d $i /data/www/img/done 判断目录是否存在# 注解：if…;then …else ..fi：为 if 条件语句,! 叹号表示反义 “不存在 “，-d 代表目录。if [! –d /data/backup/];then Mkdir–p /data/backup/else echo &quot;The Directory alreadyexists,please exit&quot;fi nginx 日志统计前10个 IPcd /home/logs/nginx/default# 注解：sort 排序、uniq（检查及删除文本文件中重复出现的行列 ）sort -m -k 4 -o access.logok access.1 access.2 access.3 ..... cat access.log |awk &#x27;&#123;print $1&#125;&#x27;|sort -n|uniq -c|sort -nr |head -10 打印出一个文件里面最大和最小值cat a.txt |sort -nr|awk ‘&#123;&#125;END&#123;print&#125; NR==1′cat a.txt |sort -nr |awk ‘END&#123;print&#125; NR==1′# 这个才是真正的打印最大最小值：sed ‘s/ / /g’ a.txt |sort -nr|sed -n ’1p;$p’ 查找3天前创建且后缀是 \\*.log 的文件并删除find . -mtime +3 -name &quot;*.log&quot; |xargs rm -rf &#123;&#125; ; 将某目录下大于 100k 的文件移动至 /tmp 下find . -size +100k -exec mv &#123;&#125; /tmp ; sed 常用命令# 如何去掉行首的. 字符: sed -i &#x27;s/^.//g&#x27; test.txt# 在行首添加一个 a 字符: sed &#x27;s/^/a/g&#x27; test.txt# 在行尾添加一个 a 字符: sed &#x27;s/$/a/&#x27; tets.txt# 在特定行后添加一个 c 字符: sed &#x27;/wuguangke/ac&#x27; test.txt#在行前加入一个 c 字符: sed &#x27;/wuguangke/ic&#x27; test.txt# 修改文本中以 jk 结尾的替换成 yzsed -e ‘s/jk$/yz/g’ b.txt# sed 冒号方式 sed -i ‘s:/tmp:/tmp/abc/:g’test.txt # 意思是将 /tmp 改成 /tmp/abc/"},{"title":"Windows","path":"/notes/windows/index.html","content":"📢&nbsp;公告通知已整理迁移至 专栏&#x2F;时间胶囊&#x2F;Windows 常见问题"},{"title":"前言","path":"/wiki/capsules/index.html","content":"危险，请不要打开这个警告，真的很危险最后一次警告，千万不要打开这个不要说我没有警告过你"},{"title":"安装与配置","path":"/wiki/git/index.html","content":"git InstallLinuxWindowsMac下载地址https://git-scm.com/download/linux安装指定系统的依赖包：Centos/RedHat$ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-develDebian/Ubuntu$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev解压安装下载的源码包：$ tar -zxf git-1.7.2.2.tar.gz$ cd git-1.7.2.2$ make prefix=/usr/local all$ sudo make prefix=/usr/local install使用终端指令安装Debian/Ubuntu$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev$ apt-get install git$ git --versiongit version 1.8.1.2CentOS/RedHat$ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel$ yum -y install git-core$ git --versiongit version 1.7.1下载地址https://gitforwindows.org/完成安装之后，就可以使用命令行的 git 工具（已经自带了 ssh 客户端）了，另外还有一个图形界面的 Git 项目管理工具。在开始菜单里找到 Git -&gt; Git Bash，会弹出 Git 命令窗口，你可以在该窗口进行 Git 操作。下载地址https://git-scm.com/download/macMac 自带 git 并且随着系统版本的更新，自带的 git 也会升级到最新，一般无需手动安装。 配置Git 提供了一个叫做 git config 的工具，专门用来配置或读取相应的工作环境变量。这些环境变量，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下三个不同的地方： /etc/gitconfig 文件：系统中对所有用户都普遍适用的配置。若使用 git config 时用 --system 选项，读写的就是这个文件。 ~/.gitconfig 文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 --global 选项，读写的就是这个文件。 当前项目的 Git 目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 .git/config 里的配置会覆盖 /etc/gitconfig 中的同名变量。 用户信息$ git config --global user.name xaoxuu$ git config --global user.email git@xaoxuu.com 如果用了 --global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。 如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 --global 选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。 查看配置信息$ git config --listhttp.postbuffer=2Muser.name=xaoxuuuser.email=git@xaoxuu.com windows下 git-bash 美化 尽管现在 wsl+linux 能玩出花来，但是以前都是 babun+git-bash 为主力的，那不美化下，windows 下的终端都没法看，就算现在要是不小心切到 git-bash ，而不想出现恶心的割裂感~ 具体配置.minttyrc 字体和配色方案再账户目录下新建 ~/.minttyrc 文件Columns=106Rows=58Font=ConsolasFontHeight=13CursorType=blockCursorBlinks=noTransparency=offBoldAsFont=yesAllowBlinking=yesScrollbar=noneScrollbackLines=200ClickTargetMod=offComposeKey=shiftForegroundColour=119,80,103BackgroundColour=249,241,233CursorColour=0,184,174Black=194,168,144BoldBlack=194,168,144Red=255,43,89BoldRed=255,43,89Green=0,127,192BoldGreen=0,127,192Yellow=151,185,1BoldYellow=151,185,1Blue=248,130,20BoldBlue=248,130,20Magenta=177,54,91BoldMagenta=177,54,91Cyan=20,77,121BoldCyan=20,77,121White=0,184,174BoldWhite=0,184,174ClipShortcuts=noFontWeight=700FontIsBold=yesLanguage=zh_CNPrinter=Generic 36C-9SeriesPCLZoomShortcuts=noAltFnShortcuts=noBellType=0OpaqueWhenFocused=nogit-prompt.sh 状态提示脚本.替换安装目录下的 /etc/profile 同名脚本即可if test -f /etc/profile.d/git-sdk.shthen TITLEPREFIX=SDK-$&#123;MSYSTEM#MINGW&#125;else TITLEPREFIX=$MSYSTEMfiif test -f ~/.config/git/git-prompt.shthen . ~/.config/git/git-prompt.shelse PS1=&#x27;\\[\\033]0;$TITLEPREFIX:$PWD\\007\\]&#x27; # set window title PS1=&quot;$PS1&quot;&#x27; &#x27; # new line PS1=&quot;$PS1&quot;&#x27;\\[\\033[1;32m\\]&#x27; # change to green # PS1=&quot;$PS1&quot;&#x27;\\u@\\h &#x27; # user@host&lt;space&gt; PS1=&quot;$PS1&quot;&#x27;\\u &#x27; # user@host&lt;space&gt; PS1=&quot;$PS1&quot;&#x27;\\[\\033[1;31m\\]&#x27; # PS1=&quot;$PS1&quot;&#x27;&#123;@v@/~&#125; &#x27; PS1=&quot;$PS1&quot;&#x27;\\[\\033[1;35m\\]&#x27; # change to purple # PS1=&quot;$PS1&quot;&#x27;$MSYSTEM &#x27; # show MSYSTEM PS1=&quot;$PS1&quot;&#x27;&quot;\\t&quot; &#x27; # show TIME PS1=&quot;$PS1&quot;&#x27;\\[\\033[1;33m\\]&#x27; # change to brownish yellow PS1=&quot;$PS1&quot;&#x27;\\W&#x27; # current working directory if test -z &quot;$WINELOADERNOEXEC&quot; then GIT_EXEC_PATH=&quot;$(git --exec-path 2&gt;/dev/null)&quot; COMPLETION_PATH=&quot;$&#123;GIT_EXEC_PATH%/libexec/git-core&#125;&quot; COMPLETION_PATH=&quot;$&#123;COMPLETION_PATH%/lib/git-core&#125;&quot; COMPLETION_PATH=&quot;$COMPLETION_PATH/share/git/completion&quot; if test -f &quot;$COMPLETION_PATH/git-prompt.sh&quot; then . &quot;$COMPLETION_PATH/git-completion.bash&quot; . &quot;$COMPLETION_PATH/git-prompt.sh&quot; PS1=&quot;$PS1&quot;&#x27;\\[\\033[36m\\]&#x27; # change color to cyan PS1=&quot;$PS1&quot;&#x27;`__git_ps1`&#x27; # bash function fi fi PS1=&quot;$PS1&quot;&#x27;\\[\\033[37m\\]&#x27; # change color # PS1=&quot;$PS1&quot;&#x27; &#x27; # new line PS1=&quot;$PS1&quot;&#x27; &gt;&gt;&gt; &#x27; # prompt: always $fiMSYS2_PS1=&quot;$PS1&quot; # for detection by MSYS2 SDK&#x27;s bash.basrc完成上述两步后，重启即可，效果如下，可根据自己口味进行调节 使用 SSH 连接到 GitHub生成新 SSH 密钥 ssh-keygen -t rsa -C user@example.com 其中 user@example.com 对应 Git 的邮箱地址 ssh-agent 是一种控制用来保存公钥身份验证所使用的私钥的程序，其实 ssh-agent 就是一个密钥管理器，运行 ssh-agent 以后，使用 ssh-add 将私钥交给 ssh-agent 保管，其他程序需要身份验证的时候可以将验证申请交给 ssh-agent 来完成整个认证过程。 eval &quot;$(ssh-agent -s)&quot; 添加生成的 SSH key 到 ssh-agent： ssh-add ~/.ssh/id_rsa 要配置 GitHub 帐户使用新的（或现有）SSH 密钥，您还需要将其添加到 GitHub 帐户。这个网上有大量的教程这里就不赘述了，后续也会讲到多 git 账户管理。"},{"title":"pacman","path":"/wiki/capsules/commands/pacman.html","content":"介绍arclinux 中的软件管理工具，可以直接从网络上的软件仓库下载安装及删除软件，自动处理依赖关系，类似ubuntu中的apt-get 安装软件pacman -S 软件名: 安装软件也可以同时安装多个包，只需以空格分隔包名即可pacman -S --needed 软件名1 软件名2: 安装软件，但不重新安装已经是最新的软件pacman -Sy 软件名: 安装软件前，先从远程仓库下载软件包数据库(数据库即所有软件列表)pacman -Sv 软件名: 在显示一些操作信息后执行安装pacman -Sw 软件名: 只下载软件包，不安装pacman -U 软件名.pkg.tar.gz: 安装本地软件包pacman -U http://www.example.com/repo/example.pkg.tar.xz: 安装一个远程包（不在 pacman 配置的源里面） 更新系统pacman -Sy: 从服务器下载新的软件包数据库（实际上就是下载远程仓库最新软件列表到本地）pacman -Su: 升级所有已安装的软件包 pacman 可以用一个命令就可以升级整个系统，花费的时间取决于系统有多老这个命令会同步非本地(local)软件仓库并升级系统的软件包: pacman -Syu 在 Arch linux 中，只支持系统完整升级，不支持部分升级。pacman -Syu 也会升级整个系统，安装完成目录占用空间立马变大很多；如果升级时，网络比较慢，觉得既浪费时间又浪费硬盘，实在不想升级那么多东西，可以逐个软件包升级，用下面命令可以升级核心包: pacman -S --needed filesystem msys2-runtime bash libreadline libiconv libarchive libgpgme libcurl pacman ncurses libintl 卸载软件pacman -R 软件名: 该命令将只删除包，保留其全部已经安装的依赖关系pacman -Rv 软件名: 删除软件，并显示详细的信息pacman -Rs 软件名: 删除软件，同时删除本机上只有该软件依赖的软件pacman -Rsc 软件名: 删除软件，并删除所有依赖这个软件的程序，慎用pacman -Ru 软件名: 删除软件,同时删除不再被任何软件所需要的依赖 搜索软件pacman -Ss 关键字: 在仓库中搜索含关键字的软件包（本地已安装的会标记）pacman -Sl &lt;repo&gt;: - 显示软件仓库中所有软件的列表 - 可以省略，通常这样用:`pacman -Sl | 关键字`pacman -Qs 关键字: 搜索已安装的软件包pacman -Qu: 列出所有可升级的软件包pacman -Qt: 列出不被任何软件要求的软件包 参数加q 可以简洁方式显示结果，比如 pacman -Ssq gcc 会比 pacman -Ss gcc 显示的好看一些 pacman -Sl | gcc 跟 pacman -Ssq gcc 很接近，但是会少一些和gcc有关但软件名不包含gcc的包 查询软件信息pacman -Q 软件名: 查看软件包是否已安装，已安装则显示软件包名称和版本pacman -Qi 软件名: 查看某个软件包信息，显示较为详细的信息，包括描述、构架、依赖、大小等等pacman -Ql 软件名: 列出软件包内所有文件，包括软件安装的每个文件、文件夹的名称和路径 软件包组pacman -Sg: 列出软件仓库上所有的软件包组pacman -Qg: 列出本地已经安装的软件包组和子包pacman -Sg 软件包组: 查看某软件包组所包含的所有软件包pacman -Qg 软件包组: 和pacman -Sg 软件包组完全一样 很多人建议通过安装软件组来安装工具链，例如: pacman -S mingw-w64-x86_64-toolchainpacman -S mingw-w64-i686-toolchainpacman -S mingw-w64-x86_64-qt5pacman -S base-devel 但是这样比较浪费空间实际上如果把 gcc, qt, clang 等安装上，msys2 就要占掉超过10G的硬盘空间，所以个人很少直接安装软件组 清理缓存pacman -Sc: 清理未安装的包文件，包文件位于 /var/cache/pacman/pkg/ 目录pacman -Scc: 清理所有的缓存文件 最常用的pacman命令pacman -Syu: 升级系统及所有已经安装的软件pacman -S 软件名: 安装软件也可以同时安装多个包，只需以空格分隔包名即可pacman -Rs 软件名: 删除软件，同时删除本机上只有该软件依赖的软件pacman -Ru 软件名: 删除软件，同时删除不再被任何软件所需要的依赖pacman -Ssq 关键字: 在仓库中搜索含关键字的软件包，并用简洁方式显示pacman -Qs 关键字: 搜索已安装的软件包pacman -Qi 软件名: 查看某个软件包信息，显示软件简介,构架,依赖,大小等详细信息pacman -Sg: 列出软件仓库上所有的软件包组pacman -Sg 软件包组: 查看某软件包组所包含的所有软件包pacman -Sc: 清理未安装的包文件，包文件位于 /var/cache/pacman/pkg/ 目录pacman -Scc: 清理所有的缓存文件"},{"title":"Capslock+","path":"/wiki/capsules/keys/capslock+.html","content":"https://capslox.com/capslock-plus/"},{"title":"linux shell(bash)","path":"/wiki/capsules/keys/shell.html","content":"Linux的缺省Shell是Bash熟练运用下面的快捷键将对提高Bash的操作有很多好处。如果你用过Emacs的话，你会发现它们的很多操作都是相同的，因为Bash默认使用的是Emacs按键绑定，当然你也可以修改为其他的方式，比如vi绑定。本文总结了shell在Emacs按键绑定下的快捷键使用方式，也就是shell默认快捷键。入门用户可以参考本文，也可以把本文作为一个参考备忘文档 Bash 默认为 emacs 编辑模式。如果你的 Bash 不在 emacs 编辑模式，可通过 set -o emacs 设置 控制命令Ctrl + l：清屏（与clear命令效果相同）Ctrl + o：执行当前命令，并选择上一条命令Ctrl + s：阻止屏幕输出(当前正在执行的命令不在打印信息)Ctrl + q：允许屏幕输出(使用Ctrl+s命令后，可以用Ctrl+q恢复)Ctrl + c：终止当前正在执行的命令Ctrl + z：挂起命令，把当前进程转到后台运行，使用fg命令恢复。Ctrl + d : 退出当前 Shell ^S、^Q、^C、^Z 是由终端设备处理的，可用 stty 命令设置。 编辑命令光标移动Ctrl + a ：移到命令行首Ctrl + e ：移到命令行尾Ctrl + f ：前移（向右移动）一个字符Ctrl + b ：后退（向左移动）一个字符Alt + f ：前移（向右移动）一个单词Alt + b ：后退（向左移动）一个单词Ctrl + xx：在命令行首和光标之间移动 文本修改补全、删除、粘贴tab : 自动补全命令Ctrl + u ：从光标处删除至命令行首Ctrl + k ：从光标处删除至命令行尾Ctrl + w ：从光标处删除至字首Alt + d ：从光标处删除至字尾Ctrl + d ：删除光标处（或光标后）的字符（如果光标前后都没有字符，即命令行为空的时候，则会退出shell）Ctrl + h ：删除光标前的字符(与backspace键相同)Alt + Backspace：与 Ctrl + w 类似，分隔符有些差别Ctrl + y ：粘贴至光标后 改变大小写Alt + c ：从光标处更改为首字母大写的单词Alt + u ：从光标处更改为全部大写的单词Alt + l ：从光标处更改为全部小写的单词 交换字符、单词位置Ctrl + t ：交换光标处和之前的字符（ESC+t相同）Alt + t ：交换光标处和之前的单词 重新执行命令Ctrl + p：历史中的上一条命令Ctrl + n：历史中的下一条命令Alt + .：使用上一条命令的最后一个参数（会直接在当前光标位置显示）Ctrl + r：搜索之前使用过的命令Ctrl + g：从历史搜索模式退出 Bang (!) 命令Bang 命令算不上快捷键键，但是使用可以快捷的进行一些操作，比如重新执行之前命令、修改上一条命令并执行等等。 !!：执行上一条命令!cc：执行最近的以cc开头的命令，如!l会执行ls命令!$：打印上一条命令的最后一个参数，并回车执行。与Alt + .相似，但是会自动执行!*：上一条命令的所有参数!cc:p：仅打印以!cc的输出，但不执行，如!l:p会显示ls!$:p：打印输出!$的输出!*:p：打印输出!*的输出^blah：删除上一条命令中第一个blah，然后执行^blah^foo：将上一条命令中的 blah 替换为 foo，然后执行^blah^foo^：将上一条命令中所有的 blah 都替换为 foo，然后执行"},{"title":"Visual Studio Code","path":"/wiki/capsules/keys/vscode.html","content":"按 Press 功能 Function Ctrl + Shift + P，F1 显示命令面板 Show Command Palette Ctrl + P 快速打开 Quick Open Ctrl + Shift + N 新窗口 &#x2F; 实例 New window&#x2F;instance Ctrl + Shift + W 关闭窗口 &#x2F; 实例 Close window&#x2F;instance 基础编辑 Basic editing 按 Press 功能 Function Ctrl+X 剪切行（空选定） Cut line (empty selection) Ctrl+C 复制行（空选定）Copy line (empty selection) Alt+ ↑ &#x2F; ↓ 向上 &#x2F; 向下移动行 Move line up&#x2F;down Shift+Alt + ↓ &#x2F; ↑ 向上 &#x2F; 向下复制行 Copy line up&#x2F;down Ctrl+Shift+K 删除行 Delete line Ctrl+Enter 在下面插入行 Insert line below Ctrl+Shift+Enter 在上面插入行 Insert line above Ctrl+Shift+\\ 跳到匹配的括号 Jump to matching bracket Ctrl+] &#x2F; [ 缩进 &#x2F; 缩进行 Indent&#x2F;outdent line Home 转到行首 Go to beginning of line End 转到行尾 Go to end of line Ctrl+Home 转到文件开头 Go to beginning of file Ctrl+End 转到文件末尾 Go to end of file Ctrl+↑ &#x2F; ↓ 向上 &#x2F; 向下滚动行 Scroll line up&#x2F;down Alt+PgUp &#x2F; PgDown 向上 &#x2F; 向下滚动页面 Scroll page up&#x2F;down Ctrl+Shift+[ 折叠（折叠）区域 Fold (collapse) region Ctrl+Shift+] 展开（未折叠）区域 Unfold (uncollapse) region Ctrl+K Ctrl+[ 折叠（未折叠）所有子区域 Fold (collapse) all subregions Ctrl+K Ctrl+] 展开（未折叠）所有子区域 Unfold (uncollapse) all subregions Ctrl+K Ctrl+0 折叠（折叠）所有区域 Fold (collapse) all regions Ctrl+K Ctrl+J 展开（未折叠）所有区域 Unfold (uncollapse) all regions Ctrl+K Ctrl+C 添加行注释 Add line comment Ctrl+K Ctrl+U 删除行注释 Remove line comment Ctrl+&#x2F; 切换行注释 Toggle line comment Shift+Alt+A 切换块注释 Toggle block comment Alt+Z 切换换行 Toggle word wrap 导航 Navigation 按 Press 功能 Function Ctrl + T 显示所有符号 Show all Symbols Ctrl + G 转到行… Go to Line… Ctrl + P 转到文件… Go to File… Ctrl + Shift + O 转到符号… Go to Symbol… Ctrl + Shift + M 显示问题面板 Show Problems panel F8 转到下一个错误或警告 Go to next error or warning Shift + F8 转到上一个错误或警告 Go to previous error or warning Ctrl + Shift + Tab 导航编辑器组历史记录 Navigate editor group history Alt + ←&#x2F;→ 返回 &#x2F; 前进 Go back &#x2F; forward Ctrl + M 切换选项卡移动焦点 Toggle Tab moves focus 搜索和替换 Search and replace 按 Press 功能 Function Ctrl + F 查找 Find Ctrl + H 替换 Replace F3 &#x2F; Shift + F3 查找下一个 &#x2F; 上一个 Find next&#x2F;previous Alt + Enter 选择查找匹配的所有出现 Select all occurences of Find match Ctrl + D 将选择添加到下一个查找匹配 Add selection to next Find match Ctrl + K Ctrl + D 将最后一个选择移至下一个查找匹配项 Move last selection to next Find match Alt + C &#x2F; R &#x2F; W 切换区分大小写 &#x2F; 正则表达式 &#x2F; 整个词 Toggle case-sensitive &#x2F; regex &#x2F; whole word 多光标和选择 Multi-cursor and selection 按 Press 功能 Function Alt + 单击 插入光标 Insert cursor Ctrl + Alt +↑&#x2F;↓ 在上 &#x2F; 下插入光标 Insert cursor above &#x2F; below Ctrl + U 撤消上一个光标操作 Undo last cursor operation Shift + Alt + I 在选定的每一行的末尾插入光标 Insert cursor at end of each line selected Ctrl + I 选择当前行 Select current line Ctrl + Shift + L 选择当前选择的所有出现 Select all occurrences of current selection Ctrl + F2 选择当前字的所有出现 Select all occurrences of current word Shift + Alt + → 展开选择 Expand selection Shift + Alt + ← 缩小选择 Shrink selection Shift + Alt + （拖动鼠标） 列（框）选择 Column (box) selection Ctrl + Shift + Alt +（箭头键） 列（框）选择 Column (box) selection Ctrl + Shift + Alt + PgUp &#x2F; PgDown 列（框）选择页上 &#x2F; 下 Column (box) selection page up&#x2F;down 丰富的语言编辑 Rich languages editing 按 Press 功能 Function Ctrl + 空格 触发建议 Trigger suggestion Ctrl + Shift + Space 触发器参数提示 Trigger parameter hints Tab Emmet 展开缩写 Emmet expand abbreviation Shift + Alt + F 格式化文档 Format document Ctrl + K Ctrl + F 格式选定区域 Format selection F12 转到定义 Go to Definition Alt + F12 Peek 定义 Peek Definition Ctrl + K F12 打开定义到边 Open Definition to the side Ctrl + . 快速解决 Quick Fix Shift + F12 显示引用 Show References F2 重命名符号 Rename Symbol Ctrl + Shift + . &#x2F;， 替换为下一个 &#x2F; 上一个值 Replace with next&#x2F;previous value Ctrl + K Ctrl + X 修剪尾随空格 Trim trailing whitespace Ctrl + K M 更改文件语言 Change file language 编辑器管理 Editor management 按 Press 功能 Function Ctrl+F4, Ctrl+W 关闭编辑器 Close editor Ctrl+K F 关闭文件夹 Close folder Ctrl+\\ 拆分编辑器 Split editor Ctrl+ 1 &#x2F; 2 &#x2F; 3 聚焦到第 1，第 2 或第 3 编辑器组 Focus into 1st, 2nd or 3rd editor group Ctrl+K Ctrl+ ←&#x2F;→ 聚焦到上一个 &#x2F; 下一个编辑器组 Focus into previous&#x2F;next editor group Ctrl+Shift+PgUp &#x2F; PgDown 向左 &#x2F; 向右移动编辑器 Move editor left&#x2F;right Ctrl+K ← &#x2F; → 移动活动编辑器组 Move active editor group 文件管理 File management 按 Press 功能 Function Ctrl+N 新文件 New File Ctrl+O 打开文件… Open File… Ctrl+S 保存 Save Ctrl+Shift+S 另存为… Save As… Ctrl+K S 全部保存 Save All Ctrl+F4 关闭 Close Ctrl+K Ctrl+W 关闭所有 Close All Ctrl+Shift+T 重新打开关闭的编辑器 Reopen closed editor Ctrl+K 输入保持打开 Enter Keep Open Ctrl+Tab 打开下一个 Open next Ctrl+Shift+Tab 打开上一个 Open previous Ctrl+K P 复制活动文件的路径 Copy path of active file Ctrl+K R 显示资源管理器中的活动文件 Reveal active file in Explorer Ctrl+K O 显示新窗口 &#x2F; 实例中的活动文件 Show active file in new window&#x2F;instance 显示 Display 按 Press 功能 Function F11 切换全屏 Toggle full screen Shift+Alt+1 切换编辑器布局 Toggle editor layout Ctrl+ &#x3D; &#x2F; - 放大 &#x2F; 缩小 Zoom in&#x2F;out Ctrl+B 切换侧栏可见性 Toggle Sidebar visibility Ctrl+Shift+E 显示浏览器 &#x2F; 切换焦点 Show Explorer &#x2F; Toggle focus Ctrl+Shift+F 显示搜索 Show Search Ctrl+Shift+G 显示 Git Show Git Ctrl+Shift+D 显示调试 Show Debug Ctrl+Shift+X 显示扩展 Show Extensions Ctrl+Shift+H 替换文件 Replace in files Ctrl+Shift+J 切换搜索详细信息 Toggle Search details Ctrl+Shift+C 打开新命令提示符 &#x2F; 终端 Open new command prompt&#x2F;terminal Ctrl+Shift+U 显示输出面板 Show Output panel Ctrl+Shift+V 切换 Markdown 预览 Toggle Markdown preview Ctrl+K V 从旁边打开 Markdown 预览 Open Markdown preview to the side 调试 Debug 按 Press 功能 Function F9 切换断点 Toggle breakpoint F5 开始 &#x2F; 继续 Start&#x2F;Continue Shift+F5 停止 Stop F11 &#x2F; Shift+F11 下一步 &#x2F; 上一步 Step into&#x2F;out F10 跳过 Step over Ctrl+K Ctrl+I 显示悬停 Show hover 集成终端 Integrated terminal 按 Press 功能 Function Ctrl+&#96; 显示集成终端 Show integrated terminal Ctrl+Shift+&#96; 创建新终端 Create new terminal Ctrl+Shift+C 复制选定 Copy selection Ctrl+Shift+V 粘贴到活动端子 Paste into active terminal Ctrl+↑ &#x2F; ↓ 向上 &#x2F; 向下滚动 Scroll up&#x2F;down Shift+PgUp &#x2F; PgDown 向上 &#x2F; 向下滚动页面 Scroll page up&#x2F;down Ctrl+Home &#x2F; End 滚动到顶部 &#x2F; 底部 Scroll to top&#x2F;bottom"},{"title":"WSL2 & Arch","path":"/wiki/capsules/list/archwsl.html","content":"安装 Arch 进入 ArchWSL 仓库下载最新 release 中的 zip 包 建议选择无 online 后缀的包 数据文件和多版本在 release 下载最新版的 Arch.zip解压到 C 盘根目录，(一定要在 C 盘，其他位置也可以)，但是你要有该目录的读写权限，所以不能放到 Program Files 等目录中双击解压好的 Arch.exe 进行安装，这个 .exe 的名字 就是要创建的 WSL 实例的名字，改不同的名字就能创建多个 Arch WSL ArchWSL 常用命令在终端中进入 Arch.exe 所在的目录，运行 .\\Arch.exe help 可查看详细命令说明; 备份 # 备份格式参数可选：tar tgz vhdx vhdxgz reg.\\Arch.exe backup --tar 恢复 .\\Arch.exe install /to/file/path/backup.tar 卸载 .\\Arch.exe clean 配置 Arch经过上面的安装后，现在到 terminal 中输入 wsl 运行即可;如果已经在使用其他的wsl系统了，那么此时直接输入wsl 并不能启动刚刚新安装的Arch，需要在终端中打开上面安装（含有 Arch.exe）时的目录，输入 .\\Arch.exe 进行运行；或者修改默认的 WSL 为刚刚安装的 Arch ，可参考：设置默认 Linux 发行版 | WSL 的基本命令 | Microsoft Docs 创建用户默认使用 root 用户 ，跳过 导入密钥(重要)# 初始化密钥环 &amp;&amp; 验证主密钥 &amp;&amp; 更新密钥sudo pacman-key --init sudo pacman-key --populate archlinux sudo pacman-key --refresh-keys 配置软件仓库Arch Linux 软件仓库国内镜像编辑 /etc/pacman.d/mirrorlist，里面有注释了的 China 的镜像(选择 https)，选一个你喜欢的取消注释就可以了。 vim /etc/pacman.d/mirrorlist 其他跟镜像有关的可以看这里：https://wiki.archlinux.org/index.php/Mirrors_(简体中文) 添加 ArchlinuxCN 源 Arch Linux 中文社区仓库 是由 Arch Linux 中文社区驱动的非官方用户仓库。包含中文用户常用软件、工具、字体 &#x2F; 美化包等。 官方仓库地址：http://repo.archlinuxcn.org echo &quot;[archlinuxcn]Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/x86_64&quot; &gt;&gt; /etc/pacman.conf 基础环境更新# 安装archlinuxcn证书sudo pacman -Syy archlinuxcn-keyring# 更新软件源# sudo pacman -Syyu --noconfirm 不提示确认对话sudo pacman -Syyu 其它配置下载镜像（推荐）利用 Reflector，自动生成，生成时可设置过滤条件 sudo pacman -S reflector 安装成功后，执行下面这条命令；意思是地址为中国、最近12小时活跃、https协议、速度排序、生成镜像文件 sudo reflector --country China --age 12 --protocol https --sort rate --save /etc/pacman.d/mirrorlist 完成后可以输入下面的命令查看生成的镜像列表 cat /etc/pacman.d/mirrorlist 安装常用工具pacman -S which openssh git zsh tree wget unzip 安装 AURpacman -S paru zsh 配置安装前置工具 pacman -S lua exa fzf zsh会自动下载zinit以及zsh插件,由于速度较慢，推荐使用代理： proxychains zsh .zshrc 配置# 修复emacs中不能输入中文# LC_CTYPE=&quot;zh_CN.utf8&quot;# 移除重复的命令历史setopt HIST_IGNORE_ALL_DUPS# 取消zsh在输出不以换行符结尾的内容是在其后添加百分号并另其一行的特性# unsetopt prompt_cr prompt_sp# 设置可以使用通配符setopt nonomatch# 免输入cd进入目录setopt auto_cd###################### ZINIT ######################### Added by Zinit&#x27;s installerif [[ ! -f $HOME/.local/share/zinit/zinit.git/zinit.zsh ]]; then print -P &quot;%F&#123;33&#125; %F&#123;220&#125;Installing %F&#123;33&#125;ZDHARMA-CONTINUUM%F&#123;220&#125; Initiative Plugin Manager (%F&#123;33&#125;zdharma-continuum/zinit%F&#123;220&#125;)…%f&quot; command mkdir -p &quot;$HOME/.local/share/zinit&quot; &amp;&amp; command chmod g-rwX &quot;$HOME/.local/share/zinit&quot; command git clone https://github.com/zdharma-continuum/zinit &quot;$HOME/.local/share/zinit/zinit.git&quot; &amp;&amp; \\ print -P &quot;%F&#123;33&#125; %F&#123;34&#125;Installation successful.%f%b&quot; || \\ print -P &quot;%F&#123;160&#125; The clone has failed.%f%b&quot;fisource &quot;$HOME/.local/share/zinit/zinit.git/zinit.zsh&quot;autoload -Uz _zinit(( $&#123;+_comps&#125; )) &amp;&amp; _comps[zinit]=_zinit### End of Zinit&#x27;s installer chunk# Load a few important annexes, without Turbozinit light-mode for \\ zdharma-continuum/zinit-annex-as-monitor \\ zdharma-continuum/zinit-annex-bin-gem-node \\ zdharma-continuum/zinit-annex-patch-dl \\ zdharma-continuum/zinit-annex-rust##### autosuggestionszinit ice wait&quot;0a&quot; lucid atload&quot;_zsh_autosuggest_start&quot;zinit light zsh-users/zsh-autosuggestions##### completionszinit ice wait&quot;0b&quot; lucid blockf atpull&#x27;zinit creinstall -q .&#x27;zinit light zsh-users/zsh-completions##### syntax highlightingzinit ice wait&quot;0c&quot; lucid atinit&quot;zicompinit; zicdreplay&quot;zinit light zdharma-continuum/fast-syntax-highlighting##### z.luazinit ice lucid wait=&#x27;0d&#x27;zinit light skywind3000/z.lua##### fzf-tabzinit ice wait&quot;0f&quot; lucid atinit&quot;zicompinit; zicdreplay&quot;zinit light Aloxaf/fzf-tab# colorzstyle &#x27;:fzf-tab:*&#x27; default-color $&#x27;\\033[38;5;79m&#x27;# disable sort when completing `git checkout`zstyle &#x27;:completion:*:git-checkout:*&#x27; sort false# set descriptions format to enable group supportzstyle &#x27;:completion:*:descriptions&#x27; format &#x27;[%d]&#x27;# set list-colors to enable filename colorizingzstyle &#x27;:completion:*&#x27; list-colors $&#123;(s.:.)LS_COLORS&#125;# preview directory&#x27;s content with exa when completingzstyle &#x27;:fzf-tab:complete:*&#x27; fzf-preview &#x27;exa -1 --color=always $realpath&#x27;# switch group using `,` and `.`zstyle &#x27;:fzf-tab:*&#x27; switch-group &#x27;,&#x27; &#x27;.&#x27;##### history searchzinit ice wait&quot;0b&quot; lucid atload&#x27;bindkey &quot;$terminfo[kcuu1]&quot; history-substring-search-up; bindkey &quot;$terminfo[kcud1]&quot; history-substring-search-down&#x27;zinit light zsh-users/zsh-history-substring-searchbindkey &#x27;^A&#x27; history-substring-search-upbindkey &#x27;^Z&#x27; history-substring-search-down##### Load Oh MY Zsh Pluginszinit snippet OMZ::plugins/git/git.plugin.zshzinit snippet OMZ::lib/history.zsh###################### STARSHIP ######################eval &quot;$(starship init zsh)&quot;# The environment for GOLANGexport GOROOT=/usr/lib/goexport GOPATH=/home/goexport PATH=$PATH:$GOROOT/bin:$GOPATH/binexport GOPROXY=https://goproxy.cn,directexport GOPRIVATE=git.ztosys.com# The environment for RUSTexport RUSTUP_DIST_SERVER=https://mirrors.sjtug.sjtu.edu.cn/rust-staticexport RUSTUP_UPDATE_ROOT=https://mirrors.sjtug.sjtu.edu.cn/rust-static/rustup# Aliasalias l=&quot;ls -alh --color&quot;alias ls=&quot;ls --color&quot;alias ll=&quot;ls -lh --color&quot;alias c=&#x27;clear&#x27;alias cda=&#x27;cd /mnt/c/Users/Administrator/&#x27;alias cdg=&#x27;cd /home/go/src/&#x27;alias cdr=&#x27;cd /home/rust&#x27;alias cdt=&#x27;cd /home/ts&#x27;alias ex=&#x27;explorer.exe .&#x27;alias tailf=&#x27;tail -f&#x27;alias gcn=&#x27;git config user.name &quot;lliei&quot;&#x27;alias gce=&#x27;git config user.email &quot;i@liei.cc&quot;&#x27;alias gczn=&#x27;git config user.name &quot;lilei1215&quot;&#x27;alias gcze=&#x27;git config user.email &quot;lilei1215@zto.ldap&quot;&#x27;source /usr/share/nvm/init-nvm.sh 插件更新 zinit update --all zinit框架升级 zinit slef-update"},{"title":"Windows 常见问题","path":"/wiki/capsules/list/windows.html","content":"WSL2 固定静态IP基于该 issuecomment 的思路，实现静态IP的方案；在 WSL2 Linux中创建一个脚本文件 vim $HOME/.config/static-ip.sh static-ip.sh#!/bin/bash/mnt/c/WINDOWS/system32/netsh.exe interface ip show addresses &quot;vEthernet (WSL)&quot; | /mnt/c/WINDOWS/system32/findstr.exe /C:&quot;172.18.18.1&quot; &gt; /dev/nullif [ $? == 1 ]; then /mnt/c/WINDOWS/system32/netsh.exe interface ip add address &quot;vEthernet (WSL)&quot; address=172.18.18.1/24fiip addr show eth0 | grep -s &quot;172.18.18.100/24&quot; &gt; /dev/nullif [ $? == 1 ]; then ip addr add 172.18.18.100/24 broadcast 172.18.18.255 dev eth0 label eth0:1fi 注意这段脚本给 Windows 端的 vEthernet (WSL) 添加IPv4 172.18.18.1，给 Linux 端的 eth0 添加IPv4 172.18.18.1；在使用前，请按需调整网络接口的名称和IP地址在 WSL2 启动的时候执行该脚本 vim /etc/profile 添加以下内容： 使用静态IPWindows 端静态IP 172.18.18.1WSL2 Linux 端静态IP 172.18.18.100常见问题 win11 能够 ping 通 wsl2，但是 wsl2 无法 ping 通 win11；经分析主要是 win11 防火墙的原因；可在 win11 中 执行如下命令(管理员运行 powershell 或 cmd )： New-NetFirewallRule -DisplayName &quot;WSL&quot; -Direction Inbound -InterfaceAlias &quot;vEthernet (WSL)&quot; -Action Allow释放 WSL 占用的硬盘空间WSL 使用虚拟硬盘(VHD)存储 linux 下的文件，随着Linux下文件越来越多，占用空间也会不断增长，不过有个最大限制 256G。但是，在 Linux 中减少文件占用，WSL 却没有相应的减少硬盘空间的占用。所以为了避免碰到 256G 的限制，或者硬盘空间告警，在删除掉 linux 下的文件后，我们需要手动释放这部分空间；要找到使用的的vhd文件路径 打开 PowerShell, 执行以下命令：wsl --shutdowndiskpart# open window Diskpartselect vdisk file=&quot;C:\\Users\\Administrator\\Data\\Arch\\ext4.vhdx&quot;attach vdisk readonlycompact vdiskdetach vdiskexitWSL2 Input/output error解决方案 1： 重启 wslwsl --shutdownwsl解决方案 2： 重新挂载 C 盘sudo umount /mnt/csudo mount -t drvfs C:\\\\ /mnt/c禁止指定程序联网使用命令行建立防火墙规则，以禁止 STC-ISP 联网为例：netsh advfirewall firewall add rule name=&quot;stc-isp-15xx-v6.86_NewLogo&quot; dir=out program=&quot;C:\\Users\\Administrator\\Desktop\\stc-isp-15xx-v6.86_NewLogo.exe&quot; action=block 恢复允许联网：netsh advfirewall firewall set rule name=&quot;stc-isp-15xx-v6.86_NewLogo&quot; new enable=no回车确定后立即生效；在控制面板 -&gt; windows 防火墙 -&gt; 高级设置 -&gt; 出站设置 里就出现了这条新增项目Chrome（CentBrowser）平滑滚动设置一直以来对 Microsoft EDGE 的平滑滚动的效果很羡慕，而 Chrome 的 Smooth Scrolling 太糟糕，研究了几天，经过摸索终于发现了其实 Chrome（CentBrowser）也有这个设置，只是默认没有开启罢了。在 chrome://flags 中将 Impulse-style scroll animationsPercent-based Scrolling这两个设置成 Enable 就行了，比任何插件都要好用，原生支持！注意Smooth Scrolling 还是 Default 就行，不需要修改开启浏览器多线程下载选项尽管没有 IDM 等专门的下载软件那么专业强大，但在开启多线程下载选项之后，只要服务器支持多线程，那么直接使用浏览器下载文件就能获得比原先更快的速度ChromeEdge (Chromium 内核)地址栏输入并回车：chrome://flags/#enable-parallel-downloading然后你就能看到如下图所示，只需将默认的 Default 改成 Enabled 即可！然后点击 Relaunch 重启浏览器，多线程下载的选项就生效了，这时就可以找个文件去试试速度了地址栏输入并回车：edge://flags/#enable-parallel-downloading然后你就能看到如下图所示，只需将默认的 Default 改成 Enabled 即可！然后点击 Relaunch 重启浏览器，多线程下载的选项就生效了，这时就可以找个文件去试试速度了浏览器开启终极黑暗模式使用扩展不使用扩展（推荐）Dark ReaderMidnight Lizard浏览器地址栏输入 edge://flags or chrome://flags使用最上方的搜索关键字 dark，将 Auto Dark Mode for Web Contents 选项设置为 Enabled with selective inversion of non-image elements，也可以尝试其他选项重启浏览器，即可。配置 WSL2 使用代理上网将宿主机的代理共享给这个局域网下的其他设备，以 Clash 为例，打开 Allow LAN 选项WSL2 下操作：## 获取主机 IP## 主机 IP 保存在 /etc/resolv.conf 中export hostip=$(cat /etc/resolv.conf |grep -oP &#x27;(?&lt;=nameserver\\ ).*&#x27;)## 设置代理export all_proxy=&quot;socks5://$&#123;hostip&#125;:7890&quot;## 验证curl google.com简化上述设置，在 ~&#x2F;.zshrc 中添加的以下配置export hostip=$(cat /etc/resolv.conf |grep -oP &#x27;(?&lt;=nameserver\\ ).*&#x27;)alias setss=&#x27;export ALL_PROXY=&quot;socks5://$&#123;hostip&#125;:7890&quot;&#x27;alias unsetss=&#x27;unset ALL_PROXY&#x27;如果wsl连接不到主机（ping不通的话），直接放开 vEthernet (WSL) 这张网卡的防火墙，在 powershell 上执行：New-NetFirewallRule -DisplayName &quot;WSL&quot; -Direction Inbound -InterfaceAlias &quot;vEthernet (WSL)&quot; -Action Allow"},{"title":"搭建免费 CDN","path":"/wiki/git/cdn/index.html","content":"百度百科CDN 的全称是 Content Delivery Network，即内容分发网络。CDN 是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN 的关键技术主要有内容存储和分发技术。 新建 Github Repository 就常规的新建 Github 仓库，作为内容存储；最好都使用命令行操作，不熟悉的自己去查，这是最基础的，乖哦！我就不说了 通过 jsDelivr 引用资源jsDelivr 是什么？jsDelivr 由 ProspectOne 维护的公共库，使用的融合 CDN 技术，由 Cloudflare、Fastly、StackPath、QUANTIL 等 CDN 供应商提供了全球超过 750 个 CDN 节点。最重要的是，jsDelivr 在中国大陆也拥有超过数百个节点，因为 jsDelivr 拥有正规的 ICP 备案，解决了中国大陆的访问速度优化，实现真正的全球极速低延迟体验。jsDelivr 是免费的、不限制带宽的，可以加速 NPM、Github 内的文件。 使用方法 根据版本号https://cdn.jsdelivr.net/gh/Username/YourRepoName@Version/FilePath 根据 Commit Hash 提交记录https://cdn.jsdelivr.net/gh/Username/YourRepoName@CommitHash/FilePath 获取最新提交https://cdn.jsdelivr.net/gh/Username/YourRepoName/FilePath 举个例子 🍌https://cdn.jsdelivr.net/gh/leeifme/oss-aliyun-cli@0.1.0/README.mdhttps://cdn.jsdelivr.net/gh/leeifme/oss-aliyun-cli@1d86a902394f556f954142125746f5b7c014c6bd/README.mdhttps://cdn.jsdelivr.net/gh/leeifme/oss-aliyun-cli/README.m 代码压缩 jsDelivr 还提供了代码压缩服务，比如将 JS&#x2F;CSS 的代码压缩，优化访问速度。只是前几次访问会执行压缩操作，速度比较慢。后面就会将文件缓存，速度不会再慢了。直接将访问链接的文件后缀改成 .min.js 即可。例如： https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/src/example.min.js"},{"title":"git-flow 的工作流程","path":"/wiki/git/git-flow/index.html","content":"前言 当在团队开发中使用版本控制系统时，商定一个统一的工作流程是至关重要的。 Git 的确可以在各个方面做很多事情，然而，如果在你的团队中还没有能形成一个特定有效的工作流程，那么混乱就将是不可避免的。 git-flow 就是当前非常流行且行之有效的工作流程， 是一个 Git 扩展集，按 Vincent Driessen 的分支模型提供高层次的库操作，并且提供了极其出色的命令帮忙以及输出提示，本文中有演示操作，可以仔细阅读并观察发生了什么事情 git-flow 安装安装指南：https://github.com/petervanderdoes/gitflow-avh/wiki/Installation 准备工作（Windows）按照官方给出的安装方法，依次点击三个链接： util-linux package libintl libiconv 三个要下载的都是 Binaries 的 zip 格式文件，下载完后只需要把各自 bin 目录下的对应文 (getopt.exe，libintl3.dll，libiconv2.dll ) 件复制到 git 安装目录的 bin 目录下即可, 其他的都不需要，版本和路径根据自己的情况而定 Clone the git-flow打开 Git Bash 执行： $ git config --global url.&quot;https://github&quot;.insteadOf git://github 如果不执行这条命令，直接执行下面命令的话，clone 会出现卡住现象 $ git clone --recursive git://github.com/nvie/gitflow.git 打开powershell（以管理员身份运行）， cd 到下载 gitflow 的目录下 PS C:\\Users\\Administrator&gt; cd .\\gitflow\\PS C:\\Users\\Administrator\\gitflow&gt; .\\contrib\\msysgit-install.cmd &quot;C:\\Program Files\\Software\\Git&quot;# &quot;C:\\Program Files\\Software\\Git&quot; 根据安装 git 的安装目录进行调整 测试是否安装成功，打开 Git Bash Administrator at 14:56:56 / $ git flow helpusage: git flow &lt;subcommand&gt;Available subcommands are: init Initialize a new git repo with support for the branching model. feature Manage your feature branches. bugfix Manage your bugfix branches. release Manage your release branches. hotfix Manage your hotfix branches. support Manage your support branches. version Shows version information. config Manage your git-flow configuration. log Show log deviating from base branch.Try &#x27;git flow &lt;subcommand&gt; help&#x27; for details. git-flow 使用开发新功能 ( Feature )需求：添加一个 README.md 文件，并添加内容 创建 my-feature 分支 Administrator at 16:04:03 Go-fun (develop) $ git flow feature start my-featureSwitched to a new branch &#x27;feature/my-feature&#x27;Summary of actions:- A new branch &#x27;feature/my-feature&#x27; was created, based on &#x27;develop&#x27;- You are now on branch &#x27;feature/my-feature&#x27;Now, start committing on your feature. When done, use: git flow feature finish my-feature Administrator at 16:04:51 Go-fun (feature/my-feature) $ 根据提示，我们知道一个新的分支 feature／my-feature 基于 develop 分支创建好了, 并且目前我们所在的分支为 feature／my-feature，可以查看下分支情况 $ git branch develop* feature/my-feature master 在 feature/my-feature 分支新建一个 README.md 并提交 $ vi README.md$ git add README.md$ git commit -m &quot;create README.md&quot;[feature/my-feature e783fdf] create README.md1 file changed, 1 insertion(+)create mode 100644 README.md 完成 feature 分支合并 根据之前创建分支的提示可知，在完成新功能的开发后，可使用 git flow feature finish &lt;name&gt; 提交合并 $ git flow feature finish my-featureSwitched to branch &#x27;develop&#x27;Updating bde3a64..e783fdfFast-forward README.md | 1 + 1 file changed, 1 insertion(+) create mode 100644 README.mdDeleted branch feature/my-feature (was e783fdf).Summary of actions:- The feature branch &#x27;feature/my-feature&#x27; was merged into &#x27;develop&#x27;- Feature branch &#x27;feature/my-feature&#x27; has been locally deleted- You are now on branch &#x27;develop&#x27; 根据提示，我们看到了 git flow feature finish my-feature 这条语句的作用。 feature/my-feature 分支被 merge 到了 develop 分支 本地 feature/my-feature 分支被删除，现在我们处于 develop 分支 参看分支情况： $ git branch* develop master 不使用 git-flow 在不使用 git-flow 工具的情况下，怎么实现 新建一个分支 $ git checkout -b my-feature develop 当开发完成后，合并分支。 $ git merge --no-ff my-featureAlready up-to-date. 删除本地 my-feature 分支 $ git branch -d my-feature 提交更改到远程 develop 分支 $ git push origin develop 比较两种方式就会发现，git flow 方便了分支的管理, 使用上更为简单 发布版本 ( Release )需求：添加一个 README.md 文件，并添加版本号与日期 创建 release 1.0 分支 Administrator at 17:37:59 Go-fun (develop) $ git flow release start 1.0Switched to a new branch &#x27;release/1.0&#x27;Summary of actions:- A new branch &#x27;release/1.0&#x27; was created, based on &#x27;develop&#x27;- You are now on branch &#x27;release/1.0&#x27;Follow-up actions:- Bump the version number now!- Start committing last-minute fixes in preparing your release- When done, run: git flow release finish &#x27;1.0&#x27;Administrator at 17:38:07 Go-fun (release/1.0) $ 根据提示，流程和创建 feature 分支差不多，查看分支情况 $ git branch develop master* release/1.0 添加修改文件到暂存区 $ git add README.md$ git commit -m &quot;update version to 1.0&quot; 完成 release 1.0 分支 Administrator at 19:00:28 Go-fun (release/1.0) $ git flow release finish 1.0Switched to branch &#x27;master&#x27;Your branch is up to date with &#x27;origin/master&#x27;.Merge made by the &#x27;recursive&#x27; strategy. README.md | 5 ++++- 1 file changed, 4 insertions(+), 1 deletion(-)Already on &#x27;master&#x27;Your branch is ahead of &#x27;origin/master&#x27; by 2 commits. (use &quot;git push&quot; to publish your local commits)Switched to branch &#x27;develop&#x27;Merge made by the &#x27;recursive&#x27; strategy. README.md | 5 ++++- 1 file changed, 4 insertions(+), 1 deletion(-)Deleted branch release/1.0 (was 922692f).Summary of actions:- Release branch &#x27;release/1.0&#x27; has been merged into &#x27;master&#x27;- The release was tagged &#x27;1.0&#x27;- Release tag &#x27;1.0&#x27; has been back-merged into &#x27;develop&#x27;- Release branch &#x27;release/1.0&#x27; has been locally deleted- You are now on branch &#x27;develop&#x27; 根据上图的提示，发现这一步做了如下的事情。 release/1.0 分支已经被 merge 到了 master 分支 版本被打上 tag 1.0 elease/1.0 被 merge 到了 develop 分支 本地 release/1.0 被删除 切换分支到 develop 更新远程分支 $ git push origin master$ git push origin develop$ git push --tags 不使用 git-flow 创建 release-1.0 分支 $ git checkout -b release-1.0 developSwitched to a new branch &#x27;release-1.0&#x27; 提交到分支 release-1.0 $ git commit -am &quot;Bumped version number to 1.0&quot; 切换分支到 master $ git checkout master 合并 release-1.0 到 develop 分支 $ git merge --no-ff release-1.0 打上标签 (tag) $ git tag -a 1.0 -am &quot;message&quot; 切换到 develop 分支，并合并到 develop 分支。 $ git checkout develop$ git merge --no-ff release-1.0 删除本地分支 realse-1.0 $ git branch -d release-1.0 更新远程分支 $ git push origin master$ git push origin develop$ git push --tags 如果说在开发新功能的时候你没体会到 git flow 的优点，那么在 release 版本的时候，就能很明显地感受到 git flow 的优势 紧急修复 ( Hotfix )git flow 基于 master 分支，用于紧急修复，修改完成后要 merge 到 master，develop 分支 使用 git-flow $ git flow hotfix start 1.0.1 不使用 git-flow $ git checkout -b hotfix-1.2.1 master 其他步骤与在 release 开发相同，同样不要忘了在 master 分支打上 tag"},{"title":"修改操作","path":"/wiki/git/modify/index.html","content":"工作区和版本库 工作区： 就是你电脑文件夹能看到的目录，就如我创建的test文件夹就是一个工作区 leeif@leeif MINGW64 /e/git/test (master)$ lsgit.txt index.html README.md 版本库(Repository)： 工作区有一个隐藏的目录文件 .git ，这个虽然在工作区目录下，但不算在工作区，而是 Git 的版本库。Git 的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支 master，以及指向 master 的一个指针叫 HEAD 。 上一篇讲了我们把文件往Git版本库里添加的时候，是分两步执行的： 用 git add 把文件添加进去，实际上就是把文件修改添加到暂存区； 用 git commit 提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个 master 分支，所以，现在，git commit 就是往 master 分支上提交更改。 你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 ok，我们实践一下： 首先新建一个文件 test.txt ，然后对 git.exe 进行修改， $ git diff git.txtdiff --git a/git.txt b/git.txtindex 97fe984..a537f08 100644--- a/git.txt+++ b/git.txt@@ -2,4 +2,6 @@ Git is a version control system. Git is free software. Git is a distributed version control system.-Git is free software.\\ No newline at end of file+Git is free software.++add test add test\\ No newline at end of file 然后我们用 git status 查看一下状态： $ git statusOn branch masterYour branch is ahead of &#x27;origin/master&#x27; by 3 commits. (use &quot;git push&quot; to publish your local commits)Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: git.txtUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) test.txt Git非常清楚地告诉我们，git.txt 被修改了，而 test.txt 还从来没有被添加过，所以它的状态是 Untracked 现在，使用两次命令 git add ，把 git.txt 和 test.txt 都添加后，用 git status 再查看一下： $ git statusOn branch masterYour branch is ahead of &#x27;origin/master&#x27; by 3 commits. (use &quot;git push&quot; to publish your local commits)Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: git.txt new file: test.txt 所以，暂存区的状态就变成这样了： git add 命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行 git commit 就可以一次性把暂存区的所有修改提交到分支。 $ git commit -m &quot;updata&amp;test &quot;[master 0fbc057] updata&amp;test 3 files changed, 5 insertions(+), 1 deletion(-) create mode 100644 test.txt 在检查下状态，如果你没在对工作区文件进行修改的话，工作区返回的状态就是 clean $ git statusOn branch masterYour branch is ahead of &#x27;origin/master&#x27; by 4 commits. (use &quot;git push&quot; to publish your local commits)nothing to commit, working tree clean 现在版本库变成了这样，暂存区就没有任何内容了： 小结：暂存区是Git非常重要的概念，弄明白了暂存区，就弄明白了Git的很多操作到底干了什么! 管理修改为什么Git比其他版本控制系统设计得优秀，因为Git跟踪并管理的是修改，而非文件。 每次修改，如果不 add 到暂存区，那就不会加入到 commit 中。 例如： 我们对 git.txt 进行两次修改，并在修改之间进行如下指令操作： 第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git commit； 没错，我们会发现第二次修改没有被提交。我们前面讲了，Git管理的是修改，当你用git add命令后，在工作区的第一次修改被放入暂存区，准备提交，但是，在工作区的第二次修改并没有放入暂存区，所以，git commit只负责把暂存区的修改提交了，也就是第一次的修改被提交了，第二次的修改不会被提交。 那怎么提交第二次修改呢？你可以继续 git add 再 git commit ，也可以别着急提交第一次修改，先 git add 第二次修改，再 git commit ，就相当于把两次修改合并后一块提交了： 第一次修改 -&gt; git add -&gt; 第二次修改 -&gt; git add -&gt; git commit 注：提交后，用 git diff HEAD -- readme.txt 命令可以查看工作区和版本库里面最新版本的区别 撤销修改每个人都会犯错，但重点在于你能不能及时改正，Git当然也知道这一点，所以它给了我们撤销修改这个机会。 第一种情况，在没 git add 提交到暂存区时，撤销修改 我对 git.txt 增加了一条错误信息，使用 git diff 查看一下： $ git diff HEAD -- git.txtdiff --git a/git.txt b/git.txtindex a537f08..246dfe2 100644--- a/git.txt+++ b/git.txt@@ -4,4 +4,6 @@ Git is free software. Git is a distributed version control system. Git is free software. add test add test++Add an error message\\ No newline at end of file 我们再用 git status 查看一下状态： $ git statusOn branch masterYour branch is ahead of &#x27;origin/master&#x27; by 4 commits. (use &quot;git push&quot; to publish your local commits)Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: git.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 可以发现，Git会告诉你，git checkout -- file 可以丢弃工作区的修改 ok， 我们试一下，执行： $ git checkout -- git.txt 然后，查看文件 git.txt: $ cat git.txtGit is a version control system.Git is free software.Git is a distributed version control system.Git is free software.add test add test 嗯，最后一行 Add an error message 果然撤销了 第二种情况，你把修改文件提交到了暂存区，但在git commit之前 我们给 git.txt 添加 Add a second error message，并执行 git add 提交到暂存区，用 git staus 参看以下状态： $ $ git status (use &quot;git push&quot; to publish your local commits)Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: git.txtbash: $: command not found 可以看到，Git同样告诉我们，用命令 git reset HEAD file 可以把暂存区的修改撤销掉（unstage），重新放回工作区： $ git reset HEAD git.txtUnstaged changes after reset:M git.txt git reset 命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用 HEAD 时，表示最新的版本。 现在，我们可以执行 git status 查看状态发现，暂存区是干净的，而工作区有修改，其实，现在就回到了我们上面第一种情况了，执行 git checkout -- git.txt 后，查看状态，发现工作区也干净了，也就达到撤销修改的目的了。 $ cat git.txtGit is a version control system.Git is free software.Git is a distributed version control system.Git is free software.add test add test 小结: 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout – file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考上一篇，不过前提是没有推送到远程库。 删除文件在Git中，删除也是一个修改操作，我们实验一下，之前添加一个新文件test.txt到Git并且进行了 git commit 提交操作，可以看下 log： $ git log --pretty=oneline0fbc057e11b4ba59f3700a79d760e5af927a6a65 updata&amp;test //添加text.txt文件9152d920e48515d79a32824efcbe14b3665a3e6d add distributedf78f60960e2d59bd6fdc1a069e840c6d1f1c2566 add txt01ce8dd6733f7f78e7611ef72f2a092417de0bca updata homepage4db229de25fb4d0c325c98df9263b2c3d4d4607f add homepage6010c7e80796b40d89e1135bc2c86ac217274015 initial commit 一般情况下，我们通常直接在文件管理器中把没用的文件删了，或者用 rm 命令删了： $ rm test.txt# 查看目录 已经没了test,txt文件$ lsgit.txt index.html README.md 习惯性查看下状态： $ git statusOn branch masterYour branch is ahead of &#x27;origin/master&#x27; by 4 commits. (use &quot;git push&quot; to publish your local commits)Changes not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) deleted: test.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 发现Git已经知道我们进行了删除操作。 现在会出现两种情况： 一种情况就是执行 rm 命令后，发现文件删除错误了，但好在版本库里还有，所以可以很轻松的把误删的文件恢复到最新版本： $ git checkout -- test.txt git checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。 另一种情况确定进行删除操作，并需要从版本库中删除该文件。因此，需要使用 git rm 命令，并执行 git commit 提交操作： $ git rm test.txtrm &#x27;test.txt&#x27;$ git commit -m &quot;deleted test&quot;[master a15cd98] deleted test 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 test.txt 现在，文件就从版本库中也删除了，就此消失不见~~~ 命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。"},{"title":"版本控制","path":"/wiki/git/version-control/index.html","content":"创建版本库把文件添加到版本库： 通过 git init 命令把这个目录变成Git可以管理的仓库$ git initInitialized empty Git repository in E:/git/test/.git/ 用命令 git add 告诉Git，把文件添加到仓库$ git add README.md 用命令 git commit 告诉Git，把文件提交到仓库$ git commit -m &quot;initial commit&quot;[master (root-commit) 6010c7e] initial commit 1 file changed, 7 insertions(+) create mode 100644 README.md 另外：初始创建一个 github 仓库时，github 会给一些命令你去创建git本地项目. git remote add origin https://github.com/leeifme/test.git 这里的origin仅仅是一个名字，你可以把 origin 命名为 test git remote add test https://github.com/leeifme/test.git, 以后就可以用 git push text master 了 git push -u origin master , 这里就是把 master（默认 git 分支）推送到 origin， -u也就是--set-upstream, 代表的是更新默认推送的地方，这里就是默认以后git pull和git push时，都是推送和拉自 origin 。 版本回退 git status 命令可以让我们时刻掌握仓库当前的状态 git diff 顾名思义就是查看difference(修改内容) 如果 git status 告诉你有文件被修改过，用 git diff 可以查看修改内容。 如何回退和撤回操作： 先用 git log 命令显示从最近到最远的 git commit 提交日志 $ git logcommit f78f60960e2d59bd6fdc1a069e840c6d1f1c2566Author: **********************Date: Thu Jun 15 01:24:55 2017 +0800 add txtcommit 01ce8dd6733f7f78e7611ef72f2a092417de0bcaAuthor: **********************Date: Thu Jun 15 01:23:51 2017 +0800 updata homepagecommit 4db229de25fb4d0c325c98df9263b2c3d4d4607fAuthor: **********************Date: Thu Jun 15 01:14:33 2017 +0800 add homepagecommit 6010c7e80796b40d89e1135bc2c86ac217274015Author: **********************Date: Thu Jun 15 01:03:15 2017 +0800 initial commit 注： 这样输出信息太多，看得眼花缭乱的，可以试试加上 --pretty=oneline 参数 $ git log --pretty=oneline9152d920e48515d79a32824efcbe14b3665a3e6d add distributedf78f60960e2d59bd6fdc1a069e840c6d1f1c2566 add txt01ce8dd6733f7f78e7611ef72f2a092417de0bca updata homepage4db229de25fb4d0c325c98df9263b2c3d4d4607f add homepage6010c7e80796b40d89e1135bc2c86ac217274015 initial commit 回退版本，使用git reset命令。在Git中，用HEAD表示当前版本，也就是最新的提交3628164...882e1e0（注意我的提交ID和你的肯定不一样），上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 $ git reset --hard HEAD^HEAD is now at f78f609 add txt //注意看commitID ​ 后悔回退，想恢复版本，怎么办？只要知道commitID就好，怎么找？ Git很人性化的提供了一个命令git reflog用来记录你的每一次命令： $ git reflogf78f609 HEAD@&#123;0&#125;: reset: moving to HEAD^9152d92 HEAD@&#123;1&#125;: commit: add distributedf78f609 HEAD@&#123;2&#125;: commit: add txt01ce8dd HEAD@&#123;3&#125;: commit: updata homepage4db229d HEAD@&#123;4&#125;: commit: add homepage6010c7e HEAD@&#123;5&#125;: commit (initial): initial commit 知道commitID后,由于HEAD指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令git reset --hard commit_id $ git reset --hard 9152d92HEAD is now at 9152d92 add distributed 我们可以再看下版本日志，查看是否回到commitID = 9152d92的版本： $ git log --pretty=oneline9152d920e48515d79a32824efcbe14b3665a3e6d add distributedf78f60960e2d59bd6fdc1a069e840c6d1f1c2566 add txt01ce8dd6733f7f78e7611ef72f2a092417de0bca updata homepage4db229de25fb4d0c325c98df9263b2c3d4d4607f add homepage6010c7e80796b40d89e1135bc2c86ac217274015 initial commit"},{"title":"使用标签插件增强阅读体验","path":"/wiki/stellar/tag-plugins/index.html","content":"Stellar 的标签插件和 Hexo 官方的标签插件一样使用空格分隔多个参数，所以如果参数内容中需要出现的空格被意外分隔开了的时候，请使用 &amp;nbsp; 代替。为了方便理解，本文档语法格式中的可选参数用方括号括起来，键值对参数用冒号分隔开，例如： &#123;% image src [description] [download:bool/string] %&#125; 就表明第一个参数是图片链接，第二个参数是图片描述，而 download 是可选参数，并且值是布尔或字符串类型，第二三个参数为可选参数。 了解参数解析规则以图片标签为例，使用空格分隔开之后得到一个数组，如果图片描述文字中有空格，多分出来的这些「参数」被合并到最后一个「非键值对参数」中，什么是「非键值对参数」呢？举个例子您就明白了：&#123;% image /assets/wiki/stellar/photos/183e71e0ad995.jpg 来自印度的 Rohit Vohra 使用 iPhone 12 Pro Max 拍摄。 download:https://www.apple.com.cn/newsroom/images/product/iphone/lifestyle/Apple_ShotoniPhone-rohit_vohra_12172020.zip %&#125;这个例子中，download:https://xxxx 是有冒号分隔开的，download 为键，后面的网址为值，所以叫做「键值对参数」；与此相对的，没有冒号分隔的就叫做「非键值对参数」。键值对参数可以放在任何位置，我可以通过匹配键来解析，而非键值对参数则只能通过顺序解析，所以它们必须和文档中要求的前后顺序一致。一般核心的、重要的参数会设置成非键值对参数，而可选参数设置成键值对参数。"},{"title":"如何使用半自动化的文档系统","path":"/wiki/stellar/wiki-settings/index.html","content":"自动意味着 Stellar 可以自动找到一个项目的所有文档分页，生成一个目录树，半自动意味着您可以手动指定顺序、标题、分组，而非依赖文件路径、文件名来排序和显示。 创建一个项目在 blog/source/ 文件夹中创建一个 wiki 文件夹，在其中放入各个项目的文档。以 Stellar 项目为例： blog/source/wiki/stellar/index.md 设置布局模板和项目名称： blog/source/wiki/stellar/index.md---layout: wiki # 使用wiki布局模板wiki: Stellar # 这是项目名title: 这是分页标题--- 建议用这个文件作为项目的主页，并在文件夹内创建其它分页。Stellar 会把同一个项目的所有分页中 order 最小的一页作为项目的主页（其默认值为0）。 完善项目信息在数据文件中创建项目文件，以 Stellar 为例： blog/source/_data/projects.ymlStellar: title: Stellar subtitle: 每个人的独立博客 tags: 博客主题 cover: true logo: src: https://cdn.jsdelivr.net/gh/cdn-x/wiki@1.0.2/stellar/icon.svg small: 112px large: 240px description: Stellar 是一个内置 wiki 系统的 hexo 主题，适合综合型站点使用。同时也拥有简约而精美的视觉设计和丰富的标签插件，帮助您简单从容地应对各种场合。 repo: xaoxuu/hexo-theme-stellar comment_title: &#x27;评论区仅供交流，有问题请提 [issue](https://github.com/xaoxuu/hexo-theme-stellar/issues) 反馈。&#x27; beaudar: repo: xaoxuu/hexo-theme-stellar &#x27;issue-term&#x27;: &#x27;Q &amp; A&#x27; 是否显示封面项目可以显示一个全屏封面，封面占据一个屏幕的高度，会居中依次显示项目的 logo、标题、描述。开启项目封面方法如下： blog/source/_data/projects.ymlStellar: cover: true logo: src: https://cdn.jsdelivr.net/gh/cdn-x/wiki@1.0.2/stellar/icon.svg small: 120px large: 240px 如果 logo 中已经包含了项目标题，可以这样设置不显示项目标题： blog/source/_data/projects.ymlStellar: cover: [logo, description] 项目文档标签如果您有很多项目，有些项目是有相关性的，可以相同的 tags 值： blog/source/_data/projects.ymlStellar: tags: 博客主题 也可以设置多个 tags 值： blog/source/_data/projects.ymlStellar: tags: [博客主题, 开源项目] 项目的 GitHub 仓库信息设置了 repo 值就会在侧边栏显示项目仓库的相关链接： blog/source/_data/projects.ymlStellar: repo: xaoxuu/hexo-theme-stellar 项目评论设置如果希望项目的所有分页使用相同的评论数据，可以在这里覆盖评论配置： blog/source/_data/projects.ymlStellar: comment_title: &#x27;评论区仅供交流，有问题请提 [issue](https://github.com/xaoxuu/hexo-theme-stellar/issues) 反馈。&#x27; beaudar: repo: xaoxuu/hexo-theme-stellar &#x27;issue-term&#x27;: &#x27;Q &amp; A&#x27; 目前支持覆盖 beaudar&#x2F;utterances，其它评论系统可以通过设置 comment_id 来实现。 是否索引如果您有些项目希望在项目列表中隐藏，可以设置 index 值： blog/source/_data/projects.ymlStellar: index: false 文档排序一个项目文档的多个分页之间以 order 的值作为排序依据，数字越小越靠前，最小的是项目主页。 侧边栏设置侧边栏组件如果您希望自定义某个项目的侧边栏组件，可以设置 sidebar 值： blog/source/_data/projects.ymlNotes: sidebar: [toc] 对目录树进行分组如果您的项目文档分页较多，可以对目录树进行分组： blog/source/_data/projects.ymlStellar: ... sections: &#x27;快速开始&#x27;: [0, 99] &#x27;基本使用&#x27;: [100, 199] &#x27;文档系统&#x27;: [200, 299] &#x27;进阶设定&#x27;: [900, 999] 左边是显示的标题，右边是 order 的区间，例如某页文档的 order 是 150，那么这页文档将会显示在「日常问题解决方案」这个组中。 修改 wiki 路径在根目录中添加 wiki_dir 指定 Wiki 主页的路径： blog/_config.ymlwiki_dir: wiki 例如书籍类的“项目”可以改为： blog/_config.ymlwiki_dir: books 例如商品&#x2F;产品类的“项目”可以改为： blog/_config.ymlwiki_dir: products"},{"title":"容器类标签（7个）","path":"/wiki/stellar/tag-plugins/container/index.html","content":"ablock 普通块容器note 标签就是使用 ablock 容器实现的，它们样式是相同的： 更名记录（Stellar 1.18.0）因为原 noteblock 标签在升级到 hexo 6.0 之后跟官方库冲突了，官方一直没有解释原因，后不得不改名：noteblock -&gt; grid -&gt; border -&gt; ablock详情见：#172 语法格式&#123;% ablock [title] [color:color] [child:codeblock/tabs] %&#125;...&#123;% endablock %&#125; 写法如下&#123;% ablock Stellar v1.12.0 color:warning %&#125;因为原 noteblock 标签在升级到 hexo 6.0 之后跟官方库冲突了，官方一直没有解释原因，后不得不改名：noteblock -&gt; grid -&gt; border详情见：[#172](https://github.com/volantis-x/hexo-theme-volantis/issues/712)&#123;% endablock %&#125; 彩色代码块设置 child:codeblock 并设置 color:颜色枚举 可以实现 10 种不同颜色的代码块，彩色代码块一般可以用在代码正确与错误的示范对比场景。 推荐的写法func test() &#123; // ...&#125;不推荐的写法func test() -&gt; () &#123; // ...&#125; 嵌套其它标签例如嵌套一个 tabs 标签： 图文混排示例代码个人电脑作为办公设备时，我们该如何保护隐私？公司一般都会强制安装安防软件，这些软件要求开机自启动，要求有屏幕录制权限、完全的磁盘访问权限包括相册图库。因此如果使用自己的 MacBook 作为办公设备，必须要把生活区和工作区完全独立开，安装在两个磁盘分区，并且对磁盘分区进行加密。 folding 折叠容器折叠块标签的语法格式为： &#123;% folding title [codeblock:bool] [open:bool] [color:color] %&#125;content&#123;% endfolding %&#125; 参数说明codeblock: true/falseopen: true/falsecolor: red/orange/yellow/green/cyan/blue/purple/light/dark 彩色可折叠代码块备注标签相较于旧版进行了增强，可以实现更多种颜色，还可以通过设置 child:codeblock 来实现可折叠的代码块。以下是一个默认打开的代码折叠框： 默认打开的代码折叠框func test() &#123; print(&quot;hello world&quot;)&#125; 代码如下： &#123;% folding child:codeblock open:true color:yellow 默认打开的代码折叠框 %&#125;代码块&#123;% endfolding %&#125; 危险，请不要打开这个通过设置颜色，以实现更醒目的作用，但不要滥用色彩哦～警告，真的很危险通过设置颜色，以实现更醒目的作用，但不要滥用色彩哦～最后一次警告，千万不要打开这个不要说我们没有警告过你，Windows 10 不是為所有人設計，而是為每個人設計。 folders 多个折叠容器聚合样式相比 folding 简单一些，适用于多个折叠标签平铺显示的场景，例如题目列表： 题目1这是答案1题目2这是答案2题目3这是答案3 代码如下： &#123;% folders %&#125;&lt;!-- folder 题目1 --&gt;这是答案1&lt;!-- folder 题目2 --&gt;这是答案2&lt;!-- folder 题目3 --&gt;这是答案3&#123;% endfolders %&#125; tabs 分栏容器这个标签移植自 NexT 主题，但做了以下修改： 支持设置 align:center 来使内容居中 设置默认激活的标签方式为 active:1 而非 , 1（使用默认格式降低学习成本，且显式声明可读性更强） 不需要 &lt;!-- endtab --&gt; 来作为结束标识（因为 Stellar 会自动判断） 不需要 tabs id 来保证唯一性（因为 Stellar 会设置唯一标识） 不支持 @icon 方式设置图标（因为 Stellar 不再内置 fontawesome 图标库） 轮廓样式简化，可以搭配其它容器类标签嵌套使用。 演示效果示例代码图片代码块表格let x = 123print(&quot;hello world&quot;) a b c a1 b1 c1 a2 b2 c2 grid 网格分区容器这个功能在 1.12.0 版本后开始支持，目前只支持显示一行两列，且手机端因宽度较窄会恢复为单列显示。 Unsplash PhotoThe Galactic Center is the rotational center of the Milky Way galaxy. Its central massive object is a supermassive black hole of about 4 million solar masses, which is called Sagittarius A*. Its mass is equal to four million suns. The center is located 25,800 light years away from Earth.Ōwhiro Bay, Wellington, New ZealandPublished on May 31, 2022SONY, ILCE-6000Free to use under the Unsplash License 普通块样式： 左侧内容右侧内容 卡片样式： 左侧内容右侧内容 示例代码： &#123;% grid bg:block %&#125;&lt;!-- cell left --&gt;&lt;center&gt;左侧内容&lt;/center&gt;&lt;!-- cell right --&gt;&lt;center&gt;右侧内容&lt;/center&gt;&#123;% endgrid %&#125; bg 为可选参数，默认没有背景，可设置为 block/card 两种样式 about 关于块容器方便在关于页面显示一段图文信息，比普通块容器稍微有一点点不一样： &#123;% about avatar:/assets/xaoxuu/avatar/rect-256@2x.png height:80px %&#125;&lt;img height=&quot;32px&quot; alt=&quot;XAOXUU&quot; src=&quot;/assets/xaoxuu/logo/180x30@2x.png&quot;&gt;**如果宇宙中真有什么终极的逻辑，那就是我们终有一天会在舰桥上重逢，直到生命终结。**XAOXUU 目前是一个 iOS 开发者，代表作品有：ProHUD、ValueX 等。在业余时间也开发了 Stellar 博客主题，更多的作品可以去项目主页查看，希望大家喜欢～&#123;% navbar [文章](/) [项目](/wiki/) [留言](#comments) [GitHub](https://github.com/xaoxuu/) %&#125;&#123;% endabout %&#125; 这个标签正在考虑重命名请发表您的建议 #198 swiper 轮播容器默认一张图片是 50% 宽度，通过设置 width:min 设置为 25% 宽度，width:max 设置为 100% 宽度。 写法如下&#123;% swiper effect:cards %&#125;![](https://images.unsplash.com/photo-1625171515821-1870deb2743b?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=774&amp;q=80)![](https://images.unsplash.com/photo-1528283648649-33347faa5d9e?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=774&amp;q=80)![](https://images.unsplash.com/photo-1542272201-b1ca555f8505?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=774&amp;q=80)![](https://images.unsplash.com/photo-1524797905120-92940d3a18d6?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=774&amp;q=80)&#123;% endswiper %&#125; 宽度切换效果写法如下&#123;% swiper width:min/max %&#125;...&#123;% endswiper %&#125;&#123;% swiper effect:cards/coverflow %&#125;...&#123;% endswiper %&#125; 注意一个页面只能设置一次，第一个 swiper 容器的效果全局生效。"},{"title":"数据集合类标签（5个）","path":"/wiki/stellar/tag-plugins/data/index.html","content":"timeline 时间线支持静态和动态时间线数据源，用法非常多，详见这篇文章： https://xaoxuu.com/blog/20221029/https://xaoxuu.com/blog/20221029/ 静态时间线静态数据是写死在 md 源文件中的，在 deploy 时就已经确定了。 2021 年 2 月 16 日主要部分功能已经开发的差不多了。2021 年 2 月 11 日今天除夕，也是生日，一个人在外地过年+过生日，熬夜开发新主题，尽量在假期结束前放出公测版。 写法如下&#123;% timeline %&#125;&lt;!-- node 2021 年 2 月 16 日 --&gt;主要部分功能已经开发的差不多了。&#123;% image /assets/wiki/stellar/photos/hello@1x.png width:300px %&#125;&lt;!-- node 2021 年 2 月 11 日 --&gt;今天除夕，也是生日，一个人在外地过年+过生日，熬夜开发新主题，尽量在假期结束前放出公测版。&#123;% endtimeline %&#125; 动态时间线动态说说朋友圈微博动态动态数据是从 GitHub Issues 中拉取的，使用方法为： 建一个仓库 创建一个 issue 并添加一个 label 进行测试 写 timeline 标签时加上 api:https://api.github.com/repos/your-name/your-repo/issues 例如： _posts/xxx.md&#123;% timeline api:https://api.github.com/repos/xaoxuu/blog-timeline/issues?direction=asc&amp;per_page=3 %&#125;&#123;% endtimeline %&#125; 效果如下： https://xaoxuu.com/wiki/stellar/fcircle/https://xaoxuu.com/wiki/stellar/fcircle/ _posts/xxx.md&#123;% timeline type:fcircle api:https://raw.githubusercontent.com/xaoxuu/friends-rss-generator/output/data.json %&#125;&#123;% endtimeline %&#125; fork 爬虫 仓库 ，修改自己的仓库名 修改 .github/workflows/main.yml 中的微博ID为你想爬取的ID，修改完后每天会自动爬取你的微博，存储为 json 文件，输出文件在 output 分支 _posts/xxx.md&#123;% timeline limit:20 type:weibo api:你的json文件地址 %&#125;&#123;% endtimeline %&#125; 静态 + 动态用法同静态和动态单独使用时一样，例如： &#123;% timeline reversed:true api:https://api.github.com/repos/xaoxuu/blog-timeline/issues?per_page=2 %&#125;&lt;!-- node 这条内容为静态数据 --&gt;这条内容为静态数据，静态数据在 `deploy` 时就已经确定了。&#123;% endtimeline %&#125; 数据筛选只显示某个人的数据筛选最近3条todo筛选评论最多的3条建议 上述示例代码如下： &#123;% folders %&#125;&lt;!-- 只显示某个人的数据 --&gt;&#123;% timeline user:xaoxuu api:https://api.github.com/repos/volantis-x/hexo-theme-volantis/issues %&#125;&#123;% endtimeline %&#125;&lt;!-- 筛选最近3条todo --&gt;&#123;% timeline api:https://api.github.com/repos/xaoxuu/hexo-theme-stellar/issues?labels=todo&amp;per_page=3 %&#125;&#123;% endtimeline %&#125;&lt;!-- 筛选评论最多的3条建议 --&gt;&#123;% timeline api:https://api.github.com/repos/volantis-x/hexo-theme-volantis/issues?labels=feature-request&amp;per_page=3&amp;sort=comments %&#125;&#123;% endtimeline %&#125;&#123;% endfolders %&#125; 更多用法详见： GitHub&nbsp;REST&nbsp;APIhttps://docs.github.com/en/rest/issues/issues#list-issues-assigned-to-the-authenticated-user friends 友链 您可以在任何位置插入友链组，支持静态数据和动态数据，静态数据需要写在数据文件中： blog/source/_data/links.yml&#x27;开源大佬&#x27;: - title: 某某某 url: https:// screenshot: avatar: description: 在需要的位置这样写： &#123;% friends 开源大佬 %&#125; 实现动态友链从 xaoxuu&#x2F;issues-json-generator 作为模板克隆或者 fork 仓库 修改 config.yml 并打开 github action 的运行权限 config.yml# 要抓取的 issues 配置issues: repo: xaoxuu/friends # 仓库持有者/仓库名（改成自己的） label: active # 筛选具有 active 标签的 issue ，取消此项则会提取所有 open 状态的 issue sort: # updated-desc # 排序，按最近更新，取消此项则按创建时间排序 不出意外的话，仓库中已经配置好了 issue 模板，只需要在模板中指定的位置填写信息就可以了。然后在自己的仓库里提交一个 issue 并将 Label 设置为 active 进行测试。 提交完 issue 一分钟左右，如果仓库中出现了 output 分支提交，可以点击查看一下文件内容是否已经包含了刚刚提交的 issue 中的数据，如果包含，那么前端页面就可以使用友链数据了： &#123;% friends api:https://raw.githubusercontent.com/xaoxuu/friends/output/v2/data.json %&#125; 数据托管与加速特别感谢特别感谢小冰博客的加速访问方案，解决了直接请求 GitHub API 速度过慢的问题，详见 小冰博客 的教程。 支持把数据托管到任何其他地方来使用，例如： &#123;% friends api:https://api.vlts.cc/output_data/v2/xaoxuu/friends %&#125; Stellar 1.13.0动态数据 API 升级至 v2 版本，原使用 issue-api 仓库的需要将友链仓库同步更新。v1 版本已经停止维护。 你可以有 N 种办法加速访问 GitHub 仓库里的文件。 sites 网站卡片 您可以在任何位置插入网站卡片组，支持静态数据和动态数据，静态数据需要写在数据文件中： blog/source/_data/links.yml&#x27;分组名&#x27;: - title: 某某某 url: https:// screenshot: avatar: description: 在需要的位置这样写： &#123;% sites 分组名 %&#125; Stellar v1.13.0原 friends 和 sites 标签数据合并至 links.yml 文件，动态数据使用方法同友链，数据源格式相同，与友链共享数据，仅样式不同，也可以用 sites 标签做友链。 ghcard 卡片 写法如下&#123;% ghcard xaoxuu %&#125;&#123;% ghcard xaoxuu/hexo-theme-stellar theme:dark %&#125; GitHub&nbsp;Card&nbsp;APIhttps://github.com/anuraghazra/github-readme-stats toc 文档目录树&#123;% toc wiki:xxx [open:true] [display:mobile] title %&#125;"},{"title":"表达类标签（14+个）","path":"/wiki/stellar/tag-plugins/express/index.html","content":"emoji 表情效果演示语法格式引入表情包内置了可配置的表情标签 使用方法如下： &#123;% emoji 爱你 %&#125;&#123;% emoji blobcat ablobcatrainbow %&#125;&#123;% emoji blobcat ablobcatattentionreverse %&#125;&#123;% emoji tieba 滑稽 %&#125;&#123;% emoji [source] name [height:1.75em] %&#125; 其中 source 可省略，默认为配置中的第一个 source（详见「引入表情包」部分） 如果对高度有特别要求，可以指定高度，例如：&#123;% emoji blobcat ablobcatrainbow height:4em %&#125; 表情速查表1：stellar表情标签索引表情速查表2：Stellar内嵌blobcat小表情 blog/_config.stellar.ymltag_plugins: ... emoji: default: https://fastly.jsdelivr.net/gh/cdn-x/emoji/qq/%s.gif twemoji: https://fastly.jsdelivr.net/gh/twitter/twemoji/assets/svg/%s.svg qq: https://fastly.jsdelivr.net/gh/cdn-x/emoji/qq/%s.gif aru: https://fastly.jsdelivr.net/gh/cdn-x/emoji/aru-l/%s.gif tieba: https://fastly.jsdelivr.net/gh/cdn-x/emoji/tieba/%s.png 在配置文件中，文件名用 %s 代替。 mark 行内文本标记支持多彩标记，包括：默认 红 橙 黄 绿 青 蓝 紫 浅 深 警告 错误 一共 12 种颜色。 支持多彩标记，包括：&#123;% mark 默认 %&#125; &#123;% mark 红 color:red %&#125; &#123;% mark 橙 color:orange %&#125; &#123;% mark 黄 color:yellow %&#125; &#123;% mark 绿 color:green %&#125; &#123;% mark 青 color:cyan %&#125; &#123;% mark 蓝 color:blue %&#125; &#123;% mark 紫 color:purple %&#125; &#123;% mark 浅 color:light %&#125; &#123;% mark 深 color:dark %&#125; &#123;% mark 警告 color:warning %&#125; &#123;% mark 错误 color:error %&#125; 一共 12 种颜色。 tag 标签这个效果类似于 mark 标签，但是更适合一批标签独占一行来使用，支持链接： Stellar Hexo GitHub Gitea 如果没有指定颜色，且没有设置默认颜色，则随机取一个颜色，快来试试吧～ &#123;% tag Stellar https://xaoxuu.com/wiki/stellar/ %&#125;&#123;% tag Hexo https://hexo.io/ %&#125;&#123;% tag GitHub https://github.com/xaoxuu/ %&#125;&#123;% tag Gitea https://gitea.xaox.cc/ color:green %&#125; image 图片标签图片标签是一个精心设计的应对各种尺寸插图的标签，对于大图，可以放置一个「下载」按钮，语法格式如下： &#123;% image src [description] [download:bool/string] [width:px] [padding:px] [bg:hex] %&#125; 参数说明src: 图片地址description: 图片描述download: href # 下载地址，设置此值后鼠标放在图片上会显示下载地址，如果下载地址为图片地址，可以设置为 truewidth: 200px # 图片宽度padding: 16px # 图片四周填充宽度bg: &#x27;#ffffff&#x27; # 图片区域背景颜色，16进制 大尺寸图片无论在什么宽度的设备上都希望横向铺满的图片，一般不需要额外操作。可以在链接后面写上图片描述，如有必要，可以通过设置 download:true 使其显示一个「下载」按钮链接指向图片地址，如果下载链接与显示的图片地址不同，可以 download:下载链接 来使其能够下载原图。 来自印度的 Rohit Vohra 使用 iPhone 12 Pro Max 拍摄。 来自澳大利亚的 Pieter de Vries 使用 iPhone 12 Pro Max 拍摄。 写法如下&#123;% image /assets/wiki/stellar/photos/183e71e0ad995.jpg 来自印度的 Rohit Vohra 使用 iPhone 12 Pro Max 拍摄。 download:https://www.apple.com.cn/newsroom/images/product/iphone/lifestyle/Apple_ShotoniPhone-rohit_vohra_12172020.zip %&#125;&#123;% image /assets/wiki/stellar/photos/bc7bda18328da.jpg 来自澳大利亚的 Pieter de Vries 使用 iPhone 12 Pro Max 拍摄。 download:https://www.apple.com.cn/newsroom/images/product/iphone/lifestyle/Apple_ShotoniPhone_pieter_de_vries_011221.zip %&#125; 小尺寸图片优化宽度较小而高度较大的图片，可以设置宽、高、填充间距、背景色等对其布局进行优化，使得它在不同宽度的屏幕下都能获得不错的视觉体验： 有底色的图片没有底色的图片有底色的图片，可以填充图片底色： &#123;% image /assets/xaoxuu/mirror/apple/documentation/watchkit/06d45110-1dd7-49a4-a413-9f5159ecdd0e.png width:200px padding:16px bg:white %&#125; 提示鼠标拖拽一下图片可以看看原图 如果不进行约束，在宽屏设备上阅读体验很糟糕没有底色的图片，可以填充 bg:var(--card) 动态颜色，能够适配暗黑模式： &#123;% image /assets/wiki/stellar/icon.svg bg:var(--card) padding:16px %&#125; 支持 Fancybox 插件点击放大由于 Stellar 主题的插件具有按需加载的特性，所以 Fancybox 插件默认也是已经配置好了的，在任意 image 标签中增加 fancybox:true 参数即可为特定图片开启缩放功能。如果一个页面没有任何地方使用，则不会加载 Fancybox 插件。 图片来自 Apple 官网 如果您希望全站所有的 image 标签都开启此功能，可在主题配置文件中修改以下参数： ######## Tag Plugins ########tag_plugins: # &#123;% image %&#125; image: fancybox: true quot 引用适合居中且醒目的引用：Stellar 是最好用的主题 支持自定义引号：热门话题 其中自定义引号素材在主题配置文件的 tag_plugins.quot 中配置： tag_plugins: ... # &#123;% quot %&#125; quot: default: # 可以自行配置多种图标方案 prefix: https://bu.dusays.com/2022/10/24/63567d3e092ff.png suffix: https://bu.dusays.com/2022/10/24/63567d3e0ab55.png hashtag: prefix: https://bu.dusays.com/2022/10/24/63567d3e07da3.png 写法如下适合居中且醒目的引用：&#123;% quot Stellar 是最好用的主题 %&#125;支持自定义引号：&#123;% quot 热门话题 icon:hashtag %&#125; 特别引用 此外，加上 el:h2/h3/h4/h5/h6 可以作为标题使用 poetry 诗词示例写法游山西村陆游莫笑农家腊酒浑，丰年留客足鸡豚。山重水复疑无路，柳暗花明又一村。箫鼓追随春社近，衣冠简朴古风存。从今若许闲乘月，拄杖无时夜叩门。诗词节选&#123;% poetry 游山西村 author:陆游 footer:诗词节选 %&#125;莫笑农家腊酒浑，丰年留客足鸡豚。**山重水复疑无路，柳暗花明又一村。**箫鼓追随春社近，衣冠简朴古风存。从今若许闲乘月，拄杖无时夜叩门。&#123;% endpoetry %&#125; note 备注块示例写法&#123;% note [title] content [color:color] %&#125;title: 标题（可选）content: 内容color: red/orange/yellow/green/cyan/blue/purple/light/dark/warning/error 具有标题的备注块直接写备注内容，默认是和代码块一样的样式，第一个空格前面的是标题，后面的是正文，如果标题中需要显示空格，请使用 &amp;nbsp; 代替。 示例写法这&nbsp;是标题这是正文 哈哈。&#123;% note 这&amp;nbsp;是标题 这是正文 哈哈。 %&#125; 彩色备注块示例写法一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 一共支持12种颜色，可以满足几乎所有的需求了。color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。&#123;% note 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 %&#125;&#123;% note color:cyan 一共支持12种颜色，可以满足几乎所有的需求了。 color 可设置 red、orange、yellow、green、cyan、blue、purple、light、dark、warning、error 几种取值。 %&#125; link 链接卡片效果演示语法格式写法示例https://xaoxuu.com/blog/20221029/https://xaoxuu.com/blog/20221029/ https://xaoxuu.com/blog/20221029/https://xaoxuu.com/blog/20221029/外链卡片标签的语法格式为： &#123;% link href [title] [icon:src] [desc:true/false] %&#125; 参数含义： href: 链接title: 可选，手动设置标题（为空时会自动抓取页面标题）icon: 可选，手动设置图标（为空时会自动抓取页面图标）desc: 可选，是否显示摘要描述，为true时将会显示页面描述不带摘要的样式：&#123;% link https://xaoxuu.com/blog/20221029/ %&#125;带摘要的样式：&#123;% link https://xaoxuu.com/blog/20221029/ desc:true %&#125; copy 复制行示例写法对于单行内容，可以使用 copy 标签来实现复制功能： 您可以设置 git:https 或者 git:ssh 或者 git:gh 来快速放置一个 git 仓库链接： &#123;% copy curl -s https://sh.xaox.cc/install | sh %&#125;&#123;% copy width:max curl -s https://sh.xaox.cc/install | sh %&#125;&#123;% copy git:https xaoxuu.com/hexo-theme-stellar %&#125;&#123;% copy git:ssh xaoxuu.com/hexo-theme-stellar %&#125;&#123;% copy git:gh xaoxuu.com/hexo-theme-stellar %&#125; radio 单选示例写法没有勾选的单选框 已勾选的单选框&#123;% radio 没有勾选的单选框 %&#125;&#123;% radio checked:true 已勾选的单选框 %&#125; 支持的参数checked: true/falsecolor: red/orange/yellow/green/cyan/blue/purple checkbox 复选示例写法普通的没有勾选的复选框 普通的已勾选的复选框 显示为加号的绿色的已勾选的复选框 显示为减号的黄色的已勾选的复选框 显示为乘号的红色的已勾选的复选框&#123;% checkbox 普通的没有勾选的复选框 %&#125;&#123;% checkbox checked:true 普通的已勾选的复选框 %&#125;&#123;% checkbox symbol:plus color:green checked:true 显示为加号的绿色的已勾选的复选框 %&#125;&#123;% checkbox symbol:minus color:yellow checked:true 显示为减号的黄色的已勾选的复选框 %&#125;&#123;% checkbox symbol:times color:red checked:true 显示为乘号的红色的已勾选的复选框 %&#125; 支持的参数checked: true/falsecolor: red/orange/yellow/green/cyan/blue/purplesymbol: plus/minus/times navbar 导航栏文章内也可以插入一个导航栏： &#123;% navbar active:1 [文章](/) [项目](/wiki/) [留言](#comments) [GitHub](https://github.com/xaoxuu/) %&#125; 文章项目留言GitHub frame 设备框架示例写法&#123;% frame iphone11 img:/assets/wiki/prohud/toast/demo-loading.png video:/assets/wiki/prohud/toast/demo-loading.mp4 focus:top %&#125; 文本修饰标签集 这是 密码 标签 这是 下划线 标签 这是 着重号 标签 这是 波浪线 标签 这是 删除线 标签 这是 上角标 标签 这是 下角标 标签 这是 键盘样式 标签，试一试：⌘ + D 写法如下- 这是 &#123;% psw 密码 %&#125; 标签- 这是 &#123;% u 下划线 %&#125; 标签- 这是 &#123;% emp 着重号 %&#125; 标签- 这是 &#123;% wavy 波浪线 %&#125; 标签- 这是 &#123;% del 删除线 %&#125; 标签- 这是 &#123;% sup 上角标 color:red %&#125; 标签- 这是 &#123;% sub 下角标 %&#125; 标签- 这是 &#123;% kbd 键盘样式 %&#125; 标签，试一试：&#123;% kbd ⌘ %&#125; + &#123;% kbd D %&#125;"}]